<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>David&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/4dfb0a779aa32370c22ca94ba2397da8</icon>
  <subtitle>knowledge is power</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://idrawone.github.io/"/>
  <updated>2022-07-22T20:31:56.729Z</updated>
  <id>https://idrawone.github.io/</id>
  
  <author>
    <name>David Zhang</name>
    <email>idrawone@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>How to setup Lustre file system and run Postgres on it</title>
    <link href="https://idrawone.github.io/2022/07/22/how-to-setup-lustre-file-system-and-run-postgres-on-it/"/>
    <id>https://idrawone.github.io/2022/07/22/how-to-setup-lustre-file-system-and-run-postgres-on-it/</id>
    <published>2022-07-22T08:00:00.000Z</published>
    <updated>2022-07-22T20:31:56.729Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-postgres-on-lustre.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>Similar to PostgreSQL, Lustre file system is also an open source project which started about 20 years ago. According to <a href="https://en.wikipedia.org/wiki/Lustre_(file_system)" target="_blank" rel="noopener">Wikipedia</a>, Lustre file system is a type of parallel distributed file system, and is designed for large-scale cluster computing with native Remote Direct Memory Access (RDMA) support. Lustre file systems are scalable and can be part of multiple computer clusters with tens of thousands of client nodes, tens of petabytes (PB) of storage on hundreds of servers, and more than a terabyte per second (TB/s) of aggregate I/O throughput. This blog will explain how to setup a simple Lustre file system on CentOS 7 and run PostgreSQL on it.</p><h4 id="2-Lustre-file-system"><a href="#2-Lustre-file-system" class="headerlink" title="2. Lustre file system"></a>2. Lustre file system</h4><p>To deliver parallel file access and improve I/O performance, Lustre file system separates out metadata services and data services. From high level architecture point of view, Lustre file system contains below basic components:<br>Management Server (MGS), provides configuration information about how the file system is configured, notifies clients about changes in the file system configuration and plays a role in the Lustre recovery process.<br>Metadata Server (MDS),  manages the file system namespace and provides metadata services to clients such as filename lookup, directory information, file layouts, and access permissions.<br>Metadata Target (MDT), stores metadata information, and holds the root information of the file system.<br>Object Storage Server (OSS), stores file data objects and makes the file contents available to Lustre clients.<br>Object Storage Target (OST), stores the contents of user files.<br>Lustre Client, mounts the Lustre file system and makes the contents of the namespace visible to the users.<br>Lustre Networking (LNet) - a network protocol used for communication between Lustre clients and servers with native RDMA supported.<br>If you want to know more details inside Lustre, you can refer to <a href="https://wiki.lustre.org/Understanding_Lustre_Internals" target="_blank" rel="noopener">Understanding Lustre Internals</a>.</p><h4 id="3-Setup-Lustre-on-CentOS-7"><a href="#3-Setup-Lustre-on-CentOS-7" class="headerlink" title="3. Setup Lustre on CentOS 7"></a>3. Setup Lustre on CentOS 7</h4><p>To setup a simple Lustre file system for PostgreSQL, we need to have 4 machines: MGS-MDS-MDT server, OSS-OST server, Lustre client1 and client2 (Postgres Servers). In this blog, I used three CentOS 7 virtual machines with below network settings:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MGS-MDS-MDT: 10.10.1.1</span><br><span class="line">OSS-OST: 10.10.1.2</span><br><span class="line">Client1&#x2F;PG Server: 10.10.1.10</span><br><span class="line">Client2&#x2F;PG Server: 10.10.1.20</span><br></pre></td></tr></table></figure><h5 id="3-1-Install-Lustre"><a href="#3-1-Install-Lustre" class="headerlink" title="3.1. Install Lustre"></a>3.1. Install Lustre</h5><p>To avoid dealing with Firewall and SELinux policy issues, I simply disabled them like below,<br>Set <code>SELINUX=disabled</code> in /etc/selinux/config, and run commands,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure><p>Add Lustre release information to <code>/etc/yum.repos.d/lustre.repo</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[lustre-server]</span><br><span class="line">name&#x3D;CentOS-$releasever - Lustre</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;build.whamcloud.com&#x2F;job&#x2F;lustre-master&#x2F;arch&#x3D;x86_64%2Cbuild_type&#x3D;server%2Cdistro&#x3D;el7%2Cib_stack&#x3D;inkernel&#x2F;lastStableBuild&#x2F;artifact&#x2F;artifacts&#x2F;</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;downloads.whamcloud.com&#x2F;public&#x2F;lustre&#x2F;latest-release&#x2F;el7&#x2F;server&#x2F;</span><br><span class="line">gpgcheck&#x3D;0</span><br><span class="line"></span><br><span class="line">[e2fsprogs]</span><br><span class="line">name&#x3D;CentOS-$releasever - Ldiskfs</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;build.whamcloud.com&#x2F;job&#x2F;e2fsprogs-master&#x2F;arch&#x3D;x86_64%2Cdistro&#x3D;el7&#x2F;lastStableBuild&#x2F;artifact&#x2F;_topdir&#x2F;RPMS&#x2F;</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;downloads.whamcloud.com&#x2F;public&#x2F;e2fsprogs&#x2F;latest&#x2F;el7&#x2F;</span><br><span class="line">gpgcheck&#x3D;0</span><br><span class="line"></span><br><span class="line">[lustre-client]</span><br><span class="line">name&#x3D;CentOS-$releasever - Lustre</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;build.whamcloud.com&#x2F;job&#x2F;lustre-master&#x2F;arch&#x3D;x86_64%2Cbuild_type&#x3D;client%2Cdistro&#x3D;el7%2Cib_stack&#x3D;inkernel&#x2F;lastStableBuild&#x2F;artifact&#x2F;artifacts&#x2F;</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;downloads.whamcloud.com&#x2F;public&#x2F;lustre&#x2F;latest-release&#x2F;el7.9.2009&#x2F;client&#x2F;</span><br><span class="line">gpgcheck&#x3D;0</span><br></pre></td></tr></table></figure><p>Then update yum and install the filesystem utilities <code>e2fsprogs</code> to deal with ext4</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum update &amp;&amp; yum upgrade -y e2fsprogs</span><br></pre></td></tr></table></figure><p>If there is no errors, then install Lustre server and tools with <code>yum install -y lustre-tests</code></p><h5 id="3-2-Setup-lnet-network"><a href="#3-2-Setup-lnet-network" class="headerlink" title="3.2. Setup lnet network"></a>3.2. Setup lnet network</h5><p>Depends on your network interfaces setup, add the lnet configuration correspondingly. For example, all my 3 CentOS 7 has a network interface <code>enp0s8</code>, therefore, I added the configuration <code>options lnet networks=&quot;tcp0(enp0s8)&quot;</code> to <code>/etc/modprobe.d/lnet.conf</code> as my Lustre lnet network configuration.</p><p>Then we need to load the lnet driver to the kernel, and start the lnet network by running below commands,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">modprobe lustre</span><br><span class="line">lsmod | grep lustre</span><br><span class="line">modprobe lnet</span><br><span class="line">lsmod | grep lnet</span><br><span class="line">lctl network up</span><br></pre></td></tr></table></figure><p>You can check if the lnet network is running on your Ethernet interface using command <code>lctl list_nids</code>, and you should see something like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.10.1.1@tcp</span><br></pre></td></tr></table></figure><p>You can try to ping other Lustre servers over the lnet network by running command <code>lctl ping 10.10.1.2@tcp1</code>. If the lnet network is working, then you should see below output,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">12345-0@lo</span><br><span class="line">12345-10.10.1.2@tcp</span><br></pre></td></tr></table></figure><h5 id="3-3-Setup-MGS-MDS-MDT-and-OSS-OST-servers"><a href="#3-3-Setup-MGS-MDS-MDT-and-OSS-OST-servers" class="headerlink" title="3.3. Setup MGS/MDS/MDT and OSS/OST servers"></a>3.3. Setup MGS/MDS/MDT and OSS/OST servers</h5><p>To set up the storage for MGS/MDS/MDT server, I added one dedicated virtual disk (/dev/sdb), created one partition (/dev/sdb1) and formatted it to ext4. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fdisk &#x2F;dev&#x2F;sdb</span><br><span class="line">...</span><br><span class="line">mkfs -t ext4 &#x2F;dev&#x2F;sdb1</span><br></pre></td></tr></table></figure><p>You need to repeat the same process on OSS/OST server to add actual files storage disk.</p><p>If everything goes fine, then it is time to mount the disk on Lustre servers. First, we need to mount the disk on MGS/MDS/MDT server by running below command,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkfs.lustre --reformat --fsname&#x3D;lustrefs --mgs --mdt --index&#x3D;0 &#x2F;dev&#x2F;sdb1</span><br><span class="line">mkdir &#x2F;mgsmdt_mount</span><br><span class="line">mount -t lustre &#x2F;dev&#x2F;sdb1 &#x2F;mgsmdt_mount</span><br></pre></td></tr></table></figure><p>Second, we mount the disk on OSS/OST server using below commands,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkfs.lustre --reformat --ost --fsname&#x3D;lustrefs --mgsnode&#x3D;10.10.1.1@tcp1 --index&#x3D;0 &#x2F;dev&#x2F;sdb1</span><br><span class="line">mkdir &#x2F;ostoss_mount </span><br><span class="line">mount -t lustre &#x2F;dev&#x2F;sdb1 &#x2F;ostoss_mount</span><br></pre></td></tr></table></figure><h5 id="3-4-Setup-Lustre-clients"><a href="#3-4-Setup-Lustre-clients" class="headerlink" title="3.4. Setup Lustre clients"></a>3.4. Setup Lustre clients</h5><p>After the Luster server’s setup is done, we can simply mount the lustre file system on client by running below commands, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir &#x2F;mnt&#x2F;lustre</span><br><span class="line">mount -t lustre 10.10.1.1@tcp0:&#x2F;lustrefs &#x2F;mnt&#x2F;lustre</span><br></pre></td></tr></table></figure><p>If no error, then you can verify it by creating a text file and entering some information from one client, and check it from another client.</p><h5 id="3-5-Setup-Postgres-on-Lustre-file-system"><a href="#3-5-Setup-Postgres-on-Lustre-file-system" class="headerlink" title="3.5. Setup Postgres on Lustre file system"></a>3.5. Setup Postgres on Lustre file system</h5><p>As there are some many tutorials about how to setup Postgres on CentOS, I will skip this part. Assume you have installed Postgres either from an “official release” or compiled from the source code yourself, then run below tests from client1,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">initdb -D &#x2F;mnt&#x2F;lustre&#x2F;pgdata</span><br><span class="line">pg_ctl -D &#x2F;mnt&#x2F;lustre&#x2F;pgdata -l &#x2F;tmp&#x2F;logfile start</span><br><span class="line">create table test(a int, b text);</span><br><span class="line">insert into test values(generate_series(1, 1000), &#39;helloworld&#39;);</span><br><span class="line">select count(*) from test;</span><br><span class="line">pg_ctl -D &#x2F;mnt&#x2F;lustre&#x2F;pgdata -l &#x2F;tmp&#x2F;logfile stop</span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line"></span><br><span class="line">Then run below commands from client2,</span><br></pre></td></tr></table></figure><p>pg_ctl -D /mnt/lustre/pgdata -l /tmp/logfile start<br>select count(*) from test;<br>pg_ctl -D /mnt/lustre/pgdata -l /tmp/logfile stop</p><pre><code>From the above simple tests, you can confirm that the table created and records inserted by client1 are stored on remote Lustre file system, and if Postgres server stop on client1, then you can start Postgres server on client2 and query all the records inserted by client1. #### 4. SummaryIn this blog, I explained how to set up a parallel distributed file system - Lustre on a local environment, and verify it with PostgreSQL servers. I hope this blog can help you if you want to evaluate some distributed file systems.</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-postgres-on-lustre.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="parallel" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/"/>
    
      <category term="distributed" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/distributed/"/>
    
      <category term="file" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/distributed/file/"/>
    
      <category term="system" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/distributed/file/system/"/>
    
      <category term="storage" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/distributed/file/system/storage/"/>
    
    
  </entry>
  
  <entry>
    <title>One idea of accessing Primary&#39;s buffer blocks</title>
    <link href="https://idrawone.github.io/2022/06/24/one-idea-of-accessing-primarys-buffer-blocks/"/>
    <id>https://idrawone.github.io/2022/06/24/one-idea-of-accessing-primarys-buffer-blocks/</id>
    <published>2022-06-24T08:00:00.000Z</published>
    <updated>2022-06-24T19:49:35.536Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-remote-access-buffer-blocks.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL is a great open source project for many reasons. One of the reasons I like it is because of the design of buffer blocks addressing. In this blog, I am going to explain a possible way to share a Primary’s buffer blocks with a Standby. If you want to know more about how buffer tag works, you can refer to my <a href="https://www.highgo.ca/2021/07/23/the-amazing-buffer-tag-in-postgresql/" target="_blank" rel="noopener">previous blog</a>.</p><h4 id="2-Primary-and-Standby"><a href="#2-Primary-and-Standby" class="headerlink" title="2. Primary and Standby"></a>2. Primary and Standby</h4><p>In Postgres, a Primary is an active database which accepts connections and performs read-write SQL operations; a Standby is a copy of the active database, and it also accepts connection but only for read-only SQL operations. Because the Standby needs to perform the ‘copy’ action in order to synchronize with Primary database, technically they are not exactly <code>equal</code> if a SQL query is time sensitive. Then, the question is can we let a Standby to be <code>equal</code> to a Primary? </p><p>The answer is <code>probably!</code>. I recently did some experimental tests to see if a Standby can access Primary’s buffer blocks in order to check the data which has not been replicated yet. The results is very positive.</p><h4 id="3-How-to-share-it"><a href="#3-How-to-share-it" class="headerlink" title="3. How to share it"></a>3. How to share it</h4><p>To achieve this experimental remote buffer blocks access, here are a few things I did:<br>On Primary side,</p><ol><li>start a simple dedicated TCP/IP server to listen for the buffer tag request from Standby</li><li>check if the buffer block in memory for received buffer tag</li><li>If found and dirty then sends the 8KB buffer block to Standby</li><li>If not found then simply answer not found</li></ol><p>On Standby side,</p><ol><li>add a simple TCP/IP client for buffer manager</li><li>send buffer tag request to Primary when buffer manager needs to load a data block from disk</li><li>add 8KB data block to shared buffer if received from Primary</li><li>load data block from disk if buffer block not found on Primary </li><li>skip buffer tag check to avoid use cashed data blocks</li></ol><p>With these basic changes, a Standby can access Primary’s buffer blocks and get the same query results even the data has not been replicated yet (in my experimental test, I actually also skip the head redo on Standby and let Standby to access Primary’s base cluster, disable the storage write actives).</p><h4 id="4-Summary"><a href="#4-Summary" class="headerlink" title="4. Summary"></a>4. Summary</h4><p>In this blog, I introduced a way to experiment the access of Primary’s buffer blocks, and hope this can be a topic for further study if someone want to learn PostgreSQL in deep.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-remote-access-buffer-blocks.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;head
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="primary" scheme="https://idrawone.github.io/categories/PostgreSQL/primary/"/>
    
      <category term="buffer" scheme="https://idrawone.github.io/categories/PostgreSQL/primary/buffer/"/>
    
      <category term="block" scheme="https://idrawone.github.io/categories/PostgreSQL/primary/buffer/block/"/>
    
      <category term="share" scheme="https://idrawone.github.io/categories/PostgreSQL/primary/buffer/block/share/"/>
    
      <category term="storage" scheme="https://idrawone.github.io/categories/PostgreSQL/primary/buffer/block/share/storage/"/>
    
    
  </entry>
  
  <entry>
    <title>How to use pg_rman do backup and restore for PostgreSQL</title>
    <link href="https://idrawone.github.io/2022/05/27/postgres-backup-restore-using-pg_rman/"/>
    <id>https://idrawone.github.io/2022/05/27/postgres-backup-restore-using-pg_rman/</id>
    <published>2022-05-27T08:00:00.000Z</published>
    <updated>2022-05-27T20:45:53.682Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-backup-restore-pg-rman.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL is a very popular open-source relational database management system, and it is widely used in many different production environments. To maintain the production environment always functioning, you need to a lot tools, and one of the tools must to have been backup and restore. This blog is going to introduce one backup and restore tools designed for Postgres, i.e. pg_rman.</p><h4 id="2-What-is-pg-rman"><a href="#2-What-is-pg-rman" class="headerlink" title="2. What is pg_rman"></a>2. What is pg_rman</h4><p>pg_ramn is a free utility program designed to backup and restore PostgreSQL database. It takes a physical online backup of whole database cluster, archive WALs, and server logs, and restore a specific backup when the Postgres is offline. pg_rman not only supports backup a Primary Postgres server, but also can get backup from a standby server. If you want to learn more about pg_rman, you can [check it out at] (<a href="https://github.com/ossc-db/pg_rman.git" target="_blank" rel="noopener">https://github.com/ossc-db/pg_rman.git</a>).</p><h4 id="3-1-How-to-setup"><a href="#3-1-How-to-setup" class="headerlink" title="3.1. How to setup"></a>3.1. How to setup</h4><p>Depends on the Postgres version you are running, in this blog, we will use the latest pg_rman tagged with <code>V1.3.14</code> to demonstrate the backup and restore on PostgreSQL 14.</p><p>Now, assume you have the PostgreSQL 14 installed properly, then you can follow below steps to set up the Postgres server.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir pgdata_rman</span><br><span class="line">initdb  -D pgdata_rman</span><br><span class="line"></span><br><span class="line">echo &quot;archive_mode &#x3D; on&quot; &gt;&gt; pgdata_rman&#x2F;postgresql.conf</span><br><span class="line">echo &quot;archive_command &#x3D; &#39;cp %p &#x2F;media&#x2F;david&#x2F;disk1&#x2F;archive&#x2F;%f&#39;&quot; &gt;&gt; pgdata_rman&#x2F;postgresql.conf</span><br><span class="line">echo &quot;log_directory &#x3D; &#39;&#x2F;media&#x2F;david&#x2F;disk1&#x2F;pglog&#39;&quot; &gt;&gt; pgdata_rman&#x2F;postgresql.conf</span><br><span class="line">pg_ctl -D pgdata_rman -l pglog&#x2F;logfile start</span><br></pre></td></tr></table></figure><p>Then, we can check out the source code from github</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;ossc-db&#x2F;pg_rman.git</span><br><span class="line">git checkout V1.3.14 -b local</span><br><span class="line">make clean &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>If no errors, then you have the pg_rman ready for the rest of the tests.</p><h5 id="3-2-Backup-and-restore"><a href="#3-2-Backup-and-restore" class="headerlink" title="3.2. Backup and restore"></a>3.2. Backup and restore</h5><p>Before running any backup and restore test, we need to initialize the backup for pg_rman to set the backup folder properly.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Initialize backup</span><br><span class="line">pg_rman init -B &#x2F;media&#x2F;david&#x2F;disk1&#x2F;backup_rman -D &#x2F;media&#x2F;david&#x2F;disk1&#x2F;pgdata_rman</span><br></pre></td></tr></table></figure><p>Once the backup folder has been initialized, then we can try to create a few tables and insert some data like below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -c &quot;CREATE TABLE abc (ID INT);&quot;</span><br><span class="line">psql -d postgres -c &quot;CREATE TABLE xyz (ID INT);&quot;</span><br><span class="line">psql -d postgres -c &quot;INSERT INTO abc VALUES (1);&quot;</span><br><span class="line">psql -d postgres -c &quot;INSERT INTO xyz VALUES (1);&quot;</span><br><span class="line">psql -d postgres -c &quot;SELECT count(*) from abc;&quot;</span><br><span class="line">psql -d postgres -c &quot;SELECT count(*) from xyz;&quot;</span><br></pre></td></tr></table></figure><p>Now, we can run our first backup with below commands,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#Do a backup</span><br><span class="line">pg_rman backup --backup-mode&#x3D;full --with-serverlog -B &#x2F;media&#x2F;david&#x2F;disk1&#x2F;backup_rman -D &#x2F;media&#x2F;david&#x2F;disk1&#x2F;pgdata_rman -A &#x2F;media&#x2F;david&#x2F;disk1&#x2F;archive -S &#x2F;media&#x2F;david&#x2F;disk1&#x2F;pglog -p 5432 -d postgres</span><br></pre></td></tr></table></figure><p>here, we do a full backup to include everything, and with all the basic information for this full backup. pg_rman will ask you to valid the backup after each backup is done. So, to verify the backup we can simple run the command,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#Validate</span><br><span class="line">pg_rman validate -B &#x2F;media&#x2F;david&#x2F;disk1&#x2F;backup_rman</span><br></pre></td></tr></table></figure><p>If the backup is valid, then we can insert some more data and run another backup. You can follow the steps below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -c &quot;INSERT INTO abc VALUES (2);&quot;</span><br><span class="line">psql -d postgres -c &quot;INSERT INTO xyz VALUES (2);&quot;</span><br><span class="line">psql -d postgres -c &quot;SELECT count(*) from abc;&quot;</span><br><span class="line">psql -d postgres -c &quot;SELECT count(*) from xyz;&quot;</span><br><span class="line"></span><br><span class="line">pg_rman backup --backup-mode&#x3D;full --with-serverlog -B &#x2F;media&#x2F;david&#x2F;disk1&#x2F;backup_rman -D &#x2F;media&#x2F;david&#x2F;disk1&#x2F;pgdata_rman -A &#x2F;media&#x2F;david&#x2F;disk1&#x2F;archive -S &#x2F;media&#x2F;david&#x2F;disk1&#x2F;pglog -p 5432 -d postgres </span><br><span class="line"></span><br><span class="line">#Validate</span><br><span class="line">pg_rman validate -B &#x2F;media&#x2F;david&#x2F;disk1&#x2F;backup_rman</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### Insert more data</span><br><span class="line">psql -d postgres -c &quot;INSERT INTO abc VALUES (3);&quot;</span><br><span class="line">psql -d postgres -c &quot;INSERT INTO xyz VALUES (3);&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ pg_rman show -B &#x2F;media&#x2F;david&#x2F;disk1&#x2F;backup_rman</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"> StartTime           EndTime              Mode    Size   TLI  Status </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">2022-05-27 13:05:30  2022-05-27 13:05:32  FULL    51MB     1  OK</span><br><span class="line">2022-05-27 13:05:28  2022-05-27 13:05:30  FULL    51MB     1  OK</span><br></pre></td></tr></table></figure><p>Now, we have two full backups first one has one record in each table, the second one has two records in each table, and the second backup we have inserted the third record to each table. If you query these two tables now, you can see below results.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ psql -d postgres -c &quot;SELECT count(*) from abc;&quot;</span><br><span class="line"> count </span><br><span class="line">-------</span><br><span class="line">     3</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">$ psql -d postgres -c &quot;SELECT count(*) from xyz;&quot;</span><br><span class="line"> count </span><br><span class="line">-------</span><br><span class="line">     3</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><p>Assume we made a mistake on the third operation, and let’s stop the PostgreSQL server and try to restore back to the second backup stage.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Stop</span><br><span class="line">pg_ctl -D pgdata_rman -l pglog&#x2F;logfile stop</span><br><span class="line"> </span><br><span class="line">#Restore to target time</span><br><span class="line">pg_rman restore -B &#x2F;media&#x2F;david&#x2F;disk1&#x2F;backup_rman -D &#x2F;media&#x2F;david&#x2F;disk1&#x2F;pgdata_rman --recovery-target-time&#x3D;&quot;2022-05-27 13:05:32&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Restart</span><br><span class="line">pg_ctl -D pgdata_rman -l pglog&#x2F;logfile start</span><br><span class="line">$ psql -d postgres -c &quot;SELECT count(*) from abc;&quot;</span><br><span class="line"> count </span><br><span class="line">-------</span><br><span class="line">     2</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">$ psql -d postgres -c &quot;SELECT count(*) from xyz;&quot;</span><br><span class="line"> count </span><br><span class="line">-------</span><br><span class="line">     2</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><p>As you can see we back to the second backup stage, and each table has only two records.</p><h5 id="3-3-Anything-is-missing"><a href="#3-3-Anything-is-missing" class="headerlink" title="3.3. Anything is missing"></a>3.3. Anything is missing</h5><p>The pg_rman is a great free open-source tool for PostgreSQL users to backup and restore the database, however, there is one feature missed at this moment, i.e. targeted table restore. as a database administrator, one specific table restore can help reduce the risk on a production enrolment if only a single table need to be restored is a clear action.</p><h4 id="4-Summary"><a href="#4-Summary" class="headerlink" title="4. Summary"></a>4. Summary</h4><p>In this blog, we discussed the basic of PostgreSQL backup restore using a free open-source tool, i.e. pg_rman, and hope this piece information can help if you are looking for a free backup and restore solution for PostgreSQL.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-backup-restore-pg-rman.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlin
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="backup" scheme="https://idrawone.github.io/categories/PostgreSQL/backup/"/>
    
      <category term="restore" scheme="https://idrawone.github.io/categories/PostgreSQL/backup/restore/"/>
    
      <category term="incremental" scheme="https://idrawone.github.io/categories/PostgreSQL/backup/restore/incremental/"/>
    
    
  </entry>
  
  <entry>
    <title>global deadlock in a distributed database cluster</title>
    <link href="https://idrawone.github.io/2022/04/29/global-deadlock-detection/"/>
    <id>https://idrawone.github.io/2022/04/29/global-deadlock-detection/</id>
    <published>2022-04-29T08:00:00.000Z</published>
    <updated>2022-04-29T20:11:28.444Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-global-deadlock.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>Nowadays, supporting distributed transactions is a typical requirement for many use cases, however, the global deadlock detection is one of the key challenging issues if you plan to use PostgreSQL to setup a distributed database solution. There are many discussions about global deadlock, but this blog will provide you a step-by-step procedure about how to create such a global deadlock and share some thoughts based on personal experience.</p><h4 id="2-Deadlock"><a href="#2-Deadlock" class="headerlink" title="2. Deadlock"></a>2. Deadlock</h4><p>First of all, the basic concept of a deadlock is that Process A is trying to acquire Lock2 while it is holding Lock1 and Process B is trying to acquire Lock1 while it is holding Lock2 at the same moment. In this situation, Either Process A or Process B can’t not continue and they will wait for each other forever. Since PostgreSQL allows user transactions to request locks in any order, therefore, this kind of deadlock can happen. When this kind of deadlock is happening, there is no <code>win-win</code> solution, the only way to solve this locking issue is that one of the transactions has to abort and release the lock. </p><p>To address this deadlock issue, PostgreSQL has two key things built-in: 1) try to avoid the deadlock by having a lock waiting queue and sort the locks requests to avoid potential deadlock; 2) requires the transaction to abort if a deadlock detected; By having these two key designs, a deadlock happens within a single PostgreSQL server can be easily resolved. For more details information about the deadlock, you can refer to the official document at <a href="https://github.com/postgres/postgres/blob/master/src/backend/storage/lmgr/README" target="_blank" rel="noopener">src/backend/storage/lmgr/README</a>. In this blog, we call this kind of deadlock as local deadlock compared with the one (global deadlock) we are going to discuss more below.</p><p>The reason PostgreSQL can detect this local deadlock is because PostgreSQL knows all the locks information, and it can easily find a lock waiting cycle. In the source code, PostgreSQL defines a generic LOCKTAG data struct to let user transaction fill in different lock information. Here is how the LOCKTAG data struct is defined in PostgreSQL.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef struct LOCKTAG</span><br><span class="line">&#123;</span><br><span class="line">    uint32 locktag_field1; &#x2F;* a 32-bit ID field *&#x2F;</span><br><span class="line">    uint32 locktag_field2; &#x2F;* a 32-bit ID field *&#x2F;</span><br><span class="line">    uint32 locktag_field3; &#x2F;* a 32-bit ID field *&#x2F;</span><br><span class="line">    uint16 locktag_field4; &#x2F;* a 16-bit ID field *&#x2F;</span><br><span class="line">    uint8 locktag_type; &#x2F;* see enum LockTagType *&#x2F;</span><br><span class="line">    uint8 locktag_lockmethodid; &#x2F;* lockmethod indicator *&#x2F;</span><br><span class="line">&#125; LOCKTAG;</span><br></pre></td></tr></table></figure><p>In PostgreSQL, there are about 10 Micros defined to address different locks in different use cases, and you can find the details by searching below key info.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#define SET_LOCKTAG_RELATION(locktag,dboid,reloid)</span><br><span class="line">#define SET_LOCKTAG_RELATION_EXTEND(locktag,dboid,reloid)</span><br><span class="line">#define SET_LOCKTAG_DATABASE_FROZEN_IDS(locktag,dboid)</span><br><span class="line">#define SET_LOCKTAG_PAGE(locktag,dboid,reloid,blocknum)</span><br><span class="line">#define SET_LOCKTAG_TUPLE(locktag,dboid,reloid,blocknum,offnum)</span><br><span class="line">#define SET_LOCKTAG_TRANSACTION(locktag,xid)</span><br><span class="line">#define SET_LOCKTAG_VIRTUALTRANSACTION(locktag,vxid)</span><br><span class="line">#define SET_LOCKTAG_SPECULATIVE_INSERTION(locktag,xid,token)</span><br><span class="line">#define SET_LOCKTAG_OBJECT(locktag,dboid,classoid,objoid,objsubid)</span><br><span class="line">#define SET_LOCKTAG_ADVISORY(locktag,id1,id2,id3,id4)</span><br></pre></td></tr></table></figure><p>In a distributed PostgreSQL deployment environment (typically, one or more Coordinator Nodes plus multiple Data Nodes), a deadlock can happen globally, like the one described in <a href="https://www.citusdata.com/blog/2017/08/31/databases-and-distributed-deadlocks-a-faq" target="_blank" rel="noopener">Databases and Distributed Deadlocks: A FAQ</a>. A deadlock triggered by Coordinator Node and caused multiple Data Nodes to wait for each other is called global deadlock or distributed deadlock. In this case, the original PostgreSQL can’t solve this problem as each Data Node doesn’t take this situation as a deadlock.</p><h4 id="3-How-to-create-a-global-deadlock"><a href="#3-How-to-create-a-global-deadlock" class="headerlink" title="3. How to create a global deadlock"></a>3. How to create a global deadlock</h4><p>To better understand the global deadlock issue, we can create a global deadlock by following below steps. First, you need to install postgres_fdw extension to setup a simple distributed database cluster by running below commands.</p><h5 id="3-1-Setup-a-simple-distributed-PostgreSQL-database-cluster"><a href="#3-1-Setup-a-simple-distributed-PostgreSQL-database-cluster" class="headerlink" title="3.1. Setup a simple distributed PostgreSQL database cluster"></a>3.1. Setup a simple distributed PostgreSQL database cluster</h5><p>Assume you have installed PostgreSQL or built your own binaries, and then initialize four PostgreSQL servers like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">initdb -D &#x2F;tmp&#x2F;pgdata_cn1 -U $USER</span><br><span class="line">initdb -D &#x2F;tmp&#x2F;pgdata_cn2 -U $USER</span><br><span class="line">initdb -D &#x2F;tmp&#x2F;pgdata_dn1 -U $USER</span><br><span class="line">initdb -D &#x2F;tmp&#x2F;pgdata_dn2 -U $USER</span><br></pre></td></tr></table></figure><p>For each PostgreSQL database, edit the configuration files to set different port and cluster name. In this case, we have two Coordinator Nodes sitting on Port 50001 and 50002, and two Data Nodes listening on 60001 and 60002.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;tmp&#x2F;pgdata_dn1&#x2F;postgresql.conf</span><br><span class="line">  port &#x3D; 60001</span><br><span class="line">  cluster_name &#x3D; &#39;dn1&#39;</span><br><span class="line">vim &#x2F;tmp&#x2F;pgdata_dn2&#x2F;postgresql.conf</span><br><span class="line">  port &#x3D; 60002</span><br><span class="line">  cluster_name &#x3D; &#39;dn2&#39;</span><br><span class="line">vim &#x2F;tmp&#x2F;pgdata_cn1&#x2F;postgresql.conf</span><br><span class="line">  port &#x3D; 50001</span><br><span class="line">  cluster_name &#x3D; &#39;cn1&#39;</span><br><span class="line">vim &#x2F;tmp&#x2F;pgdata_cn2&#x2F;postgresql.conf</span><br><span class="line">  port &#x3D; 50002</span><br><span class="line">  cluster_name &#x3D; &#39;cn2&#39;</span><br></pre></td></tr></table></figure><p>Start all PostgreSQL servers.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pg_ctl -D &#x2F;tmp&#x2F;pgdata_cn1 -l &#x2F;tmp&#x2F;logfile_cn1 start</span><br><span class="line">pg_ctl -D &#x2F;tmp&#x2F;pgdata_cn2 -l &#x2F;tmp&#x2F;logfile_cn2 start</span><br><span class="line">pg_ctl -D &#x2F;tmp&#x2F;pgdata_dn1 -l &#x2F;tmp&#x2F;logfile_dn1 start</span><br><span class="line">pg_ctl -D &#x2F;tmp&#x2F;pgdata_dn2 -l &#x2F;tmp&#x2F;logfile_dn2 start</span><br></pre></td></tr></table></figure><h5 id="3-2-Setup-the-Data-Nodes"><a href="#3-2-Setup-the-Data-Nodes" class="headerlink" title="3.2. Setup the Data Nodes"></a>3.2. Setup the Data Nodes</h5><p>Run below commands to create table t on two Data Nodes,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -U $USER -p 60001 -c &quot;create table t(a int, b text);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 60002 -c &quot;create table t(a int, b text);&quot;</span><br></pre></td></tr></table></figure><h5 id="3-3-Setup-the-Coordinator-Nodes"><a href="#3-3-Setup-the-Coordinator-Nodes" class="headerlink" title="3.3. Setup the Coordinator Nodes"></a>3.3. Setup the Coordinator Nodes</h5><p>Coordinator Node setup is a little complicated. Here, we are using the postgres_fdw extension to create a simple distributed PostgreSQL database cluster, therefore, you need to follow below steps to setup the postgres_fdw extension, user mappings, and foreign servers and tables.<br>Setup the extension, foreign servers, user mappings, and tables on Coordinator Node 1.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create extension postgres_fdw;&quot;</span><br><span class="line"></span><br><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create server s1 foreign data wrapper postgres_fdw options (dbname &#39;postgres&#39;, host &#39;127.0.0.1&#39;, port &#39;60001&#39;);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create server s2 foreign data wrapper postgres_fdw options (dbname &#39;postgres&#39;, host &#39;127.0.0.1&#39;, port &#39;60002&#39;);&quot;</span><br><span class="line"></span><br><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create user mapping for $USER server s1 options( user &#39;$USER&#39;);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create user mapping for $USER server s2 options( user &#39;$USER&#39;);&quot;</span><br><span class="line"></span><br><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create table t(a int, b text) partition by range(a);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create foreign table t_s1 partition of t for values from (1000) to (1999) server s1 options(schema_name &#39;public&#39;, table_name &#39;t&#39;);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;create foreign table t_s2 partition of t for values from (2000) to (2999) server s2 options(schema_name &#39;public&#39;, table_name &#39;t&#39;);&quot;</span><br></pre></td></tr></table></figure><p>Setup the extension, foreign servers, user mappings, and tables on Coordinator Node 2.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create extension postgres_fdw;&quot;</span><br><span class="line"></span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create server s1 foreign data wrapper postgres_fdw options (dbname &#39;postgres&#39;, host &#39;127.0.0.1&#39;, port &#39;60001&#39;);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create server s2 foreign data wrapper postgres_fdw options (dbname &#39;postgres&#39;, host &#39;127.0.0.1&#39;, port &#39;60002&#39;);&quot;</span><br><span class="line"></span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create user mapping for $USER server s1 options( user &#39;$USER&#39;);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create user mapping for $USER server s2 options( user &#39;$USER&#39;);&quot;</span><br><span class="line"></span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create table t(a int, b text) partition by range(a);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create foreign table t_s1 partition of t for values from (1000) to (1999) server s1 options(schema_name &#39;public&#39;, table_name &#39;t&#39;);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;create foreign table t_s2 partition of t for values from (2000) to (2999) server s2 options(schema_name &#39;public&#39;, table_name &#39;t&#39;);&quot;</span><br></pre></td></tr></table></figure><h5 id="3-4-Create-a-global-deadlock"><a href="#3-4-Create-a-global-deadlock" class="headerlink" title="3.4. Create a global deadlock"></a>3.4. Create a global deadlock</h5><p>Now, after you have setup this simple distributed PostgreSQL database cluster, you can run below commands in two different psql sessions/consoles to create a global deadlock.</p><p>First, insert one tuple on each Data Node.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -U $USER -p 50001 -c &quot;insert into t values(1001, &#39;session-1&#39;);&quot;</span><br><span class="line">psql -d postgres -U $USER -p 50002 -c &quot;insert into t values(2001, &#39;session-2&#39;);&quot;</span><br></pre></td></tr></table></figure><p>Second, start two different psql consoles and run the tuple update based on below sequence indicated by (x). </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -U $USER -p 50001</span><br><span class="line">begin;</span><br><span class="line">update t set b &#x3D; &#39;session-11&#39; where a &#x3D; 1001;     (1)</span><br><span class="line"></span><br><span class="line">update t set b &#x3D; &#39;session-11&#39; where a &#x3D; 2001;     (4)</span><br><span class="line"></span><br><span class="line">psql -d postgres -U $USER -p 50002</span><br><span class="line">begin;</span><br><span class="line">update t set b &#x3D; &#39;session-22&#39; where a &#x3D; 2001;     (2)</span><br><span class="line"></span><br><span class="line">update t set b &#x3D; &#39;session-22&#39; where a &#x3D; 1001;     (3)</span><br></pre></td></tr></table></figure><p>After, the update query (4) has been executed, you will end up like below waiting situation, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# begin;</span><br><span class="line">BEGIN</span><br><span class="line">postgres&#x3D;*# update t set b &#x3D; &#39;session-11&#39; where a &#x3D; 1001;</span><br><span class="line">UPDATE 1</span><br><span class="line">postgres&#x3D;*# update t set b &#x3D; &#39;session-11&#39; where a &#x3D; 2001;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">postgres&#x3D;# begin;</span><br><span class="line">BEGIN</span><br><span class="line">postgres&#x3D;*# update t set b &#x3D; &#39;session-22&#39; where a &#x3D; 2001;</span><br><span class="line">UPDATE 1</span><br><span class="line">postgres&#x3D;*# </span><br><span class="line">postgres&#x3D;*# update t set b &#x3D; &#39;session-22&#39; where a &#x3D; 1001;</span><br></pre></td></tr></table></figure><p>If you grep postgres process using below command, and you will find two separate postgres from two different Data Node are in <code>UPDATE waiting</code>, and this will last forever.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">david:postgres$ ps -ef |grep postgres |grep waiting</span><br><span class="line">david     2811  2768  0 11:15 ?        00:00:00 postgres: dn1: david postgres 127.0.0.1(45454) UPDATE waiting</span><br><span class="line">david     2812  2740  0 11:15 ?        00:00:00 postgres: dn2: david postgres 127.0.0.1(55040) UPDATE waiting</span><br></pre></td></tr></table></figure><p>When the global deadlock is happening above, you can check the waiting process in details by gdb attaching to any of them. If you dig into the source code, you can find out that this global deadlock is actually related with <code>SET_LOCKTAG_TRANSACTION</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#define SET_LOCKTAG_TRANSACTION(locktag,xid) \</span><br><span class="line">((locktag).locktag_field1 &#x3D; (xid), \</span><br><span class="line">(locktag).locktag_field2 &#x3D; 0, \</span><br><span class="line">(locktag).locktag_field3 &#x3D; 0, \</span><br><span class="line">(locktag).locktag_field4 &#x3D; 0, \</span><br><span class="line">(locktag).locktag_type &#x3D; LOCKTAG_TRANSACTION, \</span><br><span class="line">(locktag).locktag_lockmethodid &#x3D; DEFAULT_LOCKMETHOD)</span><br></pre></td></tr></table></figure><h4 id="4-How-to-solve-the-problem"><a href="#4-How-to-solve-the-problem" class="headerlink" title="4. How to solve the problem"></a>4. How to solve the problem</h4><p>There are many discussions about global deadlock detection, like the one mentioned above <a href="https://www.citusdata.com/blog/2017/08/31/databases-and-distributed-deadlocks-a-faq" target="_blank" rel="noopener">Databases and Distributed Deadlocks: A FAQ</a>, which has some recommendations like <code>Predicate Locks</code> and <code>Wait-Die or Wound-Wait</code><br>And a very detailed one about how to detect a global deadlock at <a href="https://www.enterprisedb.com/blog/postgresql-and-deadlock-detection-spanning-multiple-databases" target="_blank" rel="noopener">PostgreSQL and Deadlock Detection Spanning Multiple Databases</a>, which recommends using a <code>Global Wait-for-Graph</code> to detect it.  </p><p>Another approach is that instead of avoid the problems, or using wait-for-graph to find a cycle, we can also consider to have an independent program or even a simple database to help check if there is a global deadlock. Sometimes, the issue is hard to solve is because it is hard to get all the information. The reason we can easily see a deadlock caused by one or multiple Coordinator Nodes is because we take one step back and look at the situation as a whole picture.</p><h4 id="5-Summary"><a href="#5-Summary" class="headerlink" title="5. Summary"></a>5. Summary</h4><p>In this blog, we discussed the basic global deadlock issue, setup a simple distributed database cluster using postgres_fdw and demonstrated a global deadlock. We also discussed different approaches to either avoid this global deadlock or solve it in different ways.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-global-deadlock.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="deadlock" scheme="https://idrawone.github.io/categories/PostgreSQL/deadlock/"/>
    
      <category term="global" scheme="https://idrawone.github.io/categories/PostgreSQL/deadlock/global/"/>
    
      <category term="fdw" scheme="https://idrawone.github.io/categories/PostgreSQL/deadlock/global/fdw/"/>
    
      <category term="distributed" scheme="https://idrawone.github.io/categories/PostgreSQL/deadlock/global/fdw/distributed/"/>
    
      <category term="cluster" scheme="https://idrawone.github.io/categories/PostgreSQL/deadlock/global/fdw/distributed/cluster/"/>
    
    
  </entry>
  
  <entry>
    <title>parallel commit in postgres fdw</title>
    <link href="https://idrawone.github.io/2022/03/31/parallel-abort-in-postgres-fdw/"/>
    <id>https://idrawone.github.io/2022/03/31/parallel-abort-in-postgres-fdw/</id>
    <published>2022-03-31T08:00:00.000Z</published>
    <updated>2022-04-05T18:19:37.909Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-parallel-commit.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL is one of the greatest open source databases, not only because of the extensibility and SQL compliance but also the evolution of new features. For example, in postgres_fdw, there is a new feature <code>parallel commit</code> has been added into the main branch and will be released in PG15. This blog is for a quick taste of this new feature.</p><h4 id="2-how-parallel-commit-works"><a href="#2-how-parallel-commit-works" class="headerlink" title="2. how parallel commit works"></a>2. how parallel commit works</h4><p>If you are a PostgreSQL database developer or if your internal database is built based on PostgreSQL database, and especially you have some applications which are related with the extension <code>postgres_fdw</code>, then you might wnat to take a look at this <code>parallel commit</code> feature. This new feature is committed just a month ago. It may help you on solving some performance issues, or as a reference if you are planning to build any parallel features on a postgres_fdw based solution. Here is the details about this <code>parallel commit</code> for postgres_fdw.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">commit 04e706d4238f98a98e1c0b1a02db9d4280b96f04</span><br><span class="line">Author: Etsuro Fujita &lt;efujita@postgresql.org&gt;</span><br><span class="line">Date:   Thu Feb 24 14:30:00 2022 +0900</span><br><span class="line"></span><br><span class="line">    postgres_fdw: Add support for parallel commit.</span><br><span class="line">    </span><br><span class="line">    postgres_fdw commits remote (sub)transactions opened on remote server(s)</span><br><span class="line">    in a local (sub)transaction one by one when the local (sub)transaction</span><br><span class="line">    commits.  This patch allows it to commit the remote (sub)transactions in</span><br><span class="line">    parallel to improve performance.  This is enabled by the server option</span><br><span class="line">    &quot;parallel_commit&quot;.  The default is false.</span><br></pre></td></tr></table></figure><p>By default, this parallel commit feature is turned off. If you want to try it you can simply turn it on by </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER SERVER loopback OPTIONS (ADD parallel_commit &#39;true&#39;);</span><br></pre></td></tr></table></figure><p>Once this <code>parallel commit</code> option is on for those foreign servers involved in a local transaction and when this local transaction commits, the opened remote transaction on those foreign servers will be committed in parallel. By providing this option, PostgreSQL community expects some performance improvement when multiple foreign servers involved in a transaction. This parallel commit feature can be useful for some applications on distributed PostgreSQL database clusters using postgre_fdw.</p><p>To verify the performance improvement, you can simply test it for before and after using below commands,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -p 5432 -Atq &lt;&lt;EOT</span><br><span class="line">\timing on</span><br><span class="line">BEGIN;</span><br><span class="line">SAVEPOINT s;</span><br><span class="line">INSERT INTO ft1 VALUES (10, 10);</span><br><span class="line">INSERT INTO ft2 VALUES (20, 20);</span><br><span class="line">RELEASE SAVEPOINT s;</span><br><span class="line">COMMIT;</span><br><span class="line">EOT</span><br></pre></td></tr></table></figure><p>According to the initial discussion for this <code>parallel commit</code> feature, below are some performance numbers for your reference.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">* RELEASE</span><br><span class="line">  parallel_commit&#x3D;0: 0.385 ms</span><br><span class="line">  parallel_commit&#x3D;1: 0.221 ms</span><br><span class="line"></span><br><span class="line">* COMMIT</span><br><span class="line">  parallel_commit&#x3D;0: 1.660 ms</span><br><span class="line">  parallel_commit&#x3D;1: 0.861 ms</span><br></pre></td></tr></table></figure><p>To disable this feature, you can run a command like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER SERVER loopback OPTIONS (DROP parallel_commit);</span><br></pre></td></tr></table></figure><h4 id="3-Summary"><a href="#3-Summary" class="headerlink" title="3. Summary"></a>3. Summary</h4><p>In this blog, we discussed the parallel commit feature recently added to postgres_fdw. When you apply this feature to your production servers you might need to be careful as it is mentioned in the document, <code>this option might increase the remote server’s load when the local (sub)transaction commits</code>. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-parallel-commit.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="parallel" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/"/>
    
      <category term="commit" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/commit/"/>
    
      <category term="fdw" scheme="https://idrawone.github.io/categories/PostgreSQL/parallel/commit/fdw/"/>
    
    
  </entry>
  
  <entry>
    <title>A snippet to acquire a Lightweight lock</title>
    <link href="https://idrawone.github.io/2022/02/28/acquire-a-lightweight-lock-in-deep/"/>
    <id>https://idrawone.github.io/2022/02/28/acquire-a-lightweight-lock-in-deep/</id>
    <published>2022-02-28T08:00:00.000Z</published>
    <updated>2022-02-28T22:15:33.465Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-lwlock.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>Recently, I was working on an internal issue related with buffer manager in PostgreSQL, and I saw a typical use of the Lightweight lock in buffer manager like below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1   INIT_BUFFERTAG(newTag, smgr_rnode.node, forkNum, blockNum);</span><br><span class="line">2   newHash &#x3D; BufTableHashCode(&amp;newTag);</span><br><span class="line">3   newPartitionLock &#x3D; BufMappingPartitionLock(newHash);</span><br><span class="line">4   LWLockAcquire(newPartitionLock, LW_SHARED);</span><br><span class="line">5   buf_id &#x3D; BufTableLookup(&amp;newTag, newHash);</span><br><span class="line">6   LWLockRelease(newPartitionLock);</span><br></pre></td></tr></table></figure><p>Basically, when the buffer manger needs to access a buffer block using buffer tag, it will have to acquire a lightweight lock in either shared or exclusive mode, then find the buffer block and then release the lightweight lock.</p><p>Since the buffer manager is shared among multiple backends and a buffer block is accessed very often, this snippet has to be designed to protect the data consistency for read and write and no impact on performance.</p><p>This blog will explain how this snippet works in PostgreSQL and emphasize a little bit more on the lightweight lock acquire.</p><h4 id="2-how-to-use-snapshot-public-functions"><a href="#2-how-to-use-snapshot-public-functions" class="headerlink" title="2. how to use snapshot public functions"></a>2. how to use snapshot public functions</h4><p>Now, let’s go through the snippet above line by line.<br>The first line simply uses a Macro to initialize a buffer tag using those five numbers. Here, <code>INIT_BUFFERTAG</code> is a macro defines like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define INIT_BUFFERTAG(a,xx_rnode,xx_forkNum,xx_blockNum) \</span><br><span class="line">( \</span><br><span class="line">    (a).rnode &#x3D; (xx_rnode), \</span><br><span class="line">    (a).forkNum &#x3D; (xx_forkNum), \</span><br><span class="line">    (a).blockNum &#x3D; (xx_blockNum) \</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>After the macro call, the newTag has been assigned with those five numbers, i.e., table space number, database number, relation number, fork number (data, fsm or visibility map etc), and the block number (each block is 8k) within the actual file;</p><p>The second line <code>newHash = BufTableHashCode(&amp;newTag);</code> generates a hash number based on the buffer tag. Where, The function <code>BufTableHashCode</code> computes the hash code associated with given buffer tag in the global shared buffer hash table, and return a unsigned integer.</p><p>The third line retrieves a partition lock within the locks pool used an unsigned integer hash number mod the total number of partition locks (default 128).<br>Again, the function BufMappingPartitionLock is a predefined macro and is showing below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#define BufMappingPartitionLock(hashcode) \</span><br><span class="line">    (&amp;MainLWLockArray[BUFFER_MAPPING_LWLOCK_OFFSET + \</span><br><span class="line">        BufTableHashPartition(hashcode)].lock)</span><br></pre></td></tr></table></figure><p>It will return a lock in <code>MainLWLockArray</code> lightweight locks array. Where the <code>BUFFER_MAPPING_LWLOCK_OFFSET</code> is number of dedicated lightweight locks defined in <code>lwlocknames.txt</code> file. The number of partition lightweight locks are 128 locks located after these dedicated locks defined in these main lightweight locks array. Here, the macro <code>BufTableHashPartition</code> is to make sure it always returns a lock in the partition locks pool for any given hash number.</p><p>The fourth line to is to acquire the lightweight lock with a very efficient algorithm. This <code>LWLockAcquire</code> will help return a lightweight lock in the specified mode, i.e., shared (for read only operation) or exclusive (for write operation). This function returns <code>true</code> if the lock was available immediately, <code>false</code> if it has to sleep and wait.<br>Inside this <code>LWLockAcquire</code>, there are many considerations, but I want to emphasize one smart c implementation in the function <code>LWLockAttemptLock</code>, and I believe you can use this similar idea as a design pattern to design other CPU and Memory sensitive logic in your applications.<br>As you can see below is the key implementation of this shared and exclusive lock.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if (mode &#x3D;&#x3D; LW_EXCLUSIVE)</span><br><span class="line">&#123;</span><br><span class="line">    lock_free &#x3D; (old_state &amp; LW_LOCK_MASK) &#x3D;&#x3D; 0;</span><br><span class="line">    if (lock_free)</span><br><span class="line">        desired_state +&#x3D; LW_VAL_EXCLUSIVE;</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">    lock_free &#x3D; (old_state &amp; LW_VAL_EXCLUSIVE) &#x3D;&#x3D; 0;</span><br><span class="line">    if (lock_free)</span><br><span class="line">        desired_state +&#x3D; LW_VAL_SHARED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This implementation involves three macros: <code>LW_LOCK_MASK</code>, <code>LW_VAL_EXCLUSIVE</code> and <code>LW_VAL_SHARED</code>, where <code>LW_LOCK_MASK</code> is a consistent number, i.e., <code>0xFFFFFF</code>, used in bit operation. If any lower 24 bits has a one, then it means the lock is held in either shared or exclusive mode. In other words, someone is still reading the data, if you want the update the data, please wait. If the all lower 24 bits are zeros, then it will be assigned to a big number <code>LW_VAL_EXCLUSIVE</code>, i.e., <code>0x800000</code>, which indicates the lock is used as exclusive. If you want to acquire this lock in shared mode, then as long as the lock is not held by someone in exclusive mode and it is not held more than <code>0x7FFFFF</code>, then you can acquire one shared lock and the number of usages will be simple increase by one, i.e., <code>LW_VAL_SHARED</code>. Of course, how many shared locks can be held at the same time is limited by other parameters.</p><p>Here is the definition of these three macros.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#define LW_LOCK_MASK                ((uint32) ((1 &lt;&lt; 25)-1))</span><br><span class="line">#define LW_VAL_EXCLUSIVE            ((uint32) 1 &lt;&lt; 24)</span><br><span class="line">#define LW_VAL_SHARED               1</span><br></pre></td></tr></table></figure><p>The fifth line looks up the buffer id using the given buffer tag and hash code.<br>Once you have acquired the lock, work on the operations immediately depends on your application, but keep in mind the lightweight lock is designed to be held only in a short period. </p><p>The sixth line release the lock back to the partition lock pool.<br>After you finished your operations either read or write, then use this LWLockRelease function to release the lock as soon as you can, so you don’t block other processes too long especially if there is a write operation need to acquire this lock in exclusive mode. </p><h4 id="3-Summary"><a href="#3-Summary" class="headerlink" title="3. Summary"></a>3. Summary</h4><p>In this blog, we discussed a typical snippet which uses a lightweight lock in PostgreSQL, and explained one of the most efficient piece of code implemented for Lightweight lock in PostgreSQL, i.e., LWLockAcquire. I hope this can help when you want to achieve a similar result in your own design.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-lwlock.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. Ove
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="Lightweight lock" scheme="https://idrawone.github.io/categories/PostgreSQL/Lightweight-lock/"/>
    
      <category term="performance" scheme="https://idrawone.github.io/categories/PostgreSQL/Lightweight-lock/performance/"/>
    
      <category term="shared" scheme="https://idrawone.github.io/categories/PostgreSQL/Lightweight-lock/performance/shared/"/>
    
      <category term="exclusive" scheme="https://idrawone.github.io/categories/PostgreSQL/Lightweight-lock/performance/shared/exclusive/"/>
    
    
  </entry>
  
  <entry>
    <title>Transaction ID and Snapshot information functions</title>
    <link href="https://idrawone.github.io/2022/01/28/transaction-id-and-snapshot-information-functions/"/>
    <id>https://idrawone.github.io/2022/01/28/transaction-id-and-snapshot-information-functions/</id>
    <published>2022-01-28T08:00:00.000Z</published>
    <updated>2022-01-28T23:54:23.105Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-snapshot.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>I recently investigated one internal issue which was related with snapshot and found there were some changes on transaction id and snapshot information functions in PostgreSQL. Here, I am trying to share what I have learned. </p><p>Before PostgreSQL 13, all transaction id and snapshot related public functions were named as txid_xxx_yyy, such as,<br>txid_current(), which returns the current toplevel transaction ID.<br>txid_current_if_assigned(), which is similar to txid_current() but doesn’t assign a new xid if there isn’t one.<br>txid_current_snapshot(), which returns current snapshot in txid format with only top-transaction XIDs.<br>txid_status(), which reports the status of a recent transaction ID.</p><p>Started from PostgreSQL 13, the naming convention of these snapshot public functions txid_xxx_yyy has been changed to something like, pg_xxx_xact_yyy correspondingly. For example, txid_current() is replaced by pg_current_xact_id(), and txid_current_if_assigned() has been renamed to pg_current_xact_id_if_assigned(), etc.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">commit 4c04be9b05ad2ec5acd27c3417bf075c13cab134 (HEAD -&gt; xid8funcs)</span><br><span class="line">Author: Thomas Munro &lt;tmunro@postgresql.org&gt;</span><br><span class="line">Date:   Tue Apr 7 11:33:56 2020 +1200</span><br><span class="line"></span><br><span class="line">    Introduce xid8-based functions to replace txid_XXX.</span><br><span class="line">    </span><br><span class="line">    The txid_XXX family of fmgr functions exposes 64 bit transaction IDs to</span><br><span class="line">    users as int8.  Now that we have an SQL type xid8 for FullTransactionId,</span><br><span class="line">    define a new set of functions including pg_current_xact_id() and</span><br><span class="line">    pg_current_snapshot() based on that.  Keep the old functions around too,</span><br><span class="line">    for now.</span><br><span class="line">    </span><br><span class="line">    It&#39;s a bit sneaky to use the same C functions for both, but since the</span><br><span class="line">    binary representation is identical except for the signedness of the</span><br><span class="line">    type, and since older functions are the ones using the wrong signedness,</span><br><span class="line">    and since we&#39;ll presumably drop the older ones after a reasonable period</span><br><span class="line">    of time, it seems reasonable to switch to FullTransactionId internally</span><br><span class="line">    and share the code for both.</span><br></pre></td></tr></table></figure><p>Introduce xid8-based functions to replace txid_XXX.</p><p>An official documentation regarding these functions can be found at <a href="https://www.postgresql.org/docs/14/functions-info.html" target="_blank" rel="noopener">Transaction ID and Snapshot Information Functions</a> at Table 9.76. Transaction ID and Snapshot Information Functions.</p><h4 id="2-how-to-use-snapshot-public-functions"><a href="#2-how-to-use-snapshot-public-functions" class="headerlink" title="2. how to use snapshot public functions"></a>2. how to use snapshot public functions</h4><p>Since PostgreSQL has provided us so many public functions for end users to check the transaction id and snapshot information in details, sometimes, we need to know how to use these funtions in a simple query to have better understanding of the ongoing transactions, visibilities, and snapshots. Here, I have some simple examples to share.</p><p>first, let’s create a simple table like below,<br>postgres=# create table tbl01 (a int, b text);<br>CREATE TABLE</p><p>to find out the current transaction id, you can simply do <code>select pg_current_xact_id();</code> in a psql console,<br>postgres=# select pg_current_xact_id();<br> pg_current_xact_id </p><hr><pre><code>734</code></pre><p>(1 row)<br>Here, the number 734 is the current transaction id. Each time, when you run such a query, the transaction id will increase by one.</p><p>postgres=# select pg_current_xact_id();<br> pg_current_xact_id </p><hr><pre><code>735</code></pre><p>(1 row)</p><p>If you want to know the current transaction id, then use function <code>pg_current_xact_id_if_assigned()</code>. Obversely, as the document indicated, if you are not within a transaction, this function won’t return any transaction id.<br>postgres=# select pg_current_xact_id_if_assigned();<br> pg_current_xact_id_if_assigned </p><hr><p>(1 row)</p><p>However, if start a transaction with begin, followed a simple insert query like below, and then run the function <code>pg_current_xact_id_if_assigned()</code> again, you should be able to find out your current transaction id.<br>postgres=# begin ;<br>BEGIN<br>postgres=<em># insert into tbl01 values(1,’hello world’);<br>INSERT 0 1<br>postgres=</em># select pg_current_xact_id_if_assigned();<br> pg_current_xact_id_if_assigned </p><hr><pre><code>736</code></pre><p>(1 row)</p><p>The function <code>pg_current_snapshot()</code> will return current top level snapshot in a format like, <code>xmin:xmax:xid1,xid2</code>. For example,<br>postgres=*#  select pg_current_snapshot();<br> pg_current_snapshot </p><hr><p> 736:736:<br>(1 row<br>In this case, the PostgreSQL server has only one ongoing transaction which is 736.   </p><p>One of the use cases for end user is that a user may want to check the tuples visibilities using pg_current_snapshot and pg_current_xact_id_if_assigned. For example, start two psql consoles with begin and followed by one simple insert operation, then check the current transaction id and current snapshots.</p><p>postgres=*# select pg_current_xact_id_if_assigned();<br> pg_current_xact_id_if_assigned </p><hr><pre><code>736</code></pre><p>(1 row)</p><p>postgres=*#  select pg_current_snapshot();<br> pg_current_snapshot </p><hr><p> 736:739:737<br>(1 row)<br>In the first console, it tells that the current transactions id is 736, and there is another ongoing transaction 737 and any tuples update made by transaction 737 is not visibile to this console yet.</p><p>postgres=*# select pg_current_xact_id_if_assigned();<br> pg_current_xact_id_if_assigned </p><hr><pre><code>737</code></pre><p>(1 row)</p><p>postgres=*# select pg_current_snapshot();<br> pg_current_snapshot </p><hr><p> 736:739:736<br>(1 row)</p><p>If you check the assigned transaction id and current snapshot in the second console, it will tell you a similar information. With these two public fucntions and plus an extension pageinspect, it can help debug the tuple visibilities issue.</p><h4 id="3-Summary"><a href="#3-Summary" class="headerlink" title="3. Summary"></a>3. Summary</h4><p>In this blog, we discussed the changes made for those transaction id and snapshot public functions, and shared a few simple queries about how to use these snapshots related public funtions. It might be useful if you want to have a better understanding of the ongoing transactions and snapshots.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-snapshot.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. O
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="transaction id" scheme="https://idrawone.github.io/categories/PostgreSQL/transaction-id/"/>
    
      <category term="snapshot" scheme="https://idrawone.github.io/categories/PostgreSQL/transaction-id/snapshot/"/>
    
      <category term="public function" scheme="https://idrawone.github.io/categories/PostgreSQL/transaction-id/snapshot/public-function/"/>
    
    
  </entry>
  
  <entry>
    <title>How to run a specific regression test</title>
    <link href="https://idrawone.github.io/2021/11/26/how-to-run-a-specific-regression-test/"/>
    <id>https://idrawone.github.io/2021/11/26/how-to-run-a-specific-regression-test/</id>
    <published>2021-11-26T08:00:00.000Z</published>
    <updated>2021-11-27T00:26:44.609Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-tap-test.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>I have been working on an internal project based on PostgreSQL for a while, and from time to time, I need to run some specific test cases to verify my changes. Here, I want to shared a tip to run a specific regression TAP test quickly, especially, when you are focusing on a particular bug and you know which test case can help verify the fix. A details document about the regression test can be found at <a href="https://www.postgresql.org/docs/14/regress-run.html" target="_blank" rel="noopener">Running the Tests</a>.</p><h4 id="2-Regression-test"><a href="#2-Regression-test" class="headerlink" title="2. Regression test"></a>2. Regression test</h4><p>PostgreSQL provides a comprehensive set of regression tests to verify the SQL implementation embedded in PostgreSQL as well as the extended capabilities of PostgreSQL. Whenever you make some changes, you should run these existing test cases to make sure your change doesn’t break any existing features. Other than these regression tests, there are some special features using a test framework call TAP test. For example, <code>kerberos</code>, <code>ssl</code>, <code>recovery</code> etc.</p><p>If you want to run these tests, you have to make sure the option <code>--enable-tap-tests</code> has been configured. for example,<br><code>./configure --prefix=$HOME/pgapp --enable-tap-tests --enable-debug CFLAGS=&quot;-g3 -O0 -fno-omit-frame-pointer&quot;</code></p><p>You can run the TAP test using either <code>make check</code> or <code>make installcheck</code>, but compared with those non-TAP tests, the different is that these TAP tests will always start a test server even you run <code>make installcheck</code>. Because of this different, some tests may take a longer time than you expected, and even worse, if some test cases failed in the middle then the entire test will stop, and your test cases may never get the chance to run. For example, I changed somethings related to the recovery features, and those changes suppose to be tested by test cases <code>021_row_visibility.pl</code> and <code>025_stuck_on_old_timeline.pl</code>, but whenever I run <code>make check</code> or <code>make installcheck</code>, it ends up with something like below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">t&#x2F;001_stream_rep.pl .................. ok     </span><br><span class="line">t&#x2F;002_archiving.pl ................... ok   </span><br><span class="line">t&#x2F;003_recovery_targets.pl ............ ok   </span><br><span class="line">t&#x2F;004_timeline_switch.pl ............. ok   </span><br><span class="line">t&#x2F;005_replay_delay.pl ................ ok   </span><br><span class="line">t&#x2F;006_logical_decoding.pl ............ ok     </span><br><span class="line">t&#x2F;007_sync_rep.pl .................... ok     </span><br><span class="line">t&#x2F;008_fsm_truncation.pl .............. ok   </span><br><span class="line">t&#x2F;009_twophase.pl .................... ok     </span><br><span class="line">t&#x2F;010_logical_decoding_timelines.pl .. ok     </span><br><span class="line">t&#x2F;011_crash_recovery.pl .............. ok   </span><br><span class="line">t&#x2F;012_subtransactions.pl ............. ok     </span><br><span class="line">t&#x2F;013_crash_restart.pl ............... ok     </span><br><span class="line">t&#x2F;014_unlogged_reinit.pl ............. ok     </span><br><span class="line">t&#x2F;015_promotion_pages.pl ............. ok   </span><br><span class="line">t&#x2F;016_min_consistency.pl ............. ok   </span><br><span class="line">t&#x2F;017_shm.pl ......................... ok   </span><br><span class="line">t&#x2F;018_wal_optimize.pl ................ ok     </span><br><span class="line">t&#x2F;019_replslot_limit.pl .............. 11&#x2F;20 Bailout called.  Further testing stopped:  pg_ctl start failed</span><br><span class="line">FAILED--Further testing stopped: pg_ctl start failed</span><br><span class="line">Makefile:23: recipe for target &#39;check&#39; failed</span><br><span class="line">make: *** [check] Error 255</span><br></pre></td></tr></table></figure><p>Now, <code>019_replslot_limit.pl</code> always failed in the middle, but those test cases to verify my changes haven’t got the chance to run yet.</p><h4 id="3-How-to-run-a-specific-test"><a href="#3-How-to-run-a-specific-test" class="headerlink" title="3. How to run a specific test?"></a>3. How to run a specific test?</h4><p>To run a specific test cases, the key is to use a variable <code>PROVE_TESTS</code> provided by PostgreSQL. Details can be found at <a href="https://www.postgresql.org/docs/14/regress-tap.html" target="_blank" rel="noopener">TAP Tests</a>. This <code>PROVE_TESTS</code> variable allow to define a whitespace separated list of paths to run the specified subset of tests instead of the default t/*.pl. For example: in above case, you can run <code>make check PROVE_TESTS=&#39;t/021_row_visibility.pl t/025_stuck_on_old_timeline.pl&#39;</code>. It will run these two test cases directly. The output is something like below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">recovery$ make check PROVE_TESTS&#x3D;&#39;t&#x2F;021_row_visibility.pl t&#x2F;025_stuck_on_old_timeline.pl&#39; </span><br><span class="line">make -C ..&#x2F;..&#x2F;..&#x2F;src&#x2F;backend generated-headers</span><br><span class="line">make[1]: Entering directory &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;backend&#39;</span><br><span class="line">make -C catalog distprep generated-header-symlinks</span><br><span class="line">make[2]: Entering directory &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;backend&#x2F;catalog&#39;</span><br><span class="line">make[2]: Nothing to be done for &#39;distprep&#39;.</span><br><span class="line">make[2]: Nothing to be done for &#39;generated-header-symlinks&#39;.</span><br><span class="line">make[2]: Leaving directory &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;backend&#x2F;catalog&#39;</span><br><span class="line">make -C utils distprep generated-header-symlinks</span><br><span class="line">make[2]: Entering directory &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;backend&#x2F;utils&#39;</span><br><span class="line">make[2]: Nothing to be done for &#39;distprep&#39;.</span><br><span class="line">make[2]: Nothing to be done for &#39;generated-header-symlinks&#39;.</span><br><span class="line">make[2]: Leaving directory &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;backend&#x2F;utils&#39;</span><br><span class="line">make[1]: Leaving directory &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;backend&#39;</span><br><span class="line">rm -rf &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#39;&#x2F;tmp_install</span><br><span class="line">&#x2F;bin&#x2F;mkdir -p &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#39;&#x2F;tmp_install&#x2F;log</span><br><span class="line">make -C &#39;..&#x2F;..&#x2F;..&#39; DESTDIR&#x3D;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#39;&#x2F;tmp_install install &gt;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#39;&#x2F;tmp_install&#x2F;log&#x2F;install.log 2&gt;&amp;1</span><br><span class="line">make -j1  checkprep &gt;&gt;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#39;&#x2F;tmp_install&#x2F;log&#x2F;install.log 2&gt;&amp;1</span><br><span class="line">rm -rf &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#39;&#x2F;tmp_check</span><br><span class="line">&#x2F;bin&#x2F;mkdir -p &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#39;&#x2F;tmp_check</span><br><span class="line">cd . &amp;&amp; TESTDIR&#x3D;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#39; PATH&#x3D;&quot;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;tmp_install&#x2F;home&#x2F;sandbox&#x2F;pgapp&#x2F;bin:$PATH&quot; LD_LIBRARY_PATH&#x3D;&quot;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;tmp_install&#x2F;home&#x2F;sandbox&#x2F;pgapp&#x2F;lib:$LD_LIBRARY_PATH&quot;  PGPORT&#x3D;&#39;65432&#39; PG_REGRESS&#x3D;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#x2F;..&#x2F;..&#x2F;..&#x2F;src&#x2F;test&#x2F;regress&#x2F;pg_regress&#39; &#x2F;usr&#x2F;bin&#x2F;prove -I ..&#x2F;..&#x2F;..&#x2F;src&#x2F;test&#x2F;perl&#x2F; -I .  t&#x2F;021_row_visibility.pl t&#x2F;025_stuck_on_old_timeline.pl</span><br><span class="line">t&#x2F;021_row_visibility.pl ......... ok     </span><br><span class="line">t&#x2F;025_stuck_on_old_timeline.pl .. ok   </span><br><span class="line">All tests successful.</span><br><span class="line">Files&#x3D;2, Tests&#x3D;11, 13 wallclock secs ( 0.01 usr  0.00 sys +  1.73 cusr  4.03 csys &#x3D;  5.77 CPU)</span><br><span class="line">Result: PASS</span><br></pre></td></tr></table></figure><p>Of course, if you know the makefile very well, you can also do it on your own way. For example, by looking at the output, you can simply do in below steps to achieve the same results.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rm -rf &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#39;&#x2F;tmp_check</span><br><span class="line"></span><br><span class="line">mkdir -p &#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#39;&#x2F;tmp_check</span><br><span class="line"></span><br><span class="line">recovery$ cd . &amp;&amp; TESTDIR&#x3D;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#39; PATH&#x3D;&quot;&#x2F;home&#x2F;sandbox&#x2F;pgapp&#x2F;bin:$PATH&quot; PGPORT&#x3D;&#39;65432&#39; top_builddir&#x3D;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#x2F;..&#x2F;..&#x2F;..&#39; PG_REGRESS&#x3D;&#39;&#x2F;home&#x2F;sandbox&#x2F;sharedsm&#x2F;src&#x2F;test&#x2F;recovery&#x2F;..&#x2F;..&#x2F;..&#x2F;src&#x2F;test&#x2F;regress&#x2F;pg_regress&#39; &#x2F;usr&#x2F;bin&#x2F;prove -I ..&#x2F;..&#x2F;..&#x2F;src&#x2F;test&#x2F;perl&#x2F; -I .  t&#x2F;021_row_visibility.pl </span><br><span class="line">t&#x2F;021_row_visibility.pl .. ok     </span><br><span class="line">All tests successful.</span><br><span class="line">Files&#x3D;1, Tests&#x3D;10,  5 wallclock secs ( 0.02 usr  0.00 sys +  0.81 cusr  1.42 csys &#x3D;  2.25 CPU)</span><br><span class="line">Result: PASS</span><br></pre></td></tr></table></figure><h4 id="4-Summary"><a href="#4-Summary" class="headerlink" title="4. Summary"></a>4. Summary</h4><p>In this blog, I explained how to run a specific test case by using variable <code>PROVE_TESTS</code> for TAP test. You can also run the test manually to skip some tests either take too much time or may failed in the middle and block your test cases. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-tap-test.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. O
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="regression TAP" scheme="https://idrawone.github.io/categories/PostgreSQL/regression-TAP/"/>
    
      <category term="test" scheme="https://idrawone.github.io/categories/PostgreSQL/regression-TAP/test/"/>
    
    
  </entry>
  
  <entry>
    <title>Backup Label in PostgreSQL</title>
    <link href="https://idrawone.github.io/2021/10/15/what-is-backup-label/"/>
    <id>https://idrawone.github.io/2021/10/15/what-is-backup-label/</id>
    <published>2021-10-15T08:00:00.000Z</published>
    <updated>2021-10-15T22:35:50.149Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-backup-label.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>When I was working on some backup and recovery related features for a project based on Postgres, I noticed that there is file called <code>backup_label</code>. By quickly google search, you can find some very nice blogs or books which discussed this topic, such as, <a href="https://www.interdb.jp/pg/pgsql10.html" target="_blank" rel="noopener">The Internals of PostgreSQL</a>, one of my favourite books. In this blog, I am going to talk it a little more based on my experience.</p><h4 id="2-What-is-backup-label"><a href="#2-What-is-backup-label" class="headerlink" title="2. What is backup_label?"></a>2. What is backup_label?</h4><p>The <code>backup_label</code> is a file created in $PGDATA folder when there is an <code>exclusive backup</code> triggered by <code>pg_start_backup()</code> and the backup is in progress. This <code>backup_label</code> file will be removed once the <code>pg_stop_backup()</code> is executed. Here, the <code>exclusive backup</code> is one of the backup methods introduced to Postgres early, and as the name indicated, it does not support multiple backup activities at the same time. Because of this limitation, a frontend backup tool <code>pg_basebackup</code> is added to the Postgres later. This <code>pg_basebackup</code> client does allow multiple backup activities performed at the same time. Therefore, this kind of backup is called as <code>non-exclusive backup</code>. Both backup methods use the <code>backup_label</code> but in a different way.</p><p>In exclusive basebackup, the <code>backup_label</code> will be generated automatically on the source server side. To see how this file looks like, you can run a command like, <code>select pg_start_backup(&#39;first backup&#39;);</code> from a psql console. Then you should be able to find a <code>backup_label</code> file in $PGDATA folder with the content like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">START WAL LOCATION: 0&#x2F;6000028 (file 000000010000000000000006)</span><br><span class="line">CHECKPOINT LOCATION: 0&#x2F;6000060</span><br><span class="line">BACKUP METHOD: pg_start_backup</span><br><span class="line">BACKUP FROM: master</span><br><span class="line">START TIME: 2021-10-15 13:30:03 PDT</span><br><span class="line">LABEL: first backup</span><br><span class="line">START TIMELINE: 1</span><br></pre></td></tr></table></figure><h4 id="3-How-does-it-work"><a href="#3-How-does-it-work" class="headerlink" title="3. How does it work?"></a>3. How does it work?</h4><p>In exclusive backup mode, the Postgres source server will generate this file when <code>pg_sart_backup()</code> is executed, and removed after <code>pg_stop_backup()</code>, however, in non-executive backup mode, such as using <code>pg_basebackup</code> client to perform a base backup, the <code>backup_label</code> is only streamed to the client side but not physical saved to the source Postgres server. </p><p>As you can see in above <code>baseup_label</code> file, it contains a similar checkpoint information compared to pg_controldata file. If a backup is used in recovery with this backup_label file present, then Postgres will use the checkpoint in backup_label to start the REDO process. The reason is that there could be multiple checkpoints happening during the backup process. After the recovery process is done, this <code>backup_label</code> file will be renamed as <code>backup_label.old</code> to indelicate the recovery finished properly. In simple words, with the <code>backup_label</code> file, the database has a consistent checkpoint to recover from a proper archive.</p><h4 id="4-Does-it-impact-any-frontend-tool"><a href="#4-Does-it-impact-any-frontend-tool" class="headerlink" title="4. Does it impact any frontend tool?"></a>4. Does it impact any frontend tool?</h4><p>The answer is <code>yes</code>. Some frontend tools will perform differently if a <code>backup_label</code> file is present. For example, if <code>pg_ctl</code> sees a <code>backup_label</code> file during smart shutdown process, it will wait for it to be removed by providing a waring message to the end user with something like,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WARNING: online backup mode is active</span><br><span class="line">Shutdown will not complete until pg_stop_backup() is called</span><br></pre></td></tr></table></figure><p>Another example is the frontend tool <code>pg_rewind</code> which creates a <code>backup_label</code> to force a recovery to start from the last common checkpoint. </p><h4 id="5-Summary"><a href="#5-Summary" class="headerlink" title="5. Summary"></a>5. Summary</h4><p>In this blog, I explained the <code>backup_label</code> file in Postgres. I believe the end users won’t pay attention to it most of the time, but if you do encounter some issues related with <code>backup_label</code> then I hope this blog can give you some clues.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-backup-label.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="basebackup" scheme="https://idrawone.github.io/categories/PostgreSQL/basebackup/"/>
    
      <category term="label" scheme="https://idrawone.github.io/categories/PostgreSQL/basebackup/label/"/>
    
      <category term="start" scheme="https://idrawone.github.io/categories/PostgreSQL/basebackup/label/start/"/>
    
      <category term="stop" scheme="https://idrawone.github.io/categories/PostgreSQL/basebackup/label/start/stop/"/>
    
      <category term="tools" scheme="https://idrawone.github.io/categories/PostgreSQL/basebackup/label/start/stop/tools/"/>
    
    
  </entry>
  
  <entry>
    <title>A quick test for postgres_fdw batch insertion</title>
    <link href="https://idrawone.github.io/2021/09/17/a-quick-test-for-postgres-fdw-batch-insertion/"/>
    <id>https://idrawone.github.io/2021/09/17/a-quick-test-for-postgres-fdw-batch-insertion/</id>
    <published>2021-09-17T08:00:00.000Z</published>
    <updated>2021-09-17T23:20:32.213Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi_bulk_insertion.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>In my previous <a href="https://www.highgo.ca/2021/08/20/how-batch-insertion-was-done-in-postgres_fdw/" target="_blank" rel="noopener">blog</a>, I briefly walked through how the bulk/batch insertion was done for postgres_fdw in PG14. In this blog, I am going to run some basic tests to compare the performance for before and after the batch insertion was introduced in postgres_fdw, so that we can have a general idea about whether this feature makes any difference.</p><h4 id="2-PG-Servers-Setup"><a href="#2-PG-Servers-Setup" class="headerlink" title="2. PG Servers Setup"></a>2. PG Servers Setup</h4><p>The key of the blog is to see if there is any difference for batch insertion. To make the testing simple, here is how I set up a simple environment. </p><p>As this bulk/batch insertion was introduced for PG14, so we need to switch to the stable PG14 branch, i.e. REL_14_STABLE. After checked out the source code, simply run the commands: <code>configure, make and make install</code>. Here are the commands used in this blog.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;configure --prefix&#x3D;$HOME&#x2F;sandbox&#x2F;postgres&#x2F;pgapp --enable-tap-tests --enable-debug CFLAGS&#x3D;&quot;-g3 -O0&quot;</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line">cd contrib&#x2F;postgres_fdw&#x2F;</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line">export PGDATA&#x3D;$HOME&#x2F;sandbox&#x2F;postgres&#x2F;pgdata</span><br><span class="line">initdb -D $PGDATA</span><br><span class="line">pg_ctl -D $PGDATA -l logfile start</span><br></pre></td></tr></table></figure><p>In order to test Foreign Data Wrapper, we need to start another PG Server. To make it easy, I simply start a PG Server on a Foreign data cluster and change the default port to a different one, for example, <code>5433</code>. Below are the commands used to setup Foreign Server.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export FPGDATA&#x3D;$HOME&#x2F;sandbox&#x2F;postgres&#x2F;pgdata2</span><br><span class="line">initdb -D $FPGDATA</span><br></pre></td></tr></table></figure><p>After the Foreign data cluster has been initialized, change the port to 5433, then start the Foreign PG Server.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim $FPGDATA&#x2F;postgresql.conf </span><br><span class="line">pg_ctl -D $FPGDATA -l logfile-f start</span><br></pre></td></tr></table></figure><h4 id="3-Foreign-Tables-Setup"><a href="#3-Foreign-Tables-Setup" class="headerlink" title="3. Foreign Tables Setup"></a>3. Foreign Tables Setup</h4><p>Now, we can setup the basic Foreign Data Wrapper testing environment like below.</p><p>On the Local PG Server:</p><h5 id="3-1-Create-a-Foreign-Server-using-default-batch-settings"><a href="#3-1-Create-a-Foreign-Server-using-default-batch-settings" class="headerlink" title="3.1. Create a Foreign Server using default batch settings"></a>3.1. Create a Foreign Server using default batch settings</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create server fs foreign data wrapper postgres_fdw options (dbname &#39;postgres&#39;, host &#39;127.0.0.1&#39;, port &#39;5433&#39;);</span><br><span class="line">CREATE SERVER</span><br></pre></td></tr></table></figure><h5 id="3-2-Create-the-user-mapping"><a href="#3-2-Create-the-user-mapping" class="headerlink" title="3.2. Create the user mapping"></a>3.2. Create the user mapping</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create user mapping for david server fs options( user &#39;david&#39;);</span><br><span class="line">CREATE USER MAPPING</span><br></pre></td></tr></table></figure><h5 id="3-3-Create-Foreign-Tables-on-Local-PG-Server"><a href="#3-3-Create-Foreign-Tables-on-Local-PG-Server" class="headerlink" title="3.3. Create Foreign Tables on Local PG Server"></a>3.3. Create Foreign Tables on Local PG Server</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create foreign table ft (id int, test text) server fs options(table_name &#39;t&#39;);</span><br><span class="line">CREATE FOREIGN TABLE</span><br></pre></td></tr></table></figure><p>By default, the batch insertion size has been set to 1 as you can see from the source code.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line"> * Determine batch size for a given foreign table. The option specified for</span><br><span class="line"> * a table has precedence.</span><br><span class="line"> *&#x2F;</span><br><span class="line">static int</span><br><span class="line">get_batch_size_option(Relation rel)</span><br><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">    &#x2F;* we use 1 by default, which means &quot;no batching&quot; *&#x2F;</span><br><span class="line">    int         batch_size &#x3D; 1;</span><br></pre></td></tr></table></figure><p>Now, repeate the process to create another two Foreign Tables with different batch size correspondingly, i.e. 10 and 100.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create foreign table ft_batch10 (id int, test text) server fs options(batch_size &#39;10&#39;, table_name &#39;t10&#39;);</span><br><span class="line">CREATE FOREIGN TABLE</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# create foreign table ft_batch100 (id int, test text) server fs options(batch_size &#39;100&#39;, table_name &#39;t100&#39;);</span><br><span class="line">CREATE FOREIGN TABLE</span><br></pre></td></tr></table></figure><h5 id="3-4-Create-Tables-on-Foreign-Server"><a href="#3-4-Create-Tables-on-Foreign-Server" class="headerlink" title="3.4. Create Tables on Foreign Server"></a>3.4. Create Tables on Foreign Server</h5><p>On the Foreign PG Server side, create corresponding tables like below. Notes, you need to make the table names match the ones used in Local PG Server.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">psql -d postgres -p 5433</span><br><span class="line">postgres&#x3D;# create table t (id int, test text);</span><br><span class="line">CREATE TABLE</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# create table t10 (id int, test text);</span><br><span class="line">CREATE TABLE</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# create table t100 (id int, test text);</span><br><span class="line">CREATE TABLE</span><br></pre></td></tr></table></figure><h4 id="4-Run-the-tests"><a href="#4-Run-the-tests" class="headerlink" title="4. Run the tests"></a>4. Run the tests</h4><p>Now, enable the timeing on Local PG Server, and simply run the commands below, and then record the timing for comparison.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# \timing </span><br><span class="line">Timing is on.</span><br><span class="line"></span><br><span class="line">insert into ft values(generate_series(1,1000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft;</span><br><span class="line">delete from ft ;</span><br><span class="line">insert into ft values(generate_series(1,1000000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft;</span><br><span class="line">delete from ft ;</span><br><span class="line">insert into ft values(generate_series(1,100000000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft;</span><br><span class="line">delete from ft ;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">insert into ft_batch10 values(generate_series(1,1000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft_batch10;</span><br><span class="line">delete from ft_batch10 ;</span><br><span class="line">insert into ft_batch10 values(generate_series(1,1000000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft_batch10;</span><br><span class="line">delete from ft_batch10 ;</span><br><span class="line">insert into ft_batch10 values(generate_series(1,100000000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft_batch10;</span><br><span class="line">delete from ft_batch10 ;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">insert into ft_batch100 values(generate_series(1,1000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft_batch100;</span><br><span class="line">delete from ft_batch100 ;</span><br><span class="line">insert into ft_batch100 values(generate_series(1,1000000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft_batch100;</span><br><span class="line">delete from ft_batch100 ;</span><br><span class="line">insert into ft_batch100 values(generate_series(1,100000000),&#39;hello, world&#39;);</span><br><span class="line">select count(*) from ft_batch100;</span><br><span class="line">delete from ft_batch100 ;</span><br></pre></td></tr></table></figure><h4 id="5-Check-the-results"><a href="#5-Check-the-results" class="headerlink" title="5. Check the results"></a>5. Check the results</h4><p>Here are results from about tests.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1                               10                          100                         </span><br><span class="line">55.634 ms                       9.996 ms                    25.545 ms </span><br><span class="line">32155.960 ms (00:32.156)        5927.090 ms (00:05.927)     4754.158 ms (00:04.754) </span><br><span class="line">3237972.881 ms (53:57.973)      623204.920 ms (10:23.205)   332998.911 ms (05:32.999)</span><br></pre></td></tr></table></figure><h4 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6. Summary"></a>6. Summary</h4><p>In this blog, we simply run some basic tests to see if there is any performance improvement in postgres_fdw for the batch/bulk insertion. The results are very impressive: for 1k insertion, batch size 10 and 100 are 5 and 2 times and faster relatively; for 1 million insertion, batch size 10 and 100 are 5.5 and 6.5 times faser; for 100 millions insertion, batch size 10 and 100 are 5 and 9.5 times better.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi_bulk_insertion.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="foreign data wrapper" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/"/>
    
      <category term="fdw" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/fdw/"/>
    
      <category term="bulk" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/fdw/bulk/"/>
    
      <category term="batch" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/fdw/bulk/batch/"/>
    
      <category term="insert" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/fdw/bulk/batch/insert/"/>
    
    
  </entry>
  
  <entry>
    <title>How batch insertion was done in postgres_fdw</title>
    <link href="https://idrawone.github.io/2021/08/20/a-new-feature-walk-through-on-postgres-fdw-from-commits/"/>
    <id>https://idrawone.github.io/2021/08/20/a-new-feature-walk-through-on-postgres-fdw-from-commits/</id>
    <published>2021-08-20T08:00:00.000Z</published>
    <updated>2021-08-20T23:10:46.851Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi_bulk_insertion.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>postgres_fdw has been existing in PostgreSQL for many years, and it was one of the most popular interfaces used in many extensions. such as the <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers" target="_blank" rel="noopener">PostgreSQL foreign data wrappers wiki page</a>, and <a href="https://pgxn.org/tag/fdw/" target="_blank" rel="noopener">PostgreSQL Extension Network/PGXN</a>. However, I had not touched this postgres_fdw in deep until I got a task about combing multiple columns from multiple tables using this amazing Foreign Data Wrapper interface. After some hack, I was be able to combine multiple columns from multiple tables into one table based on postgres_fdw, but I was just curious about how many enhancements has been done recently. After a simple git pull, I found actually there are some new features was introduced in PG14, such as Asynchronous Execution, Bulk Inserts, Truncate as well as some network connection related enhancement. In this blog, I will take a detail look at one of the enhancements, i.e. Bulk insertion, to see how it was implemented.</p><h4 id="2-A-detail-looks-at-bulk-insertion"><a href="#2-A-detail-looks-at-bulk-insertion" class="headerlink" title="2. A detail looks at bulk insertion"></a>2. A detail looks at bulk insertion</h4><p>I haven’t performed any benchmark test for bulk inserts in postgres_fdw to compare before and after yet, but you can find a very nice blog <a href="https://www.percona.com/blog/2021/05/27/new-features-in-postgresql-14-bulk-inserts-for-foreign-data-wrappers/" target="_blank" rel="noopener">here</a> as your reference, if I have time I will definitely run some benchmark test on a production server. For now, let’s take a look to see how it was implemented.</p><p>The first commit was done early 2021, and here is the details information about this features.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">commit b663a4136331de6c7364226e3dbf7c88bfee7145</span><br><span class="line">Author: Tomas Vondra &lt;tomas.vondra@postgresql.org&gt;</span><br><span class="line">Date:   Wed Jan 20 23:05:46 2021 +0100</span><br><span class="line"></span><br><span class="line">    Implement support for bulk inserts in postgres_fdw</span><br><span class="line">    </span><br><span class="line">    Extends the FDW API to allow batching inserts into foreign tables. That</span><br><span class="line">    is usually much more efficient than inserting individual rows, due to</span><br><span class="line">    high latency for each round-trip to the foreign server.</span><br><span class="line">    </span><br><span class="line">    It was possible to implement something similar in the regular FDW API,</span><br><span class="line">    but it was inconvenient and there were issues with reporting the number</span><br><span class="line">    of actually inserted rows etc. This extends the FDW API with two new</span><br><span class="line">    functions:</span><br><span class="line">    </span><br><span class="line">    * GetForeignModifyBatchSize - allows the FDW picking optimal batch size</span><br><span class="line">    </span><br><span class="line">    * ExecForeignBatchInsert - inserts a batch of rows at once</span><br><span class="line">    </span><br><span class="line">    Currently, only INSERT queries support batching. Support for DELETE and</span><br><span class="line">    UPDATE may be added in the future.</span><br><span class="line">    </span><br><span class="line">    This also implements batching for postgres_fdw. The batch size may be</span><br><span class="line">    specified using &quot;batch_size&quot; option both at the server and table level.</span><br><span class="line">    </span><br><span class="line">    The initial patch version was written by me, but it was rewritten and</span><br><span class="line">    improved in many ways by Takayuki Tsunakawa.</span><br><span class="line">    </span><br><span class="line">    Author: Takayuki Tsunakawa</span><br><span class="line">    Reviewed-by: Tomas Vondra, Amit Langote</span><br><span class="line">    Discussion: https:&#x2F;&#x2F;postgr.es&#x2F;m&#x2F;20200628151002.7x5laxwpgvkyiu3q@development</span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line"></span><br><span class="line">As the author commented, two major functions, i.e. &#96;postgresGetForeignModifyBatchSize&#96; and &#96;postgresExecForeignBatchInsert&#96; were introduced to postgres_fdw to hook up with the extended FDW API. The extended FDW API can be found in &#96;src&#x2F;include&#x2F;foreign&#x2F;fdwapi.h&#96;.</span><br><span class="line"></span><br><span class="line">The corresponding implementation was done in &#96;contrib&#x2F;postgres_fdw&#x2F;postgres_fdw.c&#96;. </span><br><span class="line">Single row insertion</span><br></pre></td></tr></table></figure><p>static TupleTableSlot *<br>postgresExecForeignInsert(EState *estate,<br>                          ResultRelInfo *resultRelInfo,<br>                          TupleTableSlot *slot,<br>                          TupleTableSlot *planSlot)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vs. batch rows insertion</span><br></pre></td></tr></table></figure><p>static TupleTableSlot **<br>postgresExecForeignBatchInsert(EState <em>estate,<br>                          ResultRelInfo *resultRelInfo,<br>                          TupleTableSlot *</em>slots,<br>                          TupleTableSlot **planSlots,<br>                          int *numSlots)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Function postgresExecForeignBatchInsert support multiple slots, planSlots as well as a new parameter, i.e. numSlots. So that it can insert multiple rows in one round communication to save the network communication overhead.</span><br></pre></td></tr></table></figure><p>static int<br>postgresGetForeignModifyBatchSize(ResultRelInfo *resultRelInfo)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The function basically allows to retrieve the number of row remote server will support in bulk insertion. Here, as the function has a note, if there is trigger defined for remote table with AFTER ROW or with RETURNING required, the bulk insertion is not allowed, otherwise the rule will be broken on remote server side.</span><br><span class="line"></span><br><span class="line">Other than these two major new functions, there are some update in other functions, such as, &#96;execute_foreign_modify&#96;, which will build the bulk insertion query when it received insert operation, something like below.</span><br></pre></td></tr></table></figure><pre><code>if (operation == CMD_INSERT &amp;&amp; fmstate-&gt;num_slots != *numSlots)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">and another important change is &#96;convert_prep_stmt_params&#96; which has a loop to build the number of rows that server can accept.</span><br></pre></td></tr></table></figure><pre><code>for (i = 0; i &lt; numSlots; i++)</code></pre><pre><code>Then rest of the changes are mainly to support the bulk insertion features, such as parse the `batch_size` in option. Another new function, `rebuildInsertSql` in `deparse.c` is used in `execute_foreign_modify` to build the actual number of rows before sending the query to remote server.#### 3. LimitationAs it was mentioned in the commit message, only insertion is supported for bulk operations, delete and update are not supported yet. Hopefully, these bulk operations and interfaces can be added soon. So that, there will be even more extensions using FDW interface in the future.#### 4. SummaryIn this blog, we discussed a key performance improvement in postgres_fdw, i.e. bulk insertion and take a detail look at the source code level. I hope it can help when someone want to add a new feature to postgres_fdw or any continue improvement on bulk insertion._**Reference:**_1. [F.35. postgres_fdw](https://www.postgresql.org/docs/14/postgres-fdw.html)2. [Faster Bulk Insertion to Foreign Tables - Introduction to PostgreSQL 14 Committed Features](http://postgres-road.blogspot.com/2021/03/faster-bulk-insertion-to-foreign-tables.html)3. [New Features in PostgreSQL 14: Bulk Inserts for Foreign Data Wrappers](https://www.percona.com/blog/2021/05/27/new-features-in-postgresql-14-bulk-inserts-for-foreign-data-wrappers/)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi_bulk_insertion.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="foreign data wrapper" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/"/>
    
      <category term="fdw" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/fdw/"/>
    
      <category term="bulk" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/fdw/bulk/"/>
    
      <category term="insert" scheme="https://idrawone.github.io/categories/PostgreSQL/foreign-data-wrapper/fdw/bulk/insert/"/>
    
    
  </entry>
  
  <entry>
    <title>The Amazing Buffer Tag in PostgreSQL</title>
    <link href="https://idrawone.github.io/2021/07/23/the-amazing-buffer-tag-in-PG/"/>
    <id>https://idrawone.github.io/2021/07/23/the-amazing-buffer-tag-in-PG/</id>
    <published>2021-07-23T08:00:00.000Z</published>
    <updated>2021-07-23T21:49:52.009Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi_buffer_tag.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>I was working on the PostgreSQL storage related features recently, and I found PostgreSQL has designed an amazing storage addressing mechanism, i.e. Buffer Tag. In this blog, I want to share with you my understanding about the Buffer Tag and some potential usage of it.</p><h4 id="2-Buffer-Tag"><a href="#2-Buffer-Tag" class="headerlink" title="2. Buffer Tag"></a>2. Buffer Tag</h4><p>I was always curious to know how PostgreSQl can find out the tuple data blocks so quickly when the first time I started to use PostgreSQL in an IoT project, but I never got the chance to look it into details even though I knew PostgreSQL is an very well organized open-source project. Until I recently got a task which needs to solve some storage related issue in PostgreSQL. There is very detailed explanation about how Buffer Manger works in an online PostgreSQL books for developers <a href="https://www.interdb.jp/pg/index.html" target="_blank" rel="noopener">The Internals of PostgreSQL</a>, one of the best PostgreSQL books I would recommend to the beginner of PostgreSQL development to read.</p><p>Buffer Tag, in simple words, is just five numbers. Why it is five numbers? First, all the objects including the storage files are managed by Object Identifiers, i.e. OID. For example, when user creates a table, the table name is mapped to an OID; when user creates a database, the name is mapped to an OID; when the corresponding data need to be persistent on disk, the files is also named using OID. Secondly, when a table requires more pages to store more tuples, then each page for the same table is managed by the page number in sequence. For example, when PostgreSQL needs to estimate the table size before decide what kind of scan should be used to find out the tuple faster, it need to know the number of blocks information. Thirdly, it is easy to understand that data tuples are the major user data need to be stored, but in order to better manage these data tuples, PostgreSQL needs others information, such as visibility to manage the status of these data tuples, and free space to optimize files usage. So this ends up with five numbers, i.e. Tablespace, Database, Table, ForkNumber, BlockNumber. </p><p>Given these five numbers, PostgreSQL can always find out where the data tuples are stored, which file is used, and what size the table is etc. </p><h4 id="3-How-Buffer-Tag-is-used"><a href="#3-How-Buffer-Tag-is-used" class="headerlink" title="3. How Buffer Tag is used"></a>3. How Buffer Tag is used</h4><p>Now, we have the buffer tag, five numbers, but how it is used in PosggreSQL. One typical use case of buffer tag is to help buffer manager to manage the location of memory blocks in the buffer pool/array. In this case, a hash table was introduced to resolve the mapping between buffer tag and the location of memory block in buffer pool/array. Here is a picture to show relationship among buffer tag, hashtable, buffer descriptor, and buffer pool/array.</p><p><img src="/images/img/buffer-tag-mapping.png" alt="Buffer Tag Mapping"></p><p>For example, the first green buffer tag {(1663, 13589, 16387), 0, 0} indicates a table space 1663, a database 12709, and a table 16387 with forkNumber 0 (main fork for tuples) which stored in a file at block 0. The buffer tag has a hash value 1536704684 which has been assigned to the memory block 0 managed by buffer manager at this moment. Since buffer descriptor is addressed using the same slot number as memory block in buffer pool/array, so they both share the same slot number 0, in this case.</p><p>With the above relationship, PostgreSQL can find out the memory block location or assign buffer slot to a new memory block for particular buffer tag.</p><p>The other typical use case of buffer tag is to help the storage manager to manage the corresponding files. In this case, the blockNumber is always to 0 since it doesn’t require multiple blocks to store more data. Here, you can create your use case of buffer tag. For example, use the buf_id as the number of blocks for each database relation instead of using it to indicate the memory block location. Moreover, you can also use the buffer tag plus the hashtable to manage multiple information such as having both buf_id for location of the memory block and adding a new attribute total to manage the number of blocks. You can achieve this by define a different buffer lookup entry. For example, </p><p>The original buffer lookup entry using buffer tag to lookup the location of memory block.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* entry for buffer lookup hashtable *&#x2F;</span><br><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">    BufferTag   key;            &#x2F;* Tag of a disk page *&#x2F;</span><br><span class="line">    int         id;             &#x2F;* Associated buffer ID *&#x2F;</span><br><span class="line">&#125; BufferLookupEnt;</span><br></pre></td></tr></table></figure><p>Below is an example of buffer lookup entry which can lookup both the location of memory block and the number of blocks used by this particular buffer tag.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">    BufferTag   key;            &#x2F;* Tag of a disk page    *&#x2F;</span><br><span class="line">    int         id;             &#x2F;* Associated buffer ID  *&#x2F;</span><br><span class="line">    int         total;          &#x2F;* the total number of X *&#x2F;</span><br><span class="line">&#125; ESRelLookupEnt;</span><br><span class="line">&#96;</span><br></pre></td></tr></table></figure><h4 id="4-Summary"><a href="#4-Summary" class="headerlink" title="4. Summary"></a>4. Summary</h4><p>In this blog, we discussed what is Buffer Tag, how it is used in PostgreSQL and some potential usage of Buffer Tag to address the mapping issues between tables to storage files as well as the lookup issues.</p><p><em><strong>Reference:</strong></em></p><ol><li><a href="https://www.interdb.jp/pg/index.html" target="_blank" rel="noopener">The Internals of PostgreSQL</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi_buffer_tag.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1.
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="buffer tag" scheme="https://idrawone.github.io/categories/PostgreSQL/buffer-tag/"/>
    
      <category term="hashtable" scheme="https://idrawone.github.io/categories/PostgreSQL/buffer-tag/hashtable/"/>
    
      <category term="lookup" scheme="https://idrawone.github.io/categories/PostgreSQL/buffer-tag/hashtable/lookup/"/>
    
    
  </entry>
  
  <entry>
    <title>How to create a system information function in PostgreSQL</title>
    <link href="https://idrawone.github.io/2021/03/03/how-to-create-a-system-info-function/"/>
    <id>https://idrawone.github.io/2021/03/03/how-to-create-a-system-info-function/</id>
    <published>2021-03-03T08:00:00.000Z</published>
    <updated>2021-03-03T23:19:02.846Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi_sys_info_fun.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL supports many System Information Functions, such as Session Information Functions, Access Privilege Inquiry Functions, Schema Visibility Inquiry Functions, System Catalog Information Functions, Transaction ID and Snapshot Information Functions, etc. However, you may want build some special functions and integrate them into the PostgreSQL. This blog is going to walk through the steps about how to build your own System Information Functions into PostgreSQL.</p><h4 id="2-Analyze-the-requirement"><a href="#2-Analyze-the-requirement" class="headerlink" title="2. Analyze the requirement"></a>2. Analyze the requirement</h4><p>Since there are so many functions built-in PostgreSQL already, you should perform some research and analysis before you decide to create a new one. In this blog, I want to check the transaction id after each savepoints in an ongoing transaction, so that I can perform some visibility check before the whole transaction is committed. For example, I have a query like below, but I can’t figure out the transaction id after each savepoint if I use existing System Information Function .</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# CREATE TABLE tbl (data text);</span><br><span class="line">CREATE TABLE</span><br><span class="line">postgres&#x3D;# BEGIN;</span><br><span class="line">BEGIN</span><br><span class="line">postgres&#x3D;# INSERT INTO tbl VALUES(&#39;HelloWorld-1&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line">postgres&#x3D;# SELECT txid_current();</span><br><span class="line"> txid_current </span><br><span class="line">--------------</span><br><span class="line">          488</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SAVEPOINT AA;</span><br><span class="line">SAVEPOINT</span><br><span class="line">postgres&#x3D;# INSERT INTO tbl VALUES(&#39;HelloWorld-2&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT txid_current();</span><br><span class="line"> txid_current </span><br><span class="line">--------------</span><br><span class="line">          488</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;#</span><br></pre></td></tr></table></figure><p>As you can see, I always get the same Transaction ID even after a savepoint using existing txid_current() function. In this case, I decide to create my own system information function to retrieve the information I want.</p><h4 id="3-System-Information-Function-template"><a href="#3-System-Information-Function-template" class="headerlink" title="3. System Information Function template"></a>3. System Information Function template</h4><p>To create your own System Information Function, you need to check the System Catalogs to see in which category it can fit. For the case mentioned above, I chose the catalog <a href="https://www.postgresql.org/docs/13/catalog-pg-proc.html" target="_blank" rel="noopener">pg_proc</a> which stores information about functions, procedures, aggregate functions, and window functions. The document <a href="https://www.postgresql.org/docs/11/system-catalog-initial-data.html" target="_blank" rel="noopener">System Catalog Initial Data</a> provides more detailed description and examples about the <code>.dat</code> file format and the rules to define your own OID.</p><p>Now, let’s define a function, say <code>current_xid_list();</code>. Below is an example about how the function initial data may look like.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># function to get the top and sub transactions XIDs</span><br><span class="line">&#123; oid &#x3D;&gt; &#39;5566&#39;, descr &#x3D;&gt; &#39;get current transaction list&#39;,</span><br><span class="line">  proname &#x3D;&gt; &#39;current_xid_list&#39;, provolatile &#x3D;&gt; &#39;s&#39;,</span><br><span class="line">  prorettype &#x3D;&gt; &#39;txid_snapshot&#39;, proargtypes &#x3D;&gt; &#39;&#39;,</span><br><span class="line">  prosrc &#x3D;&gt; &#39;current_xid_list&#39; &#125;,</span><br></pre></td></tr></table></figure><p>Here, you need to generate your OID which doesn’t create any conflict. In the official PostgreSQL document, <a href="https://www.postgresql.org/docs/13/system-catalog-initial-data.html" target="_blank" rel="noopener">69.2.2. OID Assignment</a>, it descripts how the OIDs are managed and also provides a script <code>src/include/catalog/unused_oids</code> to list the unused OIDs. For example, if you run the script like below, you will get a list of OIDs that are not used by PostgreSQL yet.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ src&#x2F;include&#x2F;catalog&#x2F;unused_oids</span><br><span class="line">4 - 9</span><br><span class="line">210</span><br><span class="line">270 - 273</span><br><span class="line">357</span><br><span class="line">380 - 381</span><br><span class="line">421</span><br><span class="line">560 - 583</span><br><span class="line">606</span><br><span class="line">702 - 704</span><br><span class="line">760 - 763</span><br><span class="line">784 - 789</span><br><span class="line">811 - 816</span><br><span class="line">1177</span><br><span class="line">1179 - 1180</span><br><span class="line">1382 - 1383</span><br><span class="line">1986 - 1987</span><br><span class="line">2023</span><br><span class="line">2030</span><br><span class="line">2121</span><br><span class="line">2137</span><br><span class="line">2228</span><br><span class="line">3432</span><br><span class="line">3434 - 3435</span><br><span class="line">3998</span><br><span class="line">4035</span><br><span class="line">4142</span><br><span class="line">4187 - 4199</span><br><span class="line">4225 - 4299</span><br><span class="line">4388 - 4399</span><br><span class="line">4532 - 4565</span><br><span class="line">4572 - 4999</span><br><span class="line">5022 - 5027</span><br><span class="line">5032 - 5554</span><br><span class="line">5556 - 5999</span><br><span class="line">6015 - 6099</span><br><span class="line">6103</span><br><span class="line">6105</span><br><span class="line">6107 - 6109</span><br><span class="line">6116</span><br><span class="line">6122 - 9999</span><br></pre></td></tr></table></figure><p>In my case, I picked the OID 5566 just for easy to remember. However, if you are planning to generate a System Information Function as patch and later submit to PostgreSQL community, then you better follow the rule to minimize the risk of OID collisions with other patches. What the PostgreSQL community recommended is a random OID number between <code>8000—9999</code>. Here how it is described in the official document, <code>When choosing OIDs for a patch that is not expected to be committed immediately, best practice is to use a group of more-or-less consecutive OIDs starting with some random choice in the range 8000—9999.</code> </p><p>After this system information initial data definition, we need to define the actual c function which can help to retrieve the information we need. In the case above, there might be a bunch of SAVEPOINTs in one transaction, so we need return a list of those ongoing transaction IDs. Below is an example, which refer to the way that how the function <code>txid_current_snapshot</code> was built.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line"> * Same as txid_current_snapshot(), but returns top and sub transactions list</span><br><span class="line"> *</span><br><span class="line"> *      Return current top and sub transactions in TXID format</span><br><span class="line"> *</span><br><span class="line"> * Note that both top-transaction and sub-transaction XIDs are included.</span><br><span class="line"> *&#x2F;</span><br><span class="line">Datum</span><br><span class="line">current_xid_list(PG_FUNCTION_ARGS)</span><br><span class="line">&#123;</span><br><span class="line">    TxidSnapshot *snap;</span><br><span class="line">    uint32      nxip,</span><br><span class="line">                i;</span><br><span class="line">    TxidEpoch   state;</span><br><span class="line">    Snapshot    cur;</span><br><span class="line">    xl_xact_assignment *sublist;</span><br><span class="line">    TransactionId curxid &#x3D; GetCurrentTransactionIdIfAny();</span><br><span class="line"></span><br><span class="line">    cur &#x3D; GetActiveSnapshot();</span><br><span class="line">    if (cur &#x3D;&#x3D; NULL)</span><br><span class="line">        elog(ERROR, &quot;no active snapshot set&quot;);</span><br><span class="line"></span><br><span class="line">    load_xid_epoch(&amp;state);</span><br><span class="line"></span><br><span class="line">    StaticAssertStmt(MAX_BACKENDS * 2 &lt;&#x3D; TXID_SNAPSHOT_MAX_NXIP,</span><br><span class="line">                     &quot;possible overflow in txid_current_snapshot()&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;* allocate *&#x2F;</span><br><span class="line">    nxip &#x3D; cur-&gt;xcnt;</span><br><span class="line">    snap &#x3D; palloc(TXID_SNAPSHOT_SIZE(nxip));</span><br><span class="line">    sublist &#x3D; palloc(MinSizeOfXactAssignment);</span><br><span class="line"></span><br><span class="line">    &#x2F;* fill *&#x2F;</span><br><span class="line">    GetCurrentSubTransactionIdList(sublist);</span><br><span class="line">    snap-&gt;xmin &#x3D; sublist-&gt;xtop;</span><br><span class="line">    snap-&gt;xmax &#x3D; curxid;</span><br><span class="line">    snap-&gt;nxip &#x3D; sublist-&gt;nsubxacts;</span><br><span class="line">    for (i &#x3D; 0; i &lt; snap-&gt;nxip; i++)</span><br><span class="line">        snap-&gt;xip[i] &#x3D; sublist-&gt;xsub[i];</span><br><span class="line"></span><br><span class="line">    sort_snapshot(snap);</span><br><span class="line"></span><br><span class="line">    &#x2F;* set size after sorting, because it may have removed duplicate xips *&#x2F;</span><br><span class="line">    SET_VARSIZE(snap, TXID_SNAPSHOT_SIZE(snap-&gt;nxip));</span><br><span class="line"></span><br><span class="line">    PG_RETURN_POINTER(snap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the above function, you can define your data format. We decided to define a function which can help retrieve the transaction IDs within current transaction.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line"> * GetCurrentSubTransactionIdList</span><br><span class="line"> *&#x2F;</span><br><span class="line">void</span><br><span class="line">GetCurrentSubTransactionIdList(xl_xact_assignment *list)</span><br><span class="line">&#123;</span><br><span class="line">   TransactionState s &#x3D; CurrentTransactionState;</span><br><span class="line"></span><br><span class="line">   list-&gt;nsubxacts &#x3D; 0;</span><br><span class="line">   list-&gt;xtop &#x3D; GetTopTransactionIdIfAny();</span><br><span class="line"></span><br><span class="line">   for (s &#x3D; CurrentTransactionState; s !&#x3D; NULL; s &#x3D; s-&gt;parent)</span><br><span class="line">   &#123;</span><br><span class="line">       if (s-&gt;state &#x3D;&#x3D; TRANS_ABORT)</span><br><span class="line">           continue;</span><br><span class="line">       if (!FullTransactionIdIsValid(s-&gt;fullTransactionId))</span><br><span class="line">           continue;</span><br><span class="line"></span><br><span class="line">       list-&gt;xsub[list-&gt;nsubxacts++] &#x3D; s-&gt;fullTransactionId.value;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now, if you recompile PostgreSQL with above changes (of course, you need to declare the functions in proper files), you should be able to use your own System Information Function to see the difference based on what we has discussed at the beginning.</p><h4 id="4-Testing"><a href="#4-Testing" class="headerlink" title="4. Testing"></a>4. Testing</h4><p>Once build success, restart the PostgreSQL server. Now, let’s try the previous SQL query again. As you can see, a different transaction ID <code>489</code> after a checkpoint is showing up.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# INSERT INTO tbl VALUES(&#39;HelloWorld-1&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line">postgres&#x3D;# SELECT txid_current();</span><br><span class="line"> txid_current </span><br><span class="line">--------------</span><br><span class="line">          488</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SAVEPOINT AA;</span><br><span class="line">SAVEPOINT</span><br><span class="line">postgres&#x3D;# INSERT INTO tbl VALUES(&#39;HelloWorld-2&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT txid_current();</span><br><span class="line"> txid_current </span><br><span class="line">--------------</span><br><span class="line">          488</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT current_xid_list();</span><br><span class="line"> current_xid_list </span><br><span class="line">------------------</span><br><span class="line"> 488:489:488,489</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><p>If you add another savepoint, and then compare your newly added function <code>current_xid_list()</code> with existing <code>txid_current()</code>, you can see that <code>current_xid_list()</code> displays not only the top transaction ID, but also all the transaction IDs after each savepoint. </p><h4 id="8-Summary"><a href="#8-Summary" class="headerlink" title="8. Summary"></a>8. Summary</h4><p>In this blog, we discussed PostgreSQL System Information Functions, and perform a simple walk-through about how to create your own System Information Function following the official document, and run some simple tests.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi_sys_info_fun.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="WAL" scheme="https://idrawone.github.io/categories/PostgreSQL/WAL/"/>
    
      <category term="Streaming" scheme="https://idrawone.github.io/categories/PostgreSQL/WAL/Streaming/"/>
    
      <category term="Replication" scheme="https://idrawone.github.io/categories/PostgreSQL/WAL/Streaming/Replication/"/>
    
    
  </entry>
  
  <entry>
    <title>How to setup Postgres 13 WAL streaming replication on Ubuntu 18.04</title>
    <link href="https://idrawone.github.io/2021/02/03/how-to-setup-wal-streaming-replication-for-postgresql13/"/>
    <id>https://idrawone.github.io/2021/02/03/how-to-setup-wal-streaming-replication-for-postgresql13/</id>
    <published>2021-02-03T08:00:00.000Z</published>
    <updated>2021-02-03T19:59:44.942Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-wal-streaming.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL supports different type of replications, i.e. logical and physical. There are many tutorials discussed about the replications. This blog is a simply walk-through of the WAL Streaming replication using the latest Postgresql-13 on Ubuntu 18.04.</p><h4 id="2-Install-Postgresql-13-from-source-code"><a href="#2-Install-Postgresql-13-from-source-code" class="headerlink" title="2. Install Postgresql-13 from source code"></a>2. Install Postgresql-13 from source code</h4><p>In this blog, we will install Postgresql from the source code, so that this environment can be used for later development. Simply prepare two Ubuntu 18.04 using VirtualBox with below <a href="/images/img/wal-streaming-net.png">Network settings</a>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Primary: 192.168.0.181</span><br><span class="line">Standby: 192.168.0.182</span><br></pre></td></tr></table></figure><p>It is pretty simple to install postgres from source code. Here we checkout the Postgresql-13 stable branch from github.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir sandbox</span><br><span class="line">$ cd sandbox&#x2F;</span><br><span class="line">$ git clone https:&#x2F;&#x2F;github.com&#x2F;postgres&#x2F;postgres</span><br><span class="line">$ cd postgres&#x2F;</span><br><span class="line">$ git checkout REL_13_STABLE</span><br></pre></td></tr></table></figure><p>Install the basic build environment on Ubuntu 18.04 and then compile and install Postgres by using below commands,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install -y pkg-config build-essential libreadline-dev bison flex</span><br><span class="line">$ .&#x2F;configure --prefix&#x3D;$HOME&#x2F;sandbox&#x2F;postgres --enable-debug CFLAGS&#x3D;&#39;-ggdb -O0&#39;</span><br><span class="line">$ make clean &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>Setup the environment for Postgres database, for example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PGDATA&#x3D;$HOME&#x2F;sandbox&#x2F;pgdata</span><br><span class="line">export PATH&#x3D;$HOME&#x2F;sandbox&#x2F;pgapp&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure><h4 id="3-Setup-Primary-Server"><a href="#3-Setup-Primary-Server" class="headerlink" title="3. Setup Primary Server"></a>3. Setup Primary Server</h4><p>In order to setup the WAL streaming replication, first, let’s create a new database by running the command below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">initdb -D $PGDATA</span><br></pre></td></tr></table></figure><p>then we need to add the permission to <code>pg_hba.conf</code> file to enable a Standby server to access a Primary server.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host   replication   all   192.168.0.182&#x2F;32   trust</span><br></pre></td></tr></table></figure><p>and then update <code>postgresql.conf</code> file to let the Primary server listen on all network interface so that a standby can connect to it.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">listen_addresses &#x3D; &#39;*&#39;</span><br><span class="line"></span><br><span class="line">synchronous_standby_names &#x3D; &#39;*&#39;</span><br></pre></td></tr></table></figure><p>After all the changes changes, we can start the Primary server,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pg_ctl -D $PGDATA -l &#x2F;tmp&#x2F;logfile start</span><br></pre></td></tr></table></figure><h4 id="4-Setup-Standby-Server"><a href="#4-Setup-Standby-Server" class="headerlink" title="4. Setup Standby Server"></a>4. Setup Standby Server</h4><p>Once the Primary server is up, we need to create a backup base. This can be done on either Primary side or Standby side. Below is the command we can run on Standby server directly.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pg_basebackup --pgdata&#x3D;$PGDATA --format&#x3D;p --write-recovery-conf --checkpoint&#x3D;fast --label&#x3D;mffb --progress --host&#x3D;192.168.0.181 --port&#x3D;5432 --username&#x3D;vbox1804</span><br></pre></td></tr></table></figure><p>At this point, most of the tutorial will discuss about the <code>recovery.conf</code> setup. However, PG has removed <code>recovery.conf</code> file and merged the corresponding configuration to <code>postgresql.conf</code>. Without knowing this, if you simply follow some old tutorials, you may get an error like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FATAL:  using recovery command file &quot;recovery.conf&quot; is not supported</span><br></pre></td></tr></table></figure><p>The reason is that the <code>recovery.conf</code> has been removed and the relevant configuration has been merged into <code>postgresql.conf</code>. For details, please check the commit below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">commit 2dedf4d9a899b36d1a8ed29be5efbd1b31a8fe85</span><br><span class="line">Author: Peter Eisentraut &lt;peter_e@gmx.net&gt;</span><br><span class="line">Date:   Sun Nov 25 16:31:16 2018 +0100</span><br><span class="line"></span><br><span class="line">    Integrate recovery.conf into postgresql.conf</span><br><span class="line">    </span><br><span class="line">    recovery.conf settings are now set in postgresql.conf (or other GUC</span><br><span class="line">    sources).  Currently, all the affected settings are PGC_POSTMASTER;</span><br><span class="line">    this could be refined in the future case by case.</span><br><span class="line">    </span><br><span class="line">    Recovery is now initiated by a file recovery.signal.  Standby mode is</span><br><span class="line">    initiated by a file standby.signal.  The standby_mode setting is</span><br><span class="line">    gone.  If a recovery.conf file is found, an error is issued.</span><br><span class="line">    </span><br><span class="line">    The trigger_file setting has been renamed to promote_trigger_file as</span><br><span class="line">    part of the move.</span><br><span class="line">    </span><br><span class="line">    The documentation chapter &quot;Recovery Configuration&quot; has been integrated</span><br><span class="line">    into &quot;Server Configuration&quot;.</span><br><span class="line">    </span><br><span class="line">    pg_basebackup -R now appends settings to postgresql.auto.conf and</span><br><span class="line">    creates a standby.signal file.</span><br><span class="line">    </span><br><span class="line">    Author: Fujii Masao &lt;masao.fujii@gmail.com&gt;</span><br><span class="line">    Author: Simon Riggs &lt;simon@2ndquadrant.com&gt;</span><br><span class="line">    Author: Abhijit Menon-Sen &lt;ams@2ndquadrant.com&gt;</span><br><span class="line">    Author: Sergei Kornilov &lt;sk@zsrv.org&gt;</span><br><span class="line">    Discussion: https:&#x2F;&#x2F;www.postgresql.org&#x2F;message-id&#x2F;flat&#x2F;607741529606767@web3g.yandex.ru&#x2F;</span><br></pre></td></tr></table></figure><p>Now, let’s just make a simple change for some basic parameters to Standby Server <code>postgresql.conf</code> file.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">primary_conninfo &#x3D; &#39;host&#x3D;192.168.0.181 port&#x3D;5432 user&#x3D;xbox1804 password&#x3D;mypassword&#39; # connection string to sending server</span><br><span class="line">primary_slot_name &#x3D; &#39;standby1_slot&#39;     # replication slot on sending server</span><br></pre></td></tr></table></figure><h4 id="5-Create-replication-slot-on-Primary-Server"><a href="#5-Create-replication-slot-on-Primary-Server" class="headerlink" title="5. Create replication slot on Primary Server"></a>5. Create replication slot on Primary Server</h4><p>In order to allow the Standby to connect to Primary, we need to create the corresponding replication slot like below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# select * from pg_create_physical_replication_slot(&#39;standby1_slot&#39;);</span><br><span class="line">   slot_name   | lsn </span><br><span class="line">---------------+-----</span><br><span class="line"> standby1_slot | </span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# select slot_name, slot_type, active, wal_status from pg_replication_slots;</span><br><span class="line">   slot_name   | slot_type | active | wal_status </span><br><span class="line">---------------+-----------+--------+------------</span><br><span class="line"> standby1_slot | physical  | f      | </span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><h4 id="6-Start-Standby-Server"><a href="#6-Start-Standby-Server" class="headerlink" title="6. Start Standby Server"></a>6. Start Standby Server</h4><p>Once the replication slot has been created i.e. ‘standby1_slot’, let’s start the Standby server.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pg_ctl -D $PGDATA -l &#x2F;tmp&#x2F;logfile start</span><br></pre></td></tr></table></figure><p>If the Standby server is setup properly, then you should see below message from the log file.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOG:  started streaming WAL from primary at 0&#x2F;3000000 on timeline 1</span><br></pre></td></tr></table></figure><p>Now, if you check the replication slot on Primary server again, you should see the replication slot is <code>active</code> and the <code>wal_status</code> has been changed to <code>reserved</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# select slot_name, slot_type, active, wal_status from pg_replication_slots;</span><br><span class="line">   slot_name   | slot_type | active | wal_status </span><br><span class="line">---------------+-----------+--------+------------</span><br><span class="line"> standby1_slot | physical  | t      | reserved</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><h4 id="7-Test-WAL-Streaming-replication"><a href="#7-Test-WAL-Streaming-replication" class="headerlink" title="7. Test WAL Streaming replication"></a>7. Test WAL Streaming replication</h4><p>After all the settings has been done properly, we can start a simple test to verify the wal streaming replication setup.<br>First, let’s check if there is any relations on Primary server, for example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# \d</span><br><span class="line">Did not find any relations.</span><br></pre></td></tr></table></figure><p>You can do the same check on Standby server side. After that, let’s create a table on Primary server,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create table tbl1(id int, text varchar(10));</span><br><span class="line">CREATE TABLE</span><br><span class="line">postgres&#x3D;# \d</span><br><span class="line">        List of relations</span><br><span class="line"> Schema | Name | Type  |  Owner   </span><br><span class="line">--------+------+-------+----------</span><br><span class="line"> public | tbl1 | table | vbox1804</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><p>Then simply insert one record like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# insert into tbl1 values (1, &#39;helloworld&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line">postgres&#x3D;# select * from tbl1;</span><br><span class="line"> id |    text    </span><br><span class="line">----+------------</span><br><span class="line">  1 | helloworld</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;#</span><br></pre></td></tr></table></figure><p>Now, if you check on the Standby server, you should be able to see the table and a record have been replicated.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# \d</span><br><span class="line">Did not find any relations.</span><br><span class="line">postgres&#x3D;# \d</span><br><span class="line">        List of relations</span><br><span class="line"> Schema | Name | Type  |  Owner   </span><br><span class="line">--------+------+-------+----------</span><br><span class="line"> public | tbl1 | table | vbox1804</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# select * from tbl1;</span><br><span class="line"> id |    text    </span><br><span class="line">----+------------</span><br><span class="line">  1 | helloworld</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;#</span><br></pre></td></tr></table></figure><h4 id="8-Summary"><a href="#8-Summary" class="headerlink" title="8. Summary"></a>8. Summary</h4><p>This blog simply walk-through a very basic WAL streaming replication, if you want to know more about the replication, you can always check it out on <a href="https://www.postgresql.org/docs/13/runtime-config-replication.html" target="_blank" rel="noopener">Postgresql official website</a>.</p><p><em><strong>Reference:</strong></em> </p><p><a href="https://wiki.postgresql.org/wiki/Binary_Replication_Tutorial" target="_blank" rel="noopener">1. Database World</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-wal-streaming.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="WAL" scheme="https://idrawone.github.io/categories/PostgreSQL/WAL/"/>
    
      <category term="Streaming" scheme="https://idrawone.github.io/categories/PostgreSQL/WAL/Streaming/"/>
    
      <category term="Replication" scheme="https://idrawone.github.io/categories/PostgreSQL/WAL/Streaming/Replication/"/>
    
    
  </entry>
  
  <entry>
    <title>How to dump out a backtrace at runtime</title>
    <link href="https://idrawone.github.io/2020/12/14/how-to-dump-a-backtrace-at-runtime/"/>
    <id>https://idrawone.github.io/2020/12/14/how-to-dump-a-backtrace-at-runtime/</id>
    <published>2020-12-14T08:00:00.000Z</published>
    <updated>2020-12-14T23:57:03.745Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-gdb-backtrace.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL is a great open source database developed and maintained by many great software engineers around the world. In each release, there are many features added to this open source database. For example, one feature is very helpful for developer is <code>backtrace_functions</code> introduced in <a href="https://www.postgresql.org/docs/release/13.0/" target="_blank" rel="noopener">PostgreSQL 13</a> , which allows a developer to dump out the <code>backtrace</code> when certain errors happened on the server. In this blog, I am going to explain it in a little bit more detail.</p><h4 id="2-What-is-backtrace-functions"><a href="#2-What-is-backtrace-functions" class="headerlink" title="2. What is backtrace_functions?"></a>2. What is <code>backtrace_functions</code>?</h4><p>The <code>backtrace_functions</code> option is an option introduced for developers as it is described <a href="https://www.postgresql.org/docs/13/runtime-config-developer.html" target="_blank" rel="noopener">here</a>. You can specify a list of c function names separated by comma, if an error is raised and matches any c function in the given list, then the backtrace will be logged into the logfile. This is very useful for debugging some specific areas of the source code, especially when the error happens randomly. As the document also mentioned, this option is not available on all platforms, and quality of the backtraces depends on the compilation options. For this reason, all the examples used in this blog were tested on Ubuntu 18.04 with gcc version 7.5.0.</p><h4 id="3-How-to-make-it-work"><a href="#3-How-to-make-it-work" class="headerlink" title="3. How to make it work?"></a>3. How to make it work?</h4><p>This feature was first committed in Nov, 2019 as showing below.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">commit 71a8a4f6e36547bb060dbcc961ea9b57420f7190</span><br><span class="line">Author: Alvaro Herrera &lt;alvherre@alvh.no-ip.org&gt;</span><br><span class="line">Date:   Fri Nov 8 15:44:20 2019 -0300</span><br><span class="line"></span><br><span class="line">    Add backtrace support for error reporting</span><br></pre></td></tr></table></figure><p>To use this feature, you need to add the key word <code>backtrace_functions</code> to <code>postgresql.conf</code> file with the c function names. It can be either a single c function name or a list of c function names separated by comma. In this blog, we use <code>circle_in</code> as an example. Here is what I added to my <code>postgresql.conf</code> file.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ tail -n1 $PGDATA&#x2F;postgresql.conf</span><br><span class="line">backtrace_functions&#x3D;&#39;circle_in&#39;</span><br></pre></td></tr></table></figure><p>After restart the server, use <code>psql</code> connect to the server and enter below SQL queries (The postgresql source code used in this example is based on PostgreSQL13 development branch in March 2020, you can create your own error if you want to test this feature). </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create temp table src (f1 text);</span><br><span class="line">postgres&#x3D;# INSERT INTO tbl_circle(a) VALUES(&#39;( 1 , 1 ) , 5&#39;::circle );</span><br><span class="line">ERROR:  invalid input syntax for type circle: &quot;( 1 , 1 ) , 5&quot;</span><br><span class="line">LINE 1: INSERT INTO tbl_circle(a) VALUES(&#39;( 1 , 1 ) , 5&#39;::circle );</span><br></pre></td></tr></table></figure><p>An error is raised, now, if you dump the logfile, <code>$ cat logfile</code> you should see something like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">2020-12-14 13:43:22.541 PST [25220] ERROR:  invalid input syntax for type circle: &quot;( 1 , 1 ) , 5&quot; at character 34</span><br><span class="line">2020-12-14 13:43:22.541 PST [25220] BACKTRACE:  </span><br><span class="line">    postgres: david postgres [local] INSERT(circle_in+0x1ca) [0x55bc1cdfaa8a]</span><br><span class="line">    postgres: david postgres [local] INSERT(InputFunctionCall+0x7b) [0x55bc1cec375b]</span><br><span class="line">    postgres: david postgres [local] INSERT(OidInputFunctionCall+0x48) [0x55bc1cec39c8]</span><br><span class="line">    postgres: david postgres [local] INSERT(coerce_type+0x19a) [0x55bc1cb9d72a]</span><br><span class="line">    postgres: david postgres [local] INSERT(coerce_to_target_type+0x9d) [0x55bc1cb9e0ed]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x1c748f) [0x55bc1cba248f]</span><br><span class="line">    postgres: david postgres [local] INSERT(transformExpr+0x14) [0x55bc1cba59f4]</span><br><span class="line">    postgres: david postgres [local] INSERT(transformExpressionList+0x9f) [0x55bc1cbb273f]</span><br><span class="line">    postgres: david postgres [local] INSERT(transformStmt+0x1a47) [0x55bc1cb782d7]</span><br><span class="line">    postgres: david postgres [local] INSERT(parse_analyze+0x4f) [0x55bc1cb7957f]</span><br><span class="line">    postgres: david postgres [local] INSERT(pg_analyze_and_rewrite+0x12) [0x55bc1cd9fd62]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x3c531f) [0x55bc1cda031f]</span><br><span class="line">    postgres: david postgres [local] INSERT(PostgresMain+0x1f04) [0x55bc1cda25b4]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x34c168) [0x55bc1cd27168]</span><br><span class="line">    postgres: david postgres [local] INSERT(PostmasterMain+0xeff) [0x55bc1cd2827f]</span><br><span class="line">    postgres: david postgres [local] INSERT(main+0x4a4) [0x55bc1ca9b4e4]</span><br><span class="line">    &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libc.so.6(__libc_start_main+0xe7) [0x7f6c22eeab97]</span><br><span class="line">    postgres: david postgres [local] INSERT(_start+0x2a) [0x55bc1ca9b5aa]</span><br><span class="line">2020-12-14 13:43:22.541 PST [25220] STATEMENT:  INSERT INTO tbl_circle(a) VALUES(&#39;( 1 , 1 ) , 5&#39;::circle );</span><br></pre></td></tr></table></figure><p>As we can see the error is happening in <code>circle_in</code> function, which is called by function <code>InputFunctionCall</code>, so on and so forth. This is exactly like the backtrace when you are debugging the source code using gdb, but you may also find that some function names are showing up as a hex string, such as <code>0x3c531f</code>. The reason some function names are not showing up is because they are static functions. For these functions, we need to use the <code>addr2line</code> to convert the addresses into file names and line numbers. For example, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addr2line 0x3c531f -f -e &#96;which postgres&#96;</span><br></pre></td></tr></table></figure><p>, where <code>-f</code>  displays the function names as well as file and line number, <code>-e</code> used to specify the name of the executable for which addresses should be translated.</p><p>It depends on the compilation parameters, if you compile the postgre with default CFLAG, you may get something like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ addr2line 0x3c531f -f -e &#96;which postgres&#96;</span><br><span class="line">exec_simple_query</span><br><span class="line">postgres.c:?</span><br></pre></td></tr></table></figure><p>Where the line number doesn’t show up. To get the line number and file name, let’s add the option <code>-ggdb</code> to <code>CFLAGS</code> and then recompile the source code.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;configure &#39;--prefix&#x3D;&#x2F;home&#x2F;david&#x2F;pgapp&#39; &#39;CFLAGS&#x3D;-ggdb&#39;</span><br></pre></td></tr></table></figure><p>Now, if you repeat the above test, then you should get a similar backtrace like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">2020-12-14 13:56:28.780 PST [3459] ERROR:  invalid input syntax for type circle: &quot;( 1 , 1 ) , 5&quot; at character 34</span><br><span class="line">2020-12-14 13:56:28.780 PST [3459] BACKTRACE:  </span><br><span class="line">    postgres: david postgres [local] INSERT(circle_in+0x275) [0x56522b34137f]</span><br><span class="line">    postgres: david postgres [local] INSERT(InputFunctionCall+0xe9) [0x56522b457d39]</span><br><span class="line">    postgres: david postgres [local] INSERT(OidInputFunctionCall+0x4b) [0x56522b45805f]</span><br><span class="line">    postgres: david postgres [local] INSERT(stringTypeDatum+0x5e) [0x56522afe3220]</span><br><span class="line">    postgres: david postgres [local] INSERT(coerce_type+0x312) [0x56522afc055b]</span><br><span class="line">    postgres: david postgres [local] INSERT(coerce_to_target_type+0x95) [0x56522afc017b]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x237e37) [0x56522afcde37]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x232606) [0x56522afc8606]</span><br><span class="line">    postgres: david postgres [local] INSERT(transformExpr+0x3a) [0x56522afc83a2]</span><br><span class="line">    postgres: david postgres [local] INSERT(transformExpressionList+0x133) [0x56522afdee38]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x1ecf87) [0x56522af82f87]</span><br><span class="line">    postgres: david postgres [local] INSERT(transformStmt+0x96) [0x56522af821ac]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x1ec114) [0x56522af82114]</span><br><span class="line">    postgres: david postgres [local] INSERT(transformTopLevelStmt+0x27) [0x56522af8200f]</span><br><span class="line">    postgres: david postgres [local] INSERT(parse_analyze+0x73) [0x56522af81e85]</span><br><span class="line">    postgres: david postgres [local] INSERT(pg_analyze_and_rewrite+0x49) [0x56522b2c1bcb]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x52c2b5) [0x56522b2c22b5]</span><br><span class="line">    postgres: david postgres [local] INSERT(PostgresMain+0x813) [0x56522b2c6895]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x4889d7) [0x56522b21e9d7]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x488111) [0x56522b21e111]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x48469f) [0x56522b21a69f]</span><br><span class="line">    postgres: david postgres [local] INSERT(PostmasterMain+0x1283) [0x56522b219e5a]</span><br><span class="line">    postgres: david postgres [local] INSERT(+0x395c54) [0x56522b12bc54]</span><br><span class="line">    &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libc.so.6(__libc_start_main+0xe7) [0x7f3fc9817b97]</span><br><span class="line">    postgres: david postgres [local] INSERT(_start+0x2a) [0x56522ae4d40a]</span><br><span class="line">2020-12-14 13:56:28.780 PST [3459] STATEMENT:  INSERT INTO tbl_circle(a) VALUES(&#39;( 1 , 1 ) , 5&#39;::circle );</span><br></pre></td></tr></table></figure><p>Let’s run the command <code>addr2line</code> with the new hex address string again,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ addr2line 0x52c2b5 -f -e &#96;which postgres&#96;</span><br><span class="line">exec_simple_query</span><br><span class="line">&#x2F;home&#x2F;david&#x2F;postgres&#x2F;src&#x2F;backend&#x2F;tcop&#x2F;postgres.c:1155</span><br></pre></td></tr></table></figure><p>Now, we get the function name, file name and the line number.</p><h4 id="4-Summary"><a href="#4-Summary" class="headerlink" title="4. Summary"></a>4. Summary</h4><p>This blog simply discussed one very useful option introduced to PostgreSQL 13 for developers. I use this option a lot during my daily development work, and it helps me quickly locate the errors. I also use this feature when someone reports an error which happens randomly. To debug such issue, I simply enable it with the c function names. When the error happens again, then I can get the exactly backtrace. The <code>backtrace_functions</code> does make my work much easier when tracing a bug.</p><p><em><strong>Reference:</strong></em> </p><p><a href="https://amitdkhan-pg.blogspot.com/2020/07/backtraces-in-postgresql.html" target="_blank" rel="noopener">1. Database World</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-gdb-backtrace.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="Debug" scheme="https://idrawone.github.io/categories/PostgreSQL/Debug/"/>
    
      <category term="Backtrace" scheme="https://idrawone.github.io/categories/PostgreSQL/Debug/Backtrace/"/>
    
    
  </entry>
  
  <entry>
    <title>Free Space Mapping file in details</title>
    <link href="https://idrawone.github.io/2020/10/23/Heap-freespace-in-details/"/>
    <id>https://idrawone.github.io/2020/10/23/Heap-freespace-in-details/</id>
    <published>2020-10-23T08:00:00.000Z</published>
    <updated>2020-10-23T22:37:05.095Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-fsm-page.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>Previously, we discussed the <code>MAIN</code> fork file and corresponding extension at <a href="https://www.highgo.ca/2020/10/09/heap-file-and-page-in-details" target="_blank" rel="noopener">Heap file and page in details</a>. This blog will explain a little bit more about the Free Space Mapping file and corresponding extension.</p><h4 id="2-What-is-a-Free-Space-Mapping-file"><a href="#2-What-is-a-Free-Space-Mapping-file" class="headerlink" title="2. What is a Free Space Mapping file"></a>2. What is a Free Space Mapping file</h4><p>A Free Space Mapping, FSM, file is a file that keeps tracking the availability of free space inside a page. The FSM file is used to quickly locate a page with enough<br>free space to hold a record to be stored during insertion, and it will be updated during an insertion or a vacuum on the table.</p><p>Start from PostgreSQL 8.4 each relation has its own extensible FSM files stored on disk. The FSM file is stored under its relation folder. From previous example, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create table orders1 (id int4, test text) using heap;</span><br><span class="line">postgres&#x3D;# insert into orders1 values(1, &#39;hello world!&#39;);</span><br></pre></td></tr></table></figure><p>You will see the heap files under the database folder like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ls -ltrh &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384*</span><br><span class="line">-rw------- 1 user user  24K Oct  8 14:33 &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384_fsm</span><br><span class="line">-rw------- 1 user user 8.0K Oct  8 14:34 &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384_vm</span><br><span class="line">-rw------- 1 user user 512K Oct  8 14:34 &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384</span><br></pre></td></tr></table></figure><p>Where <code>16384</code> is the table orders1’s oid, and <code>16384_fsm</code> is the corresponding <code>Free Space Mapping</code> file.</p><h4 id="3-How-the-Free-Space-Mapping-files-are-managed"><a href="#3-How-the-Free-Space-Mapping-files-are-managed" class="headerlink" title="3. How the Free Space Mapping files are managed"></a>3. How the Free Space Mapping files are managed</h4><p>Before PostgreSQL 8.4, the FSM is maintained in memory with the limitation of fixed-size. Now, all FSM files are on disk and can be extended in the same way as heap segmentation files. The FSM files will be updated during an insertion and a Vacuum process either periodically or triggered manually. In some conditions, the FSM may need to be rebuilt, for example, if a leaf node’s value is less than the root node or if there is truncate operation.</p><p>FSM file is mainly used to quickly locate a page for insert operation and in the meantime it helps to speed up the insertion by trying to inert records in existing pages instead of extend a new page. By doing this, it not only help speed up the insertion but also help improve the selection performance. Moreover, the user to implement various strategies, like preferring pages closer to a given page, or spreading the load across the table. </p><h4 id="4-What-is-inside-in-an-FSM-page"><a href="#4-What-is-inside-in-an-FSM-page" class="headerlink" title="4. What is inside in an FSM page"></a>4. What is inside in an FSM page</h4><p>Inside the FSM page, there are two binary tree structure are used: low-level binary tree is used to record the amount of free space on each heap page; high-level binary tree is used scale up the low-level data structure. For details, please reference the <a href="https://github.com/postgres/postgres/blob/master/src/backend/storage/freespace/README" target="_blank" rel="noopener">README</a>.</p><h4 id="5-The-extension-for-FSM"><a href="#5-The-extension-for-FSM" class="headerlink" title="5. The extension for FSM"></a>5. The extension for FSM</h4><p>The <code>pg_freespacemap</code> extension provides the functions that allow you to inspect the free space in each page for a given relation/table. So far, there is only one function provide in <code>pg_freespacemap</code>, i.e. <code>pg_freespace</code>. This function can be used retrieve the amount of free space on each page by giving different parameters. To use this extension, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create extension pg_freespacemap;</span><br><span class="line">CREATE EXTENSION</span><br><span class="line">postgres&#x3D;# create table orders1 (id int4, test text);</span><br><span class="line">CREATE TABLE</span><br><span class="line">postgres&#x3D;# insert into orders1 values(generate_series(1,1000), &#39;hello world!&#39;);</span><br><span class="line">INSERT 0 1000</span><br></pre></td></tr></table></figure><ul><li>retrieve free space for all pages <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# vacuum orders1;</span><br><span class="line">VACUUM</span><br><span class="line">postgres&#x3D;# SELECT * FROM pg_freespace(&#39;orders1&#39;);</span><br><span class="line"> blkno | avail </span><br><span class="line">-------+-------</span><br><span class="line">     0 |     0</span><br><span class="line">     1 |     0</span><br><span class="line">     2 |     0</span><br><span class="line">     3 |     0</span><br><span class="line">     4 |     0</span><br><span class="line">     5 |     0</span><br><span class="line">     6 |  5120</span><br><span class="line">(7 rows)</span><br></pre></td></tr></table></figure>From the above results, it tells that the first 5 pages are all full, only the last page, page6, has some free space are available. </li></ul><p>Let’s delete different number of records in each page, and then check free space again to what is happening inside.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# delete from orders1 where id%2&#x3D;1 and id &lt; 158;</span><br><span class="line">DELETE 79</span><br><span class="line">postgres&#x3D;# delete from orders1 where id%4&#x3D;1 and id &gt;&#x3D; 158 and id &lt; 315;</span><br><span class="line">DELETE 39</span><br><span class="line">postgres&#x3D;# delete from orders1 where id%8&#x3D;1 and id &gt;&#x3D; 315 and id &lt; 472;</span><br><span class="line">DELETE 19</span><br><span class="line">postgres&#x3D;# delete from orders1 where id%16&#x3D;1 and id &gt;&#x3D; 472 and id &lt; 629;</span><br><span class="line">DELETE 10</span><br><span class="line">postgres&#x3D;# delete from orders1 where id%32&#x3D;1 and id &gt;&#x3D; 629 and id &lt; 786;</span><br><span class="line">DELETE 5</span><br><span class="line">postgres&#x3D;# delete from orders1 where id%64&#x3D;1 and id &gt;&#x3D; 786;</span><br><span class="line">DELETE 3</span><br><span class="line">postgres&#x3D;# vacuum orders1;</span><br><span class="line">VACUUM</span><br><span class="line">postgres&#x3D;# SELECT * FROM pg_freespace(&#39;orders1&#39;);</span><br><span class="line"> blkno | avail </span><br><span class="line">-------+-------</span><br><span class="line">     0 |  3776</span><br><span class="line">     1 |  1856</span><br><span class="line">     2 |   896</span><br><span class="line">     3 |   480</span><br><span class="line">     4 |   224</span><br><span class="line">     5 |    96</span><br><span class="line">     6 |  5184</span><br><span class="line">(7 rows)</span><br></pre></td></tr></table></figure><p>Now, we can see the amount of free space is different and it depends on how many records has been deleted.</p><ul><li><p>retrieve free space for a specific page<br>The <code>pg_freespace</code> also allow you to check the amount of free space available in a specified page, for example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# SELECT * FROM pg_freespace(&#39;orders1&#39;, 3);</span><br><span class="line"> pg_freespace </span><br><span class="line">--------------</span><br><span class="line">          480</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure></li><li><p>insert using free space<br>From the above delete examples, we know how many records deleted in each page, in other words, the maximum records can fit in for each page. Let’s perform some insertion test.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# insert into orders1 values(generate_series(1,65), &#39;hello world!&#39;);</span><br><span class="line">INSERT 0 65</span><br><span class="line">postgres&#x3D;# vacuum orders1;</span><br><span class="line">VACUUM</span><br><span class="line">postgres&#x3D;# SELECT * FROM pg_freespace(&#39;orders1&#39;);</span><br><span class="line"> blkno | avail </span><br><span class="line">-------+-------</span><br><span class="line">     0 |   672</span><br><span class="line">     1 |  1856</span><br><span class="line">     2 |   896</span><br><span class="line">     3 |   480</span><br><span class="line">     4 |   224</span><br><span class="line">     5 |    96</span><br><span class="line">     6 |  5184</span><br><span class="line">(7 rows)</span><br></pre></td></tr></table></figure><p>From the results above, we can see the records was inserted to the first page, instead of allocating a new page.</p></li></ul><h4 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6.    Summary"></a>6.    Summary</h4><p>We explained why there is a free space mapping file under corresponding relation folder, how the free space mapping files are managed, and demonstrated how to use the extension <code>pg_freespacemap</code> to check what happens when user performed some insert, delete and vacuum. In next blog, I will explain the visibility mapping files.</p><p>Ref: <a href="https://www.postgresql.org/docs/current/storage-file-layout.html" target="_blank" rel="noopener">PG Database File Layout</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-fsm-page.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. O
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="Heap" scheme="https://idrawone.github.io/categories/PostgreSQL/Heap/"/>
    
      <category term="Page" scheme="https://idrawone.github.io/categories/PostgreSQL/Heap/Page/"/>
    
      <category term="Extension" scheme="https://idrawone.github.io/categories/PostgreSQL/Heap/Page/Extension/"/>
    
      <category term="Freespace" scheme="https://idrawone.github.io/categories/PostgreSQL/Heap/Page/Extension/Freespace/"/>
    
    
  </entry>
  
  <entry>
    <title>Heap file and page in details</title>
    <link href="https://idrawone.github.io/2020/10/09/Heap-Page-in-details/"/>
    <id>https://idrawone.github.io/2020/10/09/Heap-Page-in-details/</id>
    <published>2020-10-09T08:00:00.000Z</published>
    <updated>2020-10-09T23:47:06.359Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-heap-page.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL is a great open source database, and many users chose it because of the efficiency of its central algorithms and data structures. As a software developer, I was always curious about how each part was done, such as the physical files storage. The reason is that I always see a lot of files and folders were created after a simple initdb command. For example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ls -ltr &#x2F;home&#x2F;user&#x2F;pgdata</span><br><span class="line">drwx------ 4 user user  4096 Oct  8 13:38 pg_logical</span><br><span class="line">drwx------ 5 user user  4096 Oct  8 13:38 base</span><br><span class="line">drwx------ 2 user user  4096 Oct  8 13:38 global</span><br><span class="line">…. …</span><br><span class="line">-rw------- 1 user user     3 Oct  8 13:38 PG_VERSION</span><br></pre></td></tr></table></figure><p>I can do a simple command like below to check the file <code>PG_VERSION</code>, but what about the rest of the files and folders? </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;PG_VERSION </span><br><span class="line">14</span><br></pre></td></tr></table></figure><p>In this blog, I am going to share what I learned about the <code>heap files</code> under <code>base</code> folder.</p><h4 id="1-How-the-Heap-files-are-created"><a href="#1-How-the-Heap-files-are-created" class="headerlink" title="1. How the Heap files are created?"></a>1. How the Heap files are created?</h4><p>To explain this, let’s take a look at two key data structures. </p><ul><li><code>RelFileNode</code> defined in <code>src/include/storage/felfilenode.h</code>. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedef struct RelFileNode</span><br><span class="line">&#123;</span><br><span class="line">  Oid     spcNode;    &#x2F;* tablespace *&#x2F;</span><br><span class="line">  Oid     dbNode;     &#x2F;* database *&#x2F;</span><br><span class="line">  Oid     relNode;    &#x2F;* relation *&#x2F;</span><br><span class="line">&#125; RelFileNode;</span><br></pre></td></tr></table></figure>Where, <code>spcNode</code> is the tablespace oid, <code>dbNode</code> is the database oid, and <code>relNode</code> is table oid. The table oid will be used as the file name to create the corresponding heap file. However, the Heap files will not be created unless you insert the first record to the table. For example, <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create table orders1 (id int4, test text) using heap;</span><br><span class="line">postgres&#x3D;# insert into orders1 values(1, &#39;hello world!&#39;);</span><br></pre></td></tr></table></figure>You will see the heap files under the database folder like below,<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ls -ltrh &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384*</span><br><span class="line">-rw------- 1 user user  24K Oct  8 14:33 &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384_fsm</span><br><span class="line">-rw------- 1 user user 8.0K Oct  8 14:34 &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384_vm</span><br><span class="line">-rw------- 1 user user 512K Oct  8 14:34 &#x2F;home&#x2F;user&#x2F;pgdata&#x2F;base&#x2F;12705&#x2F;16384</span><br></pre></td></tr></table></figure>Where 16384 is the table orders1’s oid. To verify it, there is a built-in function <code>pg_relation_filepath</code> which returns the first heap file segment with a relative path to the environment variable PGDATA. For example,<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# SELECT pg_relation_filepath(&#39;orders1&#39;);</span><br><span class="line"> pg_relation_filepath </span><br><span class="line">----------------------</span><br><span class="line"> base&#x2F;12705&#x2F;16384</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure></li><li><code>ForkNumber</code> defined in src/include/common/relpath.h.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">typedef enum ForkNumber</span><br><span class="line">&#123;</span><br><span class="line">  InvalidForkNumber &#x3D; -1,</span><br><span class="line">  MAIN_FORKNUM &#x3D; 0,</span><br><span class="line">  FSM_FORKNUM,</span><br><span class="line">  VISIBILITYMAP_FORKNUM,</span><br><span class="line">  INIT_FORKNUM</span><br><span class="line">&#125; ForkNumber;</span><br></pre></td></tr></table></figure>Where, <code>MAIN_FORKNUM</code> represents heap files, <code>FSM_FORKNUM</code> represents free space mapping files, and <code>VISIBILITYMAP_FORKNUM</code> represents visibility mapping files. In above example, the physical files map to the enum values <code>MAIN_FORKNUM</code>, <code>FSM_FORKNUM</code> and <code>VISIBILITYMAP_FORKNUM</code> are 16384, 16384_fsm and 16384_vm correspondingly. The rest of this blog will focus on <code>heap file</code>. </li></ul><h4 id="2-How-the-Heap-files-are-managed"><a href="#2-How-the-Heap-files-are-managed" class="headerlink" title="2. How the Heap files are managed?"></a>2. How the Heap files are managed?</h4><p>Heap file, as the fork name <code>MAIN_FORKNUM</code> indicated, is the main file used to store all the data records. The heap file will be divided into different segments when it exceeds 1GB that is the default settings. The first file is always named using the filenode (table oid), and subsequent segments will be named as filenode.1, filenode.2 etc. In theory, the segmentation rule also applies to free space mapping and visibility mapping files, but it seldom happens since free space mapping file and visibility mapping file are not increasing as fast as heap files.</p><h4 id="3-How-does-a-Page-look-like"><a href="#3-How-does-a-Page-look-like" class="headerlink" title="3. How does a Page look like?"></a>3. How does a Page look like?</h4><p>To make the data management easier, each heap file is splitted into different pages with a default size 8KB. The data structure for each page is defined by below data structures:</p><ul><li><p>ItemIdData</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedef struct ItemIdData</span><br><span class="line">&#123;</span><br><span class="line">  unsigned  lp_off:15,  &#x2F;* offset to tuple (from start of page) *&#x2F;</span><br><span class="line">      lp_flags:2, &#x2F;* state of line pointer, see below *&#x2F;</span><br><span class="line">      lp_len:15;  &#x2F;* byte length of tuple *&#x2F;</span><br><span class="line">&#125; ItemIdData;</span><br></pre></td></tr></table></figure><p>ItemIdData is the line pointer in a page, which is defined in <code>src/include/storage/itemid.h</code>.</p></li><li><p>HeapTupleFields</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">typedef struct HeapTupleFields</span><br><span class="line">&#123;</span><br><span class="line">  TransactionId t_xmin;   &#x2F;* inserting xact ID *&#x2F;</span><br><span class="line">  TransactionId t_xmax;   &#x2F;* deleting or locking xact ID *&#x2F;</span><br><span class="line"></span><br><span class="line">  union</span><br><span class="line">  &#123;</span><br><span class="line">    CommandId t_cid;    &#x2F;* inserting or deleting command ID, or both *&#x2F;</span><br><span class="line">    TransactionId t_xvac; &#x2F;* old-style VACUUM FULL xact ID *&#x2F;</span><br><span class="line">  &#125;     t_field3;</span><br><span class="line">&#125; HeapTupleFields;</span><br></pre></td></tr></table></figure><p>HeapTupleFields is part of the header for each tuple, defined in <code>src/include/access/htup_details.h</code>.</p></li><li><p>HeapTupleHeaderData</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">struct HeapTupleHeaderData</span><br><span class="line">&#123;</span><br><span class="line">  union</span><br><span class="line">  &#123;</span><br><span class="line">    HeapTupleFields t_heap;</span><br><span class="line">    DatumTupleFields t_datum;</span><br><span class="line">  &#125; t_choice;</span><br><span class="line"></span><br><span class="line">  ItemPointerData t_ctid;   &#x2F;* current TID of this or newer tuple (or a</span><br><span class="line">                 * speculative insertion token) *&#x2F;</span><br><span class="line"></span><br><span class="line">  &#x2F;* Fields below here must match MinimalTupleData! *&#x2F;</span><br><span class="line"></span><br><span class="line">#define FIELDNO_HEAPTUPLEHEADERDATA_INFOMASK2 2</span><br><span class="line">  uint16    t_infomask2;  &#x2F;* number of attributes + various flags *&#x2F;</span><br><span class="line"></span><br><span class="line">#define FIELDNO_HEAPTUPLEHEADERDATA_INFOMASK 3</span><br><span class="line">  uint16    t_infomask;   &#x2F;* various flag bits, see below *&#x2F;</span><br><span class="line"></span><br><span class="line">#define FIELDNO_HEAPTUPLEHEADERDATA_HOFF 4</span><br><span class="line">  uint8   t_hoff;     &#x2F;* sizeof header incl. bitmap, padding *&#x2F;</span><br><span class="line"></span><br><span class="line">  &#x2F;* ^ - 23 bytes - ^ *&#x2F;</span><br><span class="line"></span><br><span class="line">#define FIELDNO_HEAPTUPLEHEADERDATA_BITS 5</span><br><span class="line">  bits8   t_bits[FLEXIBLE_ARRAY_MEMBER];  &#x2F;* bitmap of NULLs *&#x2F;</span><br><span class="line"></span><br><span class="line">  &#x2F;* MORE DATA FOLLOWS AT END OF STRUCT *&#x2F;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>HeapTupleHeaderData is the tuple data structure, defined in defined in <code>src/include/access/htup_details.h</code>.</p></li></ul><p>A high level picture for a tuple looks like the picture below. <img src="/images/img/tuple.png" alt="tuple image"></p><p>But, this may be still hard to understand for an end user. Don’t worry, PG provides an extension <code>pageinspect</code>. </p><h4 id="4-The-extension-for-Page"><a href="#4-The-extension-for-Page" class="headerlink" title="4. The extension for Page"></a>4. The extension for Page</h4><p>The <code>pageinspect</code> extension provides the functions that allow you to inspect the contents of database pages at a low level, which is very useful for debugging purposes. Here are the main functions provided by <code>pageinspect</code>. To use this extension, you have to install it first, and then add it to your PG server. For example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# create extension pageinspect;</span><br><span class="line">CREATE EXTENSION</span><br></pre></td></tr></table></figure><p>Here are the functions for heap page:</p><ul><li>heap_page_items<br><code>heap_page_items</code> returns all the records within given page. It includes line pointers, tuple headers as well as tuple raw data, i.e. <code>lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |  t_data</code>.<br>All the tuples will be displayed at the moment when the page is loaded from heap file into buffer manager, no matter whether the tuple is visible or not. For example,<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# insert into orders1 values(generate_series(1, 200), &#39;hello world!&#39;);</span><br><span class="line">INSERT 0 200</span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_items(get_raw_page(&#39;orders1&#39;, 0));</span><br><span class="line"> lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                t_data                </span><br><span class="line">-----+--------+----------+--------+--------+--------+----------+---------+-------------+------------+--------+--------+-------+--------------------------------------</span><br><span class="line">   1 |   8144 |        1 |     41 |    691 |      0 |        0 | (0,1)   |           2 |       2050 |     24 |        |       | \x010000001b68656c6c6f20776f726c6421</span><br><span class="line">   2 |   8096 |        1 |     41 |    691 |      0 |        0 | (0,2)   |           2 |       2050 |     24 |        |       | \x020000001b68656c6c6f20776f726c6421</span><br><span class="line">   3 |   8048 |        1 |     41 |    691 |      0 |        0 | (0,3)   |           2 |       2050 |     24 |        |       | \x030000001b68656c6c6f20776f726c6421</span><br><span class="line">   4 |   8000 |        1 |     41 |    691 |      0 |        0 | (0,4)   |           2 |       2050 |     24 |        |       | \x040000001b68656c6c6f20776f726c6421</span><br><span class="line">   5 |   7952 |        1 |     41 |    691 |      0 |        0 | (0,5)   |           2 |       2050 |     24 |        |       | \x050000001b68656c6c6f20776f726c6421</span><br><span class="line">   6 |   7904 |        1 |     41 |    691 |      0 |        0 | (0,6)   |           2 |       2050 |     24 |        |       | \x060000001b68656c6c6f20776f726c6421</span><br></pre></td></tr></table></figure></li></ul><ul><li>tuple_data_split<br><code>tuple_data_split</code> splits tuple data into attributes and returns bytea array. For example,<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# SELECT tuple_data_split(&#39;orders1&#39;::regclass, t_data, t_infomask, t_infomask2, t_bits) FROM heap_page_items(get_raw_page(&#39;orders1&#39;, 0));</span><br><span class="line">                tuple_data_split                 </span><br><span class="line">-------------------------------------------------</span><br><span class="line"> &#123;&quot;\\x01000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> &#123;&quot;\\x02000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> &#123;&quot;\\x03000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br></pre></td></tr></table></figure></li></ul><ul><li>heap_page_item_attrs</li></ul><p><code>heap_page_item_attrs</code> is equivalent to <code>heap_page_items</code> except that it returns tuple raw data as an array of attributes. For example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 0), &#39;orders1&#39;::regclass);</span><br><span class="line"> lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                     t_attrs                     </span><br><span class="line">-----+--------+----------+--------+--------+--------+----------+---------+-------------+------------+--------+--------+-------+-------------------------------------------------</span><br><span class="line">   1 |   8144 |        1 |     41 |    591 |      0 |        0 | (0,1)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x01000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   2 |   8096 |        1 |     41 |    591 |      0 |        0 | (0,2)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x02000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   3 |   8048 |        1 |     41 |    591 |      0 |        0 | (0,3)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x03000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   ... ...</span><br></pre></td></tr></table></figure><ul><li>heap_tuple_infomask_flags<br><code>heap_tuple_infomask_flags</code> will help decode the tuple header attributes, i.e. <code>t_infomask</code> and <code>t_infomask2</code> into a human-readable set of arrays made of flag names, with one column for all the flags and one column for combined flags. For example,<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# SELECT t_ctid, raw_flags, combined_flags FROM heap_page_items(get_raw_page(&#39;orders1&#39;, 0)), LATERAL heap_tuple_infomask_flags(t_infomask, t_infomask2) WHERE t_infomask IS NOT NULL OR t_infomask2 IS NOT NULL;</span><br><span class="line"> t_ctid  |                        raw_flags                         | combined_flags </span><br><span class="line">---------+----------------------------------------------------------+----------------</span><br><span class="line"> (0,1)   | &#123;HEAP_HASVARWIDTH,HEAP_XMIN_COMMITTED,HEAP_XMAX_INVALID&#125; | &#123;&#125;</span><br><span class="line"> (0,2)   | &#123;HEAP_HASVARWIDTH,HEAP_XMIN_COMMITTED,HEAP_XMAX_INVALID&#125; | &#123;&#125;</span><br><span class="line"> (0,3)   | &#123;HEAP_HASVARWIDTH,HEAP_XMIN_COMMITTED,HEAP_XMAX_INVALID&#125; | &#123;&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="5-What-happens-on-heap-page-when-performing-insert-delete-and-vacuum"><a href="#5-What-happens-on-heap-page-when-performing-insert-delete-and-vacuum" class="headerlink" title="5. What happens on heap page when performing insert, delete and vacuum"></a>5. What happens on heap page when performing insert, delete and vacuum</h4><p>Now, we have learned something about heap file and the page inspect extension. Let’s see how the tuples are managed when user performs some insert, delete and vacuum on a table.</p><ul><li><p>Insert<br>First, let insert 200 records to a brand new table orders1,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# insert into orders1 values(generate_series(1, 200), &#39;hello world!&#39;);</span><br><span class="line">INSERT 0 200</span><br></pre></td></tr></table></figure><p>then use the function <code>heap_page_item_attrs</code> to see how the page looks like,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 0), &#39;orders1&#39;::regclass);</span><br><span class="line"> lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                     t_attrs                     </span><br><span class="line">-----+--------+----------+--------+--------+--------+----------+---------+-------------+------------+--------+--------+-------+-------------------------------------------------</span><br><span class="line">   1 |   8144 |        1 |     41 |    591 |      0 |        0 | (0,1)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x01000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   2 |   8096 |        1 |     41 |    591 |      0 |        0 | (0,2)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x02000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   3 |   8048 |        1 |     41 |    591 |      0 |        0 | (0,3)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x03000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">... ...</span><br><span class="line"> 155 |    752 |        1 |     41 |    591 |      0 |        0 | (0,155) |           2 |       2306 |     24 |        |       | &#123;&quot;\\x9b000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> 156 |    704 |        1 |     41 |    591 |      0 |        0 | (0,156) |           2 |       2306 |     24 |        |       | &#123;&quot;\\x9c000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> 157 |    656 |        1 |     41 |    591 |      0 |        0 | (0,157) |           2 |       2306 |     24 |        |       | &#123;&quot;\\x9d000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">(157 rows)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 1), &#39;orders1&#39;::regclass);</span><br><span class="line"> lp | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                     t_attrs                     </span><br><span class="line">----+--------+----------+--------+--------+--------+----------+--------+-------------+------------+--------+--------+-------+-------------------------------------------------</span><br><span class="line">  1 |   8144 |        1 |     41 |    591 |      0 |        0 | (1,1)  |           2 |       2306 |     24 |        |       | &#123;&quot;\\x9e000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">  2 |   8096 |        1 |     41 |    591 |      0 |        0 | (1,2)  |           2 |       2306 |     24 |        |       | &#123;&quot;\\x9f000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">  3 |   8048 |        1 |     41 |    591 |      0 |        0 | (1,3)  |           2 |       2306 |     24 |        |       | &#123;&quot;\\xa0000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> ... ... </span><br><span class="line"> 41 |   6224 |        1 |     41 |    591 |      0 |        0 | (1,41) |           2 |       2306 |     24 |        |       | &#123;&quot;\\xc6000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> 42 |   6176 |        1 |     41 |    591 |      0 |        0 | (1,42) |           2 |       2306 |     24 |        |       | &#123;&quot;\\xc7000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> 43 |   6128 |        1 |     41 |    591 |      0 |        0 | (1,43) |           2 |       2306 |     24 |        |       | &#123;&quot;\\xc8000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">(43 rows)</span><br></pre></td></tr></table></figure><p>As you can see, after 200 records were inserted, PG created two pages: the 1st page has 157 tuples, and the 2nd page has 43 tuples. If you try to access the 3rd page, then you will some errors like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 2), &#39;orders1&#39;::regclass);</span><br><span class="line">ERROR:  block number 2 is out of range for relation &quot;orders1&quot;</span><br></pre></td></tr></table></figure></li><li><p>Delete</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# delete from orders1 where id%2&#x3D;1;</span><br><span class="line">DELETE 100</span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 0), &#39;orders1&#39;::regclass);</span><br><span class="line"> lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                     t_attrs                     </span><br><span class="line">-----+--------+----------+--------+--------+--------+----------+---------+-------------+------------+--------+--------+-------+-------------------------------------------------</span><br><span class="line">   1 |   8144 |        1 |     41 |    598 |    599 |        0 | (0,1)   |        8194 |        258 |     24 |        |       | &#123;&quot;\\x01000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   2 |   8096 |        1 |     41 |    598 |      0 |        0 | (0,2)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x02000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   3 |   8048 |        1 |     41 |    598 |    599 |        0 | (0,3)   |        8194 |        258 |     24 |        |       | &#123;&quot;\\x03000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   4 |   8000 |        1 |     41 |    598 |      0 |        0 | (0,4)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x04000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   5 |   7952 |        1 |     41 |    598 |    599 |        0 | (0,5)   |        8194 |        258 |     24 |        |       | &#123;&quot;\\x05000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   6 |   7904 |        1 |     41 |    598 |      0 |        0 | (0,6)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x06000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br></pre></td></tr></table></figure><p>Now, for all the odd records, the <code>t_max</code> points to a different transaction (delete) id, and <code>t_infomask2</code> indicates the tuple has been deleted. For more detailed information, please check <code>t_infomask2</code> definition.</p></li><li><p>Insert a new record<br>If you insert a record now, you will find the new record is inserted into the first empty slot. In this example, the first line <code>\\xe8030000</code> is the new record with <code>id=1000</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# insert into orders1 values(1000, &#39;hello world!&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 0), &#39;orders1&#39;::regclass);</span><br><span class="line"> lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                     t_attrs                     </span><br><span class="line">-----+--------+----------+--------+--------+--------+----------+---------+-------------+------------+--------+--------+-------+-------------------------------------------------</span><br><span class="line">   1 |   4400 |        1 |     41 |    601 |      0 |        0 | (0,1)   |           2 |       2050 |     24 |        |       | &#123;&quot;\\xe8030000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   2 |   8144 |        1 |     41 |    598 |      0 |        0 | (0,2)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x02000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   3 |      0 |        0 |      0 |        |        |          |         |             |            |        |        |       | </span><br><span class="line">   4 |   8096 |        1 |     41 |    598 |      0 |        0 | (0,4)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x04000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   5 |      0 |        0 |      0 |        |        |          |         |             |            |        |        |       | </span><br><span class="line">   6 |   8048 |        1 |     41 |    598 |      0 |        0 | (0,6)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x06000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br></pre></td></tr></table></figure></li></ul><p>The <code>t_min</code> points to the new transaction (insert) id, and <code>t_max</code> is cleared to indicate this is a valid record.</p><ul><li>Vacuum<br>Let’s perform a vacuum on this table only, and then insert another new record, <code>id=1001</code>.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# vacuum orders1;</span><br><span class="line">VACUUM</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# insert into orders1 values(1001, &#39;hello world!&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 0), &#39;orders1&#39;::regclass);</span><br><span class="line"> lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                     t_attrs                     </span><br><span class="line">-----+--------+----------+--------+--------+--------+----------+---------+-------------+------------+--------+--------+-------+-------------------------------------------------</span><br><span class="line">   1 |   4400 |        1 |     41 |    601 |      0 |        0 | (0,1)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\xe8030000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   2 |   8144 |        1 |     41 |    598 |      0 |        0 | (0,2)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x02000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   3 |   4352 |        1 |     41 |    602 |      0 |        0 | (0,3)   |           2 |       2050 |     24 |        |       | &#123;&quot;\\xe9030000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   4 |   8096 |        1 |     41 |    598 |      0 |        0 | (0,4)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x04000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   5 |      0 |        0 |      0 |        |        |          |         |             |            |        |        |       | </span><br><span class="line">   6 |   8048 |        1 |     41 |    598 |      0 |        0 | (0,6)   |           2 |       2306 |     24 |        |       | &#123;&quot;\\x06000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br></pre></td></tr></table></figure><p>The result shows the 2nd new record <code>id=1001</code> is inserted to the 3rd place, and we don’t see any different after <code>vacuum orders1</code> was executed.</p><ul><li>Vacuum full<br>Now, let’s run a vacuum full, and insert the 3rd new record,<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# vacuum full;</span><br><span class="line">VACUUM</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# insert into orders1 values(1002, &#39;hello world!&#39;);</span><br><span class="line">INSERT 0 1</span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 0), &#39;orders1&#39;::regclass);</span><br><span class="line"> lp  | lp_off | lp_flags | lp_len | t_xmin | t_xmax | t_field3 | t_ctid  | t_infomask2 | t_infomask | t_hoff | t_bits | t_oid |                     t_attrs                     </span><br><span class="line">-----+--------+----------+--------+--------+--------+----------+---------+-------------+------------+--------+--------+-------+-------------------------------------------------</span><br><span class="line">   1 |   8144 |        1 |     41 |    601 |      0 |        0 | (0,1)   |           2 |       2818 |     24 |        |       | &#123;&quot;\\xe8030000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   2 |   8096 |        1 |     41 |    598 |      0 |        0 | (0,2)   |           2 |       2818 |     24 |        |       | &#123;&quot;\\x02000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   3 |   8048 |        1 |     41 |    602 |      0 |        0 | (0,3)   |           2 |       2818 |     24 |        |       | &#123;&quot;\\xe9030000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   4 |   8000 |        1 |     41 |    598 |      0 |        0 | (0,4)   |           2 |       2818 |     24 |        |       | &#123;&quot;\\x04000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   5 |   7952 |        1 |     41 |    598 |      0 |        0 | (0,5)   |           2 |       2818 |     24 |        |       | &#123;&quot;\\x06000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">   6 |   7904 |        1 |     41 |    598 |      0 |        0 | (0,6)   |           2 |       2818 |     24 |        |       | &#123;&quot;\\x08000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">... ...    </span><br><span class="line"> 100 |   3392 |        1 |     41 |    598 |      0 |        0 | (0,100) |           2 |       2818 |     24 |        |       | &#123;&quot;\\xc4000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> 101 |   3344 |        1 |     41 |    598 |      0 |        0 | (0,101) |           2 |       2818 |     24 |        |       | &#123;&quot;\\xc6000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> 102 |   3296 |        1 |     41 |    598 |      0 |        0 | (0,102) |           2 |       2818 |     24 |        |       | &#123;&quot;\\xc8000000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line"> 103 |   3248 |        1 |     41 |    676 |      0 |        0 | (0,103) |           2 |       2050 |     24 |        |       | &#123;&quot;\\xea030000&quot;,&quot;\\x1b68656c6c6f20776f726c6421&quot;&#125;</span><br><span class="line">(103 rows)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT * FROM heap_page_item_attrs(get_raw_page(&#39;orders1&#39;, 2), &#39;orders1&#39;::regclass);</span><br><span class="line">ERROR:  block number 2 is out of range for relation &quot;orders1&quot;</span><br></pre></td></tr></table></figure>After the <code>vacuum full</code>, there are some changes,<br>1) all dead tuples were removed, the rest tuples were shuffled and merged into the 1st page, and the 2nd page was deleted.<br>2) the new record 1id=10021 was inserted to the very end.<br>3) No access to the 2nd page, since it has been deleted.</li></ul><p>This extension provides an easy way to observe how a heap page is changed when performing insert, delete and vacuum. The same behaviour can be observed on the heap file when using hexdump command (<code>checkpoint</code> may require to force the memory page to be flushed to heap file after each operation).</p><h4 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6.    Summary"></a>6.    Summary</h4><p>We explained how the heap files are created, the internal data structure of heap file and page (a segment of a heap file), and demonstrated how to use the extension <code>pageinspect</code> to check what happens when user performed some insert, delete and vacuum. In the coming blogs, I will explain the free space mapping file and the visibility mapping file in the same way.</p><p>Ref: <a href="https://www.postgresql.org/docs/current/storage-file-layout.html" target="_blank" rel="noopener">PG Database File Layout</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-heap-page.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. 
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="Heap" scheme="https://idrawone.github.io/categories/PostgreSQL/Heap/"/>
    
      <category term="Page" scheme="https://idrawone.github.io/categories/PostgreSQL/Heap/Page/"/>
    
      <category term="Extension" scheme="https://idrawone.github.io/categories/PostgreSQL/Heap/Page/Extension/"/>
    
    
  </entry>
  
  <entry>
    <title>How to setup Postgresql on an IPv6 enabled network</title>
    <link href="https://idrawone.github.io/2020/08/21/How-to-setup-Postgresql-on-an-IPv6-enabled-network/"/>
    <id>https://idrawone.github.io/2020/08/21/How-to-setup-Postgresql-on-an-IPv6-enabled-network/</id>
    <published>2020-08-21T08:00:00.000Z</published>
    <updated>2020-08-21T23:26:40.124Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-ipv6.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL is a great open source database, not only because it supports lot of database features, but also because it supports different network setup. For example, you can set it up on an IPv6 enabled network in just a few steps. This blog will demonstrate how to setup PostgreSQL on an IPv6 network in Linux. </p><p>Before we dive into the detail, let’s discuss a little bit IPv6. IPv6 was developed by the Internet Engineering Task Force (IETF) in late 1998 and was intended to replace IPv4. With the IPv4 address exhaustion issue, after about two decades, IPv6 now is finally coming into the real picture. Below is the <a href="https://www.internetsociety.org/resources/2018/state-of-ipv6-deployment-2018/" target="_blank" rel="noopener">state of IPv6 Deployment in 2018</a>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">* Over 25% of all Internet-connected networks advertise IPv6 connectivity.</span><br><span class="line">* Google reports 49 countries deliver more than 5% of traffic over IPv6, with new countries joining all the time.</span><br><span class="line">* Google reports 24 countries whose IPv6 traffic exceeds 15%.</span><br></pre></td></tr></table></figure><p>If you check your home internet modem/router and most likely you will find the IPv6 is already enabled. There are many documents and RFCs explain IPv6 in much more detail. For example, <code>IP Version 6 Addressing Architecture</code> defined in <a href="https://datatracker.ietf.org/doc/rfc4291/" target="_blank" rel="noopener">RFC 4291</a>. In this blog, I will just explain some simple concepts which is required in this demo.</p><h4 id="2-Setup-IPv6-network"><a href="#2-Setup-IPv6-network" class="headerlink" title="2. Setup IPv6 network"></a>2. Setup IPv6 network</h4><h5 id="Link-local-address"><a href="#Link-local-address" class="headerlink" title="Link-local address"></a>Link-local address</h5><p>Not like IPv4, all the interface of an IPv6 enabled host require a link-local address. The link-local address will always start with the prefix fe80:: and it is generated during TCP/IP stack boot up on that interface. The interesting part is that link-local address doesn’t request a DHCP server or any manual configuration. The link-local can be set to derive from the MAC address of the interface, in this case, if you know the MAC of the interface then you can create the link-local address by simply copy and paste the MAC to a <a href="https://ben.akrin.com/?p=1347" target="_blank" rel="noopener">link-local calculator</a>. </p><h5 id="Global-address"><a href="#Global-address" class="headerlink" title="Global address"></a>Global address</h5><p>However, there is a limitation as the name indicated, it only works between the hosts which are directly connected. To allow the communication cross the internet or multiple routers, the host needs to have a global address. There are many different ways to setup a global IPv6 address. Here, we introduce three typical ways: Manually, DHCPv6 and SLAAC.</p><ul><li><p>To manually setup an IPv6 global address, you can use either <code>ip</code> or <code>ifconfig</code>. For example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ip -6 addr add 2020:1:0:0::db1&#x2F;64 dev eth0 </span><br><span class="line"></span><br><span class="line">sudo ifconfig eth0 inet6 add 2020:1:0:0::db1&#x2F;64</span><br></pre></td></tr></table></figure><p>Since IPv6 allows the HEX characters, you can make your own customized IPv6 address for fun. For example, configure a PostgreSQL server with IPv6 address like, <code>:db:feed</code>, <code>:da7a:ba5e</code>, <code>:db1</code>, <code>:db2</code> etc,.</p></li><li><p>Stateless address autoconfiguration (SLAAC) requires to have a router which broadcast the <code>router advertisement</code> periodically. The router should also response to <code>router solicitation</code> request from any host machine. Once the host receive the <code>router advertisement</code>, it will use the <code>prefix</code> to generate the global IPv6 address automatically. Below is an example,<br>Install the <code>Router Advertisement Daemon (radvd)</code> on PostgreSQL server side, </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install radvd</span><br></pre></td></tr></table></figure><p>then configure the radvd conf file, for example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">interface eno1</span><br><span class="line">&#123;</span><br><span class="line">   AdvSendAdvert on;</span><br><span class="line">   AdvManagedFlag off;</span><br><span class="line">   AdvOtherConfigFlag on;</span><br><span class="line">   prefix 2020:1:0:0::&#x2F;64</span><br><span class="line">   &#123;</span><br><span class="line">        AdvAutonomous on;</span><br><span class="line">   &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Configure a new IPv6 address on Postgres server for radvd daemon to use</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip -6 addr add 2020:1:0:0::db1&#x2F;64 dev eno1</span><br></pre></td></tr></table></figure><p>Then start the <code>radvd</code> daemon, <code>sudo radvd -l /etc/radvd.conf</code><br>Now, if you check the ip address on the client machine side, you should see something like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">enp0s3: flags&#x3D;4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.20.14.27  netmask 255.255.255.0  broadcast 172.20.14.255</span><br><span class="line">        inet6 2020:1::8dcf:b8be:dbcc:26c6  prefixlen 64  scopeid 0x0&lt;global&gt;</span><br><span class="line">        inet6 fe80::8005:8b22:cd7d:ee39  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 08:00:27:29:ab:c9  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 118  bytes 38615 (38.6 KB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 181  bytes 26919 (26.9 KB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p>where, <code>2020:1::8dcf:b8be:dbcc:26c6</code> is the global address generated after receive the <code>router advertisement</code>.</p></li><li><p>Stateful IPv6 address is done via a DHCPv6 server. The setup is similar to the IPv4 DHCP server setup. Below is an example on an Ubuntu machine, </p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install isc-dhcp-server</span><br></pre></td></tr></table></figure><p>After the DHCP Server has been installed, edit the configuration file for IPv6 address assignment.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;dhcp&#x2F;dhcpd6.conf</span><br></pre></td></tr></table></figure><p>and add below information,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ddns-update-style none;</span><br><span class="line">default-lease-time 7200; # 12 hours</span><br><span class="line">max-lease-time 86400; # 12 hours</span><br><span class="line">authoritative;</span><br><span class="line"></span><br><span class="line">### Subnet</span><br><span class="line">subnet6 2020:2:0:0::&#x2F;64 &#123;</span><br><span class="line">    range6</span><br><span class="line">        2020:2:0:0::1001  2020:2:0:0::1005;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Configure a new IPv6 address on Postgres server for DHCPv6 server to use</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip -6 addr add 2020:2:0:0::db1&#x2F;64 dev eno1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dhcpd -6 -d -cf &#x2F;etc&#x2F;dhcp&#x2F;dhcpd6.conf eth0</span><br></pre></td></tr></table></figure><p>On the client machine side, run a dhcp request for IPv6 manually. <code>sudo dhclient -6 enp0s3</code>, and then perform an ip address check.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">enp0s3: flags&#x3D;4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.20.14.27  netmask 255.255.255.0  broadcast 172.20.14.255</span><br><span class="line">        inet6 2020:2::1004  prefixlen 128  scopeid 0x0&lt;global&gt;</span><br><span class="line">        inet6 2020:1::8dcf:b8be:dbcc:26c6  prefixlen 64  scopeid 0x0&lt;global&gt;</span><br><span class="line">        inet6 fe80::8005:8b22:cd7d:ee39  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 08:00:27:29:ab:c9  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 1118  bytes 253355 (253.3 KB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 495  bytes 76673 (76.6 KB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p>where, <code>2020:2::1004</code> is the global IPv6 address assigned by the DHCPv6 server.</p><h4 id="3-Connetivity-test-using-ping6"><a href="#3-Connetivity-test-using-ping6" class="headerlink" title="3. Connetivity test using ping6"></a>3. Connetivity test using ping6</h4><ul><li>PostgreSQL server<ul><li>Network interface: eno1</li><li>link-local: fe80::1c79:293f:1b6e:c826</li><li>IPv6 global address(SLAAC): 2020:1::db1</li><li>IPv6 global address(DHCPv6): 2020:2::db1</li></ul></li></ul><ul><li>psql client IPs<ul><li>Network interface: enp0s3</li><li>link-local: fe80::8005:8b22:cd7d:ee39</li><li>IPv6 global address generated(SLAAC): 2020:1::8dcf:b8be:dbcc:26c6</li><li>IPv6 global address assigned(DHCPv6): 2020:2::1004</li></ul></li></ul><h5 id="ping6-test-from-server-to-client"><a href="#ping6-test-from-server-to-client" class="headerlink" title="ping6 test from server to client"></a>ping6 test from server to client</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ ping6 fe80::8005:8b22:cd7d:ee39%eno1</span><br><span class="line">PING fe80::8005:8b22:cd7d:ee39%eno1(fe80::8005:8b22:cd7d:ee39%eno1) 56 data bytes</span><br><span class="line">64 bytes from fe80::8005:8b22:cd7d:ee39%eno1: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.582 ms</span><br><span class="line">64 bytes from fe80::8005:8b22:cd7d:ee39%eno1: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.572 ms</span><br><span class="line"></span><br><span class="line">$ ping6 2020:1::8dcf:b8be:dbcc:26c6</span><br><span class="line">PING 2020:1::8dcf:b8be:dbcc:26c6(2020:1::8dcf:b8be:dbcc:26c6) 56 data bytes</span><br><span class="line">64 bytes from 2020:1::8dcf:b8be:dbcc:26c6: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.576 ms</span><br><span class="line">64 bytes from 2020:1::8dcf:b8be:dbcc:26c6: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.601 ms</span><br><span class="line"></span><br><span class="line">$ ping6 2020:2::1004</span><br><span class="line">PING 2020:2::1004(2020:2::1004) 56 data bytes</span><br><span class="line">64 bytes from 2020:2::1004: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.896 ms</span><br><span class="line">64 bytes from 2020:2::1004: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.631 ms</span><br></pre></td></tr></table></figure><h5 id="ping6-test-from-client-to-server"><a href="#ping6-test-from-client-to-server" class="headerlink" title="ping6 test from client to server"></a>ping6 test from client to server</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ ping6 fe80::1c79:293f:1b6e:c826%enp0s3</span><br><span class="line">PING fe80::1c79:293f:1b6e:c826%enp0s3(fe80::1c79:293f:1b6e:c826%enp0s3) 56 data bytes</span><br><span class="line">64 bytes from fe80::1c79:293f:1b6e:c826%enp0s3: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.144 ms</span><br><span class="line">64 bytes from fe80::1c79:293f:1b6e:c826%enp0s3: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.220 ms</span><br><span class="line"></span><br><span class="line">$ ping6 2020:1::db1</span><br><span class="line">PING 2020:1::db1(2020:1::db1) 56 data bytes</span><br><span class="line">64 bytes from 2020:1::db1: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.825 ms</span><br><span class="line">64 bytes from 2020:1::db1: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.520 ms</span><br><span class="line"></span><br><span class="line">$ ping6 2020:2::db1</span><br><span class="line">PING 2020:2::db1(2020:2::db1) 56 data bytes</span><br><span class="line">64 bytes from 2020:2::db1: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.508 ms</span><br><span class="line">64 bytes from 2020:2::db1: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.486 ms</span><br></pre></td></tr></table></figure><h4 id="4-Configure-PostgreSQL-for-IPv6"><a href="#4-Configure-PostgreSQL-for-IPv6" class="headerlink" title="4. Configure PostgreSQL for IPv6"></a>4. Configure PostgreSQL for IPv6</h4><p>Edit the postgresql.conf file to allow Postgres listen on different interfaces</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen_addresses &#x3D; &#39;*&#39;</span><br></pre></td></tr></table></figure><p>Edit the host-based authentication file to allow client machine to connect with different source IPs.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># IPv6 local connections:</span><br><span class="line">host    all             all             fe80::8005:8b22:cd7d:ee39&#x2F;128           trust</span><br><span class="line">host    all             all             2020:1::8dcf:b8be:dbcc:26c6&#x2F;128         trust</span><br><span class="line">host    all             all             2020:2::1004&#x2F;128                        trust</span><br></pre></td></tr></table></figure><h5 id="psql-client-connect-to-Postgres-server-using-link-local-address-with-interface-name"><a href="#psql-client-connect-to-Postgres-server-using-link-local-address-with-interface-name" class="headerlink" title="psql client connect to Postgres server using link-local address with interface name"></a>psql client connect to Postgres server using link-local address with interface name</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ psql -d postgres -U david -h fe80::1c79:293f:1b6e:c826%enp0s3</span><br><span class="line">psql (14devel)</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT datname,pid, usename, client_addr FROM pg_stat_activity where usename&#x3D;&#39;david&#39;;</span><br><span class="line"> datname  |  pid  | usename |        client_addr        </span><br><span class="line">----------+-------+---------+---------------------------</span><br><span class="line">          | 24170 | david   | </span><br><span class="line"> postgres | 24244 | david   | fe80::8005:8b22:cd7d:ee39</span><br><span class="line">(2 rows)</span><br></pre></td></tr></table></figure><h5 id="psql-client-connect-to-Postgres-server-using-global-address-Stateless-address"><a href="#psql-client-connect-to-Postgres-server-using-global-address-Stateless-address" class="headerlink" title="psql client connect to Postgres server using global address(Stateless address)"></a>psql client connect to Postgres server using global address(Stateless address)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ psql -d postgres -U david -h 2020:1::db1</span><br><span class="line">psql (14devel)</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT datname,pid, usename, client_addr FROM pg_stat_activity where usename&#x3D;&#39;david&#39;;</span><br><span class="line"> datname  |  pid  | usename |         client_addr         </span><br><span class="line">----------+-------+---------+-----------------------------</span><br><span class="line">          | 24131 | david   | </span><br><span class="line"> postgres | 24149 | david   | 2020:1::8dcf:b8be:dbcc:26c6</span><br></pre></td></tr></table></figure><h5 id="psql-client-connect-to-Postgres-server-using-global-address-Stateful-address"><a href="#psql-client-connect-to-Postgres-server-using-global-address-Stateful-address" class="headerlink" title="psql client connect to Postgres server using global address(Stateful address)"></a>psql client connect to Postgres server using global address(Stateful address)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ psql -d postgres -U david -h 2020:2::db1</span><br><span class="line">psql (14devel)</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# SELECT datname,pid, usename, client_addr FROM pg_stat_activity where usename&#x3D;&#39;david&#39;;</span><br><span class="line"> datname  |  pid  | usename | client_addr  </span><br><span class="line">----------+-------+---------+--------------</span><br><span class="line">          | 24170 | david   | </span><br><span class="line"> postgres | 24235 | david   | 2020:2::1004</span><br></pre></td></tr></table></figure><h4 id="5-Typical-errors"><a href="#5-Typical-errors" class="headerlink" title="5. Typical errors"></a>5. Typical errors</h4><h5 id="Using-link-local-to-connect-Postgres-without-the-interface-name"><a href="#Using-link-local-to-connect-Postgres-without-the-interface-name" class="headerlink" title="Using link-local to connect Postgres without the interface name"></a>Using link-local to connect Postgres without the interface name</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ psql -d postgres -U david -h fe80::1c79:293f:1b6e:c826</span><br><span class="line">psql: error: could not connect to server: could not connect to server: Invalid argument</span><br><span class="line">    Is the server running on host &quot;fe80::1c79:293f:1b6e:c826&quot; and accepting</span><br><span class="line">    TCP&#x2F;IP connections on port 5432?</span><br></pre></td></tr></table></figure><h5 id="psql-client-using-a-wrong-global-address-as-source-address"><a href="#psql-client-using-a-wrong-global-address-as-source-address" class="headerlink" title="psql client using a wrong global address as source address"></a>psql client using a wrong global address as source address</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ psql -d postgres -h 2020:2::db1</span><br><span class="line">psql: error: could not connect to server: FATAL:  no pg_hba.conf entry for host &quot;2020:1::8dcf:b8be:dbcc:26c6&quot;, user &quot;dbtest&quot;, database &quot;postgres&quot;</span><br></pre></td></tr></table></figure><p>This is due to multiple IPv6 global addresses available on the same interface. In this case, the application, i.e. <code>psql</code> should have an option to select the preferred IPv6, otherwise, the kernel will pick up the IPv6 global address based on predefined policy and rules. Please check <a href="http://linux-ip.net/html/routing-saddr-selection.html" target="_blank" rel="noopener">Source Address Selection</a> for details. A simple solution is the remove other global IPv6 addresses, and disable the corresponding <code>service</code> i.e. <code>radvd</code> or <code>DHCPv6</code> server.</p><h4 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6.    Summary"></a>6.    Summary</h4><p>We demonstrated how to setup a simple IPv6 network with one Postgres server and one psql client. To enable the IPv6 configuration is pretty simple on PostgreSQL side, but some the basic IPv6 knowledge is required.</p><p>Ref: [Configuring IPv6 addresses] (<a href="https://www.tldp.org/HOWTO/Linux+IPv6-HOWTO/ch06s02.html" target="_blank" rel="noopener">https://www.tldp.org/HOWTO/Linux+IPv6-HOWTO/ch06s02.html</a>)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-ipv6.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. Overv
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="Debug" scheme="https://idrawone.github.io/categories/PostgreSQL/Debug/"/>
    
    
  </entry>
  
  <entry>
    <title>A simple way found a bug born in 1997</title>
    <link href="https://idrawone.github.io/2020/07/10/A-simple-way-to-trace-a-bug-when-you-donot-have-enough-time/"/>
    <id>https://idrawone.github.io/2020/07/10/A-simple-way-to-trace-a-bug-when-you-donot-have-enough-time/</id>
    <published>2020-07-10T08:00:00.000Z</published>
    <updated>2020-07-11T18:53:36.544Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/fi-gdb-step-mult.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>Whenever I tried to study PostgreSQL source code a little deeper, I always wanted to find some tools to help me understand better as I really don’t want to read the code line by line for a particular feature, but at the same time, I really wanted to figure it out quickly. Simply put, I was kind of “lazy” at that movement. Luckily, I found one very simple way to help me when I was studying the <code>Geometric Types</code> in PostgreSQL. This simple method helped me find out a bug exist since 1997. Thanks to Tom Lane who helpped fix it and committed it to Postgresql. The commit is “35d1eefb29d03d5a85f71038679f1f8a14358255” with below comments.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Fix circle_in to accept &quot;(x,y),r&quot; as it&#39;s advertised to do.</span><br><span class="line"></span><br><span class="line">Our documentation describes four allowed input syntaxes for circles,</span><br><span class="line">but the regression tests tried only three ... with predictable</span><br><span class="line">consequences.  Remarkably, this has been wrong since the circle</span><br><span class="line">datatype was added in 1997, but nobody noticed till now.</span><br></pre></td></tr></table></figure><p>In this blog, I will use this story to explain how did I figure out this bug using a script in a very simple way.</p><h4 id="2-Find-a-bug-born-in-1997"><a href="#2-Find-a-bug-born-in-1997" class="headerlink" title="2. Find a bug born in 1997"></a>2. Find a bug born in 1997</h4><p>A few months ago, I was trying to see what was all the Geometric Types PostgreSQL can support by checking the official <a href="https://www.postgresql.org/docs/current/datatype-geometric.html" target="_blank" rel="noopener">document</a>. In the section <code>8.8.7. Circles</code>, the different ways to insert a circle were described like below. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Circles are represented by a center point and radius. Values of type circle are specified using any of the following syntaxes:</span><br><span class="line"></span><br><span class="line">&lt; ( x , y ) , r &gt;</span><br><span class="line">( ( x , y ) , r )</span><br><span class="line">  ( x , y ) , r</span><br><span class="line">    x , y   , r</span><br></pre></td></tr></table></figure><p>I was so suprised that there are some many ways to draw a circle in PostgreSQL, and accidently I had a psql console connected to a server at that moment. So, I decided to try all the methods one by one. However, when I followed the 3rd way to insert a circle, I encountered an error, i.e. <code>invalid input syntax for type circle</code>. Here is the what did at that moment.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE tbl_circle(id serial PRIMARY KEY, a circle);</span><br><span class="line">INSERT INTO tbl_circle(a) VALUES(&#39;( 1 , 1 ) , 5&#39;::circle );</span><br><span class="line"></span><br><span class="line">ERROR:  invalid input syntax for type circle: &quot;( 1 , 1 ) , 5&quot;</span><br><span class="line">LINE 1: INSERT INTO tbl_circle(a) VALUES(&#39;( 1 , 1 ) , 5&#39;::circle );</span><br></pre></td></tr></table></figure><p>The first thoughts came to my mind was that I must have typed something wrong. But after carefully checked each character, I couldn’t find any error. However, I conldn’t believe what I saw on the screen, therefore I called my colleague to help me do a quick check. The result was the same. Then I started to think if I can go a little further to find out the bug before reporting to the community, it might help some. But, the question was how to find the issue out within limited time (I did have a lot of work need to be done in the same day, in other words, “I was busy”. Well, “busy” is actually one of the main reasons I want to discuss about this simple method).</p><p>Obviously, I was not so familiar with the data type related circle in PostgreSQL source code, but I did know how to compile PostgreSQL from source code and how to use gdb to run a simple debug (keep in mind, these are all the prerequisite). </p><p>I started to compile the source code with gdb enabled like below.<br><code>./configure --enable-cassert --enable-debug CFLAGS=&quot;-ggdb -O0 -g3 -fno-omit-frame-pointer”</code></p><p>After the PostgerSQL server restarted, I used gdb to attach to the postgres running in background which connected to my psql console. I set up a breakpoint to the function <code>transformExprRecurse</code> (well, this is another prerequisite). I tried to repeat the circle insert query, and the gdb stopped at <code>transformExprRecurse</code>. Now, I was totally stuck. I didn’t know how to locate the bug, I had no idea what was behind the circle data type, and in which file it was implemented etc.. Then how could I move a litter further?</p><p>Well, I did have one thing in my mind that I need to quickly find out the difference between the working data type and the non-working data type. To achieve this, a simple way would be just type a <code>next</code> and then press <code>enter</code>. I started to do it. But after repeated 3 times, I gave it up. I realized that I didn’t know how many times I have to repeat the process and it was not possible for me to capture the difference. Then I started to question myself whether there was a way to automatically type <code>next</code> and then <code>enter</code> until the circle insert query was finished. Thanks to <code>google</code>, yes, I found <a href="https://stackoverflow.com/questions/5812411/gdb-automatic-nexting" target="_blank" rel="noopener">this</a>. I copied and pasted the script and added <code>transformExprRecurse</code> as the default breakpoint. The scpript was ended up like below,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># file: step_mult.gdb</span><br><span class="line"></span><br><span class="line">set pagination off</span><br><span class="line">set detach-on-fork off</span><br><span class="line">set schedule-multiple on</span><br><span class="line">handle SIGUSR1 noprint nostop</span><br><span class="line">handle SIGUSR2 noprint nostop</span><br><span class="line">macro define __builtin_offsetof(T, F) ((int) &amp;(((T *) 0)-&gt;F))</span><br><span class="line">macro define __extension__</span><br><span class="line">python gdb.events.exited.connect(lambda x: [gdb.execute(&#39;inferior 1&#39;), gdb.post_event(lambda: gdb.execute(&#39;continue&#39;))])</span><br><span class="line"></span><br><span class="line">set logging file gdb.log</span><br><span class="line">set logging on</span><br><span class="line"></span><br><span class="line">break transformExprRecurse</span><br><span class="line"></span><br><span class="line">####</span><br><span class="line">define step_mult</span><br><span class="line">    set $step_mult_max &#x3D; 100000</span><br><span class="line">    if $argc &gt;&#x3D; 1</span><br><span class="line">        set $step_mult_max &#x3D; $arg0</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    set $step_mult_count &#x3D; 0</span><br><span class="line">    while ($step_mult_count &lt; $step_mult_max)</span><br><span class="line">        set $step_mult_count &#x3D; $step_mult_count + 1</span><br><span class="line">        printf &quot;step #%d\n&quot;, $step_mult_count</span><br><span class="line">        step</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>I re-attach the postgres, ran the command <code>source step_mult.gdb</code> within gdb console, and then let the postgres continue to run in the background. I switched to another console and started to insert a circle using the 3rd way again. Postgres stopped at <code>exec_simple_query</code>, then I ran <code>step_mult 10000</code>. After a while, I saw the error message on my psql console again. I changed the log file gdb.log to gdb-2nd.log and repeated the steps, but this time I inserted a circle using the 2nd way. Now, I got two gdb log files which contain all the single step for the working and non-working circle data types.</p><p>I used a very nice <a href="https://www.scootersoftware.com/index.php" target="_blank" rel="noopener">Intelligent Comparison tools</a> to compare these two gdb log files and I foud the difference like below. <img src="/images/img/gdb-step-diff.png" alt="diff image">. The big difference I saw was showing in <code>circle_in</code> function within <code>src/backend/utils/adt/geo_ops.c</code>.</p><p>Now, I figured out where the data type circle was implemented. To proof that it was the right place to fix this issue, I made a quick dirty fix. Then I performed a test and found the 3rd data type was kind of <code>fixed</code>. </p><p>At this point, I was more confident to report this issue to the community with my <code>dirty</code> patch to proof that PostgreSQL doesn’t work with the 3rd way to draw a circle. The entire process took me about an hour, but I think finding out a bug which has stayed in PostgreSQL about 23 years in an hour is not that bad. </p><h4 id="3-Summary"><a href="#3-Summary" class="headerlink" title="3.    Summary"></a>3.    Summary</h4><p>PostgreSQL is one of the best open source RDBMS in the world, and there are many other open source projects like it. As a software engineer, you might encounter something like me in your daily work. If you find something fishy but don’t have enough time, then try the way I did. It may surprise you, who knows. From my opinion, this method may be suitable for below sisutations:</p><p>1) A feature is working in one use case but it doesn’t work in another very similar use case;<br>2) To find a function execution path in different conditions;<br>… </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/fi-gdb-step-mult.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="Debug" scheme="https://idrawone.github.io/categories/PostgreSQL/Debug/"/>
    
    
  </entry>
  
  <entry>
    <title>Build PostgreSQL and Extension on Windows</title>
    <link href="https://idrawone.github.io/2020/05/15/Build-PostgreSQL-and-Extension-on-Windows/"/>
    <id>https://idrawone.github.io/2020/05/15/Build-PostgreSQL-and-Extension-on-Windows/</id>
    <published>2020-05-15T08:00:00.000Z</published>
    <updated>2020-05-15T22:30:10.898Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/img/win-fi.png" alt="Featured image"></p><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p>PostgreSQL is an open-source RDMS and running across many platforms including Linux (all recent distributions), Windows, FreeBSD, OpenBSD, NetBSD, Mac OS X, AIX, HP/UX, IRIX, Solaris, Tru64 Unix, and UnixWare. There are many discussions about how to build Postgres and extensions from source code on a Linux-like environment, but sometimes, a developer may want to quickly setup a Windows environment to check a feature for cross-platform support. This blog is going to explain how to build Postgres and extensions from source code on Windows platforms and it was tested on Windows 7, 10 and 2019 Server.</p><h4 id="2-Environment-setup"><a href="#2-Environment-setup" class="headerlink" title="2. Environment setup"></a>2. Environment setup</h4><p>This blog refers to the official <a href="https://www.postgresql.org/docs/12/install-windows-full.html" target="_blank" rel="noopener">document</a> and the blog <a href="https://www.2ndquadrant.com/en/blog/compiling-postgresql-extensions-visual-studio-windows" target="_blank" rel="noopener">Compiling PostgreSQL extensions with Visual Studio on Windows</a>, but providing many detailed screenshots on the latest version Visual Studio 2019 for building an extension as a standlone VS2019 project.</p><h5 id="3-Install-VS2019-Windows-SDK-and-other-tools"><a href="#3-Install-VS2019-Windows-SDK-and-other-tools" class="headerlink" title="3. Install VS2019, Windows SDK and other tools"></a>3. Install VS2019, Windows SDK and other tools</h5><p>Download the latest <a href="https://visualstudio.microsoft.com/downloads/?utm_medium=post-banner&utm_source=microsoft.com&utm_campaign=channel+banner&utm_content=launch+vs2019" target="_blank" rel="noopener">Visual Studio 2019</a> package. During the installation process, selecting the option <code>Desktop development with C++</code> is enough to build Postgres. This option will install <code>MSVC for VS 2019</code>, <code>Windows 10 SDK</code> and some basic <code>C/C++ building tools</code>. As described in the official document, <a href="https://platform.activestate.com/activestate/activeperl-5.28/auto-fork?utm_source=activestate.com&utm_medium=referral&utm_content=activeperl-5.28-mac&utm_campaign=user-acquisition" target="_blank" rel="noopener">ActiveState Perl</a> is required to run the build and generate scripts, and <a href="https://platform.activestate.com/activestate/activetcl-8.6/auto-fork?utm_source=activestate.com&utm_medium=referral&utm_content=activetcl-8.6&utm_campaign=user-acquisition" target="_blank" rel="noopener">ActiveState TCL</a> is required for building PL/Tcl. If the you build from a released source code <a href="https://www.postgresql.org/ftp/source/v12.3/" target="_blank" rel="noopener">tar file</a>, then install above tools should be enough for the default configuration, however if you build with the source coded cloned from <a href="https://github.com/postgres/postgres.git" target="_blank" rel="noopener">github</a>, then you need to install <code>Bison</code> and <code>Flex</code>, which can be found <a href="http://www.mingw.org/wiki/MSYS" target="_blank" rel="noopener">here</a>.<br>If you prefer to use Linux style commands as much as possible, then you can install <a href="https://github.com/git-for-windows/git/releases/latest" target="_blank" rel="noopener">git bash</a>. After all the tools has been installed, you need to <code>edit the system environment variables</code> to include all the binaries paths, for example, <img src="/images/img/win-env.png" alt="windows environment image"></p><h5 id="4-Build-postgres"><a href="#4-Build-postgres" class="headerlink" title="4. Build postgres"></a>4. Build postgres</h5><p>If you have an extension need to be built under the source code tree, then it is time to clone or copy your extension to <code>contrib</code> folder before starting the build. To build Postgres is pretty simple, just turn on VS 2019 terminal i.e. <code>Developer Command Prompt for VS 2019</code> and then navigate to the windows build folder inside the postgres source code, for example, <code>c:\Users\Administrator\Downloads\postgres\src\tools\msvc&gt;</code> and then run <code>build.bat</code>.</p><h5 id="5-Regress-test"><a href="#5-Regress-test" class="headerlink" title="5. Regress test"></a>5. Regress test</h5><p>If the build is succeeded, then you can perform a regress test by running <code>vcregress check</code>. To perform a regress test for the extensions, run the command <code>vcregress contribcheck</code>. If you are developing an extension on Windows and you want to speed up the build, then you can build your extension only by running the build script with the extension name, for example, <code>build.bat wal2mongo</code>. However, you can’t run a regress test for each individual extension. This can be worked around by removing all other extension from <code>contrib</code> folder temporally.</p><h5 id="6-Build-extension-in-an-independent-project-using-VS-2019"><a href="#6-Build-extension-in-an-independent-project-using-VS-2019" class="headerlink" title="6. Build extension in an independent project using VS 2019"></a>6. Build extension in an independent project using VS 2019</h5><p>Sometimes a developer may want to build an extension within VS2019 IDE. This is a little bit tricky and not even recommended to do it in this way but it is possible. The blog mentioned above has a detailed discussion about this topic. Here, we provide a step by step guide to walk you through the whole process on VS 2019.</p><ul><li>Start VS 2019 and <code>Create a new project</code></li><li>Select <code>Empty Project</code> template, which will create a C/C++ for Windows without any starting files.</li><li>Give a name for this extension project, for example <code>wal2mongo</code> (We use <a href="https://github.com/HighgoSoftware/wal2mongo.git" target="_blank" rel="noopener">wal2mongo</a> to demonstrate how to build an extension using VS 2019)</li><li>Right click on the project, select <code>Add</code> then <code>New Item...</code></li><li>Select <code>C++ File (.cpp)</code> template and name the file as <code>wal2mongo.c</code></li><li>Copy the whole content from <a href="https://github.com/HighgoSoftware/wal2mongo/blob/release/wal2mongo.c" target="_blank" rel="noopener">this file</a> to the newly created <code>wal2mongo.c</code> file</li><li>Add <code>PGDLLEXPORT</code> after the keyword <code>extern</code>, otherwise MSVC will not export its symbol.<br>the original file,<br><img src="/images/img/win-before.png" alt="before change image"><br>and how it looks like after the changes.<br><img src="/images/img/win-after.png" alt="after change image"></li><li>Right click the project, select <code>Properties</code> and then change following in order,<br>1 Click on <code>Configuration Properities</code> -&gt; <code>General</code> -&gt; Configuration Type, then select <code>Dynamic Library (.dll)</code><br><img src="/images/img/win-pro-1.png" alt="vs pro-1 image"><br>2 Click on <code>Configuration Prosperities</code> -&gt; <code>C/C++</code> -&gt; <code>General</code>, add the including paths in the order below<br><img src="/images/img/win-pro-2.png" alt="vs pro-2 image"><br>3 Click on <code>Configuration Prosperities</code> -&gt; <code>C/C++</code> -&gt; <code>Code Generation</code> -&gt; <code>Enable C++ Exceptions</code>, select <code>No</code><br><img src="/images/img/win-pro-3.png" alt="vs pro-3 image"><br>4 <code>Configuration Prosperities</code> -&gt; <code>C/C++</code> -&gt; <code>Advanced</code> -&gt; <code>Compile As</code>, select <code>Compile as C Code(/TC)</code><br><img src="/images/img/win-pro-4.png" alt="vs pro-4 image"><br>5 Click on <code>Configuration Prosperities</code> -&gt; <code>Linker</code> -&gt; <code>General</code> -&gt; <code>Additional Library Directories</code>, enter the lib path where your Postgres libraries are installed<br><img src="/images/img/win-pro-5.png" alt="vs pro-5 image"><br>6 Click on <code>Configuration Prosperities</code> -&gt; <code>Linker</code> -&gt; <code>Input</code> -&gt; <code>Additional Dependencies</code>, add <code>postgres.lib</code><br><img src="/images/img/win-pro-6.png" alt="vs pro-6 image"><br>7 Click on <code>Configuration Prosperities</code> -&gt; <code>Linker</code> -&gt; <code>Manifest File</code> -&gt; <code>Generate Manifest</code>, select <code>No (/MANIFEST:NO)</code><br><img src="/images/img/win-pro-7.png" alt="vs pro-7 image"></li><li>Finally, right click on the project and then select build.<br>If everything goes fine, then you should see <code>wal2mongo.dll</code> is created. Copy <code>wal2mongo.dll</code> to the lib folder where the Postgres libraries were installed. Then you should be able to test this extension as normal.</li></ul><h4 id="7-Summary"><a href="#7-Summary" class="headerlink" title="7. Summary"></a>7. Summary</h4><p>In this blog, we discussed how to build postgres and extension on Windows, especially to build an extension within VS2019. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/img/win-fi.png&quot; alt=&quot;Featured image&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. Overvi
      
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://idrawone.github.io/categories/PostgreSQL/"/>
    
      <category term="Extension" scheme="https://idrawone.github.io/categories/PostgreSQL/Extension/"/>
    
      <category term="Build" scheme="https://idrawone.github.io/categories/PostgreSQL/Extension/Build/"/>
    
      <category term="Windows" scheme="https://idrawone.github.io/categories/PostgreSQL/Extension/Build/Windows/"/>
    
      <category term="VS2019" scheme="https://idrawone.github.io/categories/PostgreSQL/Extension/Build/Windows/VS2019/"/>
    
    
  </entry>
  
</feed>
